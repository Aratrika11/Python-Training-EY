{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZPirnoVMezn4"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "spark = SparkSession.builder.appName(\"DAG and Broadcast Exercise\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset 1"
      ],
      "metadata": {
        "id": "2J2OSbZJtYEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rides_data = [\n",
        "(\"R001\",\"U001\",\"Hyderabad\",12.5,240,\"Completed\"),\n",
        "(\"R002\",\"U002\",\"Delhi\",8.2,180,\"Completed\"),\n",
        "(\"R003\",\"U003\",\"Mumbai\",15.0,300,\"Cancelled\"),\n",
        "(\"R004\",\"U004\",\"Bangalore\",5.5,120,\"Completed\"),\n",
        "(\"R005\",\"U005\",\"Hyderabad\",20.0,360,\"Completed\"),\n",
        "(\"R006\",\"U006\",\"Delhi\",25.0,420,\"Completed\"),\n",
        "(\"R007\",\"U007\",\"Mumbai\",7.5,150,\"Completed\"),\n",
        "(\"R008\",\"U008\",\"Bangalore\",18.0,330,\"Completed\"),\n",
        "(\"R009\",\"U009\",\"Delhi\",6.0,140,\"Cancelled\"),\n",
        "(\"R010\",\"U010\",\"Hyderabad\",10.0,200,\"Completed\")\n",
        "]\n",
        "rides_cols = [\n",
        "\"ride_id\",\"user_id\",\n",
        "\"city\",\"distance_km\",\n",
        "\"duration_seconds\",\"status\"\n",
        "]\n",
        "rides_df = spark.createDataFrame(rides_data, rides_cols)\n",
        "rides_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fc33tYUNsi7i",
        "outputId": "c910cc4c-b54f-468c-c1f5-feb8da0a546c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+---------+-----------+----------------+---------+\n",
            "|ride_id|user_id|     city|distance_km|duration_seconds|   status|\n",
            "+-------+-------+---------+-----------+----------------+---------+\n",
            "|   R001|   U001|Hyderabad|       12.5|             240|Completed|\n",
            "|   R002|   U002|    Delhi|        8.2|             180|Completed|\n",
            "|   R003|   U003|   Mumbai|       15.0|             300|Cancelled|\n",
            "|   R004|   U004|Bangalore|        5.5|             120|Completed|\n",
            "|   R005|   U005|Hyderabad|       20.0|             360|Completed|\n",
            "|   R006|   U006|    Delhi|       25.0|             420|Completed|\n",
            "|   R007|   U007|   Mumbai|        7.5|             150|Completed|\n",
            "|   R008|   U008|Bangalore|       18.0|             330|Completed|\n",
            "|   R009|   U009|    Delhi|        6.0|             140|Cancelled|\n",
            "|   R010|   U010|Hyderabad|       10.0|             200|Completed|\n",
            "+-------+-------+---------+-----------+----------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset 2"
      ],
      "metadata": {
        "id": "heDKM4ZOtUcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "surge_data = [\n",
        "(\"Hyderabad\",1.2),\n",
        "(\"Delhi\",1.5),\n",
        "(\"Mumbai\",1.8),\n",
        "(\"Bangalore\",1.3)\n",
        "]\n",
        "surge_cols = [\"city\",\"surge_multiplier\"]\n",
        "surge_df = spark.createDataFrame(surge_data, surge_cols)\n",
        "surge_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9NmcW1EtTm8",
        "outputId": "ad16ce37-9db9-4c97-d8a4-d705ae242190"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------------+\n",
            "|     city|surge_multiplier|\n",
            "+---------+----------------+\n",
            "|Hyderabad|             1.2|\n",
            "|    Delhi|             1.5|\n",
            "|   Mumbai|             1.8|\n",
            "|Bangalore|             1.3|\n",
            "+---------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EXERCISE SET 1 — TRANSFORMATIONS vs ACTIONS\n",
        "###Exercise 1.1\n",
        "\n",
        "Create a transformation pipeline that:\n",
        "\n",
        "*   Filters only Completed rides\n",
        "*   Selects ride_id , city , distance_km\n"
      ],
      "metadata": {
        "id": "ZMvq4-I3ttjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_df = (\n",
        "    rides_df\n",
        "    .filter(col(\"status\") == \"Completed\")\n",
        "    .select(\"ride_id\",\"city\",\"distance_km\")\n",
        ")"
      ],
      "metadata": {
        "id": "KU37zxdBuX26"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exercise 1.2\n",
        "\n",
        "Trigger a single action on the pipeline.\n",
        "Tasks:\n",
        "\n",
        "\n",
        "*   Identify which line caused execution\n",
        "*   Explain why previous lines did not execute\n"
      ],
      "metadata": {
        "id": "f22p1tC1uj_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQRrS0_yxOHE",
        "outputId": "1f2c448a-91d8-47a4-fe40-423844f7d137"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+-----------+\n",
            "|ride_id|     city|distance_km|\n",
            "+-------+---------+-----------+\n",
            "|   R001|Hyderabad|       12.5|\n",
            "|   R002|    Delhi|        8.2|\n",
            "|   R004|Bangalore|        5.5|\n",
            "|   R005|Hyderabad|       20.0|\n",
            "|   R006|    Delhi|       25.0|\n",
            "|   R007|   Mumbai|        7.5|\n",
            "|   R008|Bangalore|       18.0|\n",
            "|   R010|Hyderabad|       10.0|\n",
            "+-------+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_df.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMfb2vy88Thq",
        "outputId": "e4adf3aa-c9d2-4c90-dbff-682de2ca65f0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Project ['ride_id, 'city, 'distance_km]\n",
            "+- Filter (status#5 = Completed)\n",
            "   +- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "ride_id: string, city: string, distance_km: double\n",
            "Project [ride_id#0, city#2, distance_km#3]\n",
            "+- Filter (status#5 = Completed)\n",
            "   +- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [ride_id#0, city#2, distance_km#3]\n",
            "+- Filter (isnotnull(status#5) AND (status#5 = Completed))\n",
            "   +- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "\n",
            "== Physical Plan ==\n",
            "*(1) Project [ride_id#0, city#2, distance_km#3]\n",
            "+- *(1) Filter (isnotnull(status#5) AND (status#5 = Completed))\n",
            "   +- *(1) Scan ExistingRDD[ride_id#0,user_id#1,city#2,distance_km#3,duration_seconds#4L,status#5]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EXERCISE SET 2 — DAG & LINEAGE"
      ],
      "metadata": {
        "id": "8wLtKI6Nv9EP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exercise 2.1\n",
        "\n",
        "Create a transformation chain with:\n",
        "\n",
        "*  Multiple filters\n",
        "*  A column selection\n",
        "\n",
        "Tasks:\n",
        "\n",
        "\n",
        "*  Run explain(True)\n",
        "*  Identify:\n",
        "    *  Logical plan\n",
        "    *  Optimized logical plan\n",
        "    *  Physical plan\n"
      ],
      "metadata": {
        "id": "nFtlOoiUxPRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dag_df = (\n",
        "    rides_df\n",
        "    .filter(col(\"status\") == \"Completed\")\n",
        "    .filter(col(\"distance_km\") > 10)\n",
        "    .select(\"ride_id\",\"city\",\"distance_km\")\n",
        ")\n",
        "\n",
        "dag_df.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRf-839tyYGA",
        "outputId": "efc1c17b-b584-4add-f065-e834ba09b479"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Project ['ride_id, 'city, 'distance_km]\n",
            "+- Filter (distance_km#3 > cast(10 as double))\n",
            "   +- Filter (status#5 = Completed)\n",
            "      +- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "ride_id: string, city: string, distance_km: double\n",
            "Project [ride_id#0, city#2, distance_km#3]\n",
            "+- Filter (distance_km#3 > cast(10 as double))\n",
            "   +- Filter (status#5 = Completed)\n",
            "      +- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [ride_id#0, city#2, distance_km#3]\n",
            "+- Filter ((isnotnull(status#5) AND isnotnull(distance_km#3)) AND ((status#5 = Completed) AND (distance_km#3 > 10.0)))\n",
            "   +- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "\n",
            "== Physical Plan ==\n",
            "*(1) Project [ride_id#0, city#2, distance_km#3]\n",
            "+- *(1) Filter ((isnotnull(status#5) AND isnotnull(distance_km#3)) AND ((status#5 = Completed) AND (distance_km#3 > 10.0)))\n",
            "   +- *(1) Scan ExistingRDD[ride_id#0,user_id#1,city#2,distance_km#3,duration_seconds#4L,status#5]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercise 2.2\n",
        "\n",
        "Reorder transformations (filter after join vs before join).\n",
        "\n",
        "Tasks:\n",
        "\n",
        "*   Compare DAGs\n",
        "*   Identify which plan is more efficient and why\n"
      ],
      "metadata": {
        "id": "RcjWzIKxyYpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bad_df = (\n",
        "    rides_df\n",
        "    .join(surge_df, \"city\")\n",
        "    .filter(col(\"distance_km\") > 10)\n",
        ")\n",
        "\n",
        "bad_df.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XOWptZYy4zl",
        "outputId": "6d514b74-f2a3-4e97-d28f-9963cad6740e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Filter '`>`('distance_km, 10)\n",
            "+- Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#28]\n",
            "   +- Join Inner, (city#2 = city#27)\n",
            "      :- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "      +- LogicalRDD [city#27, surge_multiplier#28], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "city: string, ride_id: string, user_id: string, distance_km: double, duration_seconds: bigint, status: string, surge_multiplier: double\n",
            "Filter (distance_km#3 > cast(10 as double))\n",
            "+- Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#28]\n",
            "   +- Join Inner, (city#2 = city#27)\n",
            "      :- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "      +- LogicalRDD [city#27, surge_multiplier#28], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#28]\n",
            "+- Join Inner, (city#2 = city#27)\n",
            "   :- Filter ((isnotnull(distance_km#3) AND (distance_km#3 > 10.0)) AND isnotnull(city#2))\n",
            "   :  +- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "   +- Filter isnotnull(city#27)\n",
            "      +- LogicalRDD [city#27, surge_multiplier#28], false\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#28]\n",
            "   +- SortMergeJoin [city#2], [city#27], Inner\n",
            "      :- Sort [city#2 ASC NULLS FIRST], false, 0\n",
            "      :  +- Exchange hashpartitioning(city#2, 200), ENSURE_REQUIREMENTS, [plan_id=89]\n",
            "      :     +- Filter ((isnotnull(distance_km#3) AND (distance_km#3 > 10.0)) AND isnotnull(city#2))\n",
            "      :        +- Scan ExistingRDD[ride_id#0,user_id#1,city#2,distance_km#3,duration_seconds#4L,status#5]\n",
            "      +- Sort [city#27 ASC NULLS FIRST], false, 0\n",
            "         +- Exchange hashpartitioning(city#27, 200), ENSURE_REQUIREMENTS, [plan_id=90]\n",
            "            +- Filter isnotnull(city#27)\n",
            "               +- Scan ExistingRDD[city#27,surge_multiplier#28]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "good_df = (\n",
        "    rides_df\n",
        "    .filter(col(\"distance_km\") > 10)\n",
        "    .join(surge_df, \"city\")\n",
        ")\n",
        "\n",
        "good_df.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yOcCVp58qbe",
        "outputId": "58a8a938-4a45-4952-ec6c-66a9a4079618"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Join UsingJoin(Inner, [city])\n",
            ":- Filter (distance_km#3 > cast(10 as double))\n",
            ":  +- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "+- LogicalRDD [city#27, surge_multiplier#28], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "city: string, ride_id: string, user_id: string, distance_km: double, duration_seconds: bigint, status: string, surge_multiplier: double\n",
            "Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#28]\n",
            "+- Join Inner, (city#2 = city#27)\n",
            "   :- Filter (distance_km#3 > cast(10 as double))\n",
            "   :  +- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "   +- LogicalRDD [city#27, surge_multiplier#28], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#28]\n",
            "+- Join Inner, (city#2 = city#27)\n",
            "   :- Filter ((isnotnull(distance_km#3) AND (distance_km#3 > 10.0)) AND isnotnull(city#2))\n",
            "   :  +- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "   +- Filter isnotnull(city#27)\n",
            "      +- LogicalRDD [city#27, surge_multiplier#28], false\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#28]\n",
            "   +- SortMergeJoin [city#2], [city#27], Inner\n",
            "      :- Sort [city#2 ASC NULLS FIRST], false, 0\n",
            "      :  +- Exchange hashpartitioning(city#2, 200), ENSURE_REQUIREMENTS, [plan_id=120]\n",
            "      :     +- Filter ((isnotnull(distance_km#3) AND (distance_km#3 > 10.0)) AND isnotnull(city#2))\n",
            "      :        +- Scan ExistingRDD[ride_id#0,user_id#1,city#2,distance_km#3,duration_seconds#4L,status#5]\n",
            "      +- Sort [city#27 ASC NULLS FIRST], false, 0\n",
            "         +- Exchange hashpartitioning(city#27, 200), ENSURE_REQUIREMENTS, [plan_id=121]\n",
            "            +- Filter isnotnull(city#27)\n",
            "               +- Scan ExistingRDD[city#27,surge_multiplier#28]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EXERCISE SET 3 — PARTITIONS & SHUFFLE"
      ],
      "metadata": {
        "id": "Ma9nEsMRwBMU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exercise 3.1\n",
        "\n",
        "Check the number of partitions of rides_df .\n",
        "Tasks:\n",
        "\n",
        "\n",
        "*  Repartition into 4 partitions\n",
        "*  Coalesce into 1 partition\n",
        "*  Observe number of output files when writing to Parquet\n"
      ],
      "metadata": {
        "id": "M1X6EQ8Jz8A8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rides_df.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80tbGSmB0e-s",
        "outputId": "a52f49f3-e4b2-4b6b-f663-2d47395df1ca"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "repart_df = rides_df.repartition(4)\n",
        "repart_df.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viUqgKDl8xuq",
        "outputId": "8cb0793f-4abc-4e72-da17-614b68eb27ea"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coal_df = rides_df.coalesce(1)\n",
        "coal_df.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YL7lMjm88fR",
        "outputId": "1edab94c-ebb3-452a-8761-bd96d77cc755"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coal_df.write.mode(\"overwrite\").parquet(\"/tmp/rides_single_file\")"
      ],
      "metadata": {
        "id": "hRyEgnev8-OC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exercise 3.2\n",
        "\n",
        "Repartition rides by city .\n",
        "\n",
        "Tasks:\n",
        "\n",
        "*  Run explain(True)\n",
        "*  Identify whether a shuffle is introduced\n"
      ],
      "metadata": {
        "id": "xasN4IHZ0fe5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "city_part_df = rides_df.repartition(\"city\")\n",
        "city_part_df.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vx5vay4p1Cxw",
        "outputId": "05e5d2b5-0c24-4d7e-a13a-7ab59f872a97"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'RepartitionByExpression ['city]\n",
            "+- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "ride_id: string, user_id: string, city: string, distance_km: double, duration_seconds: bigint, status: string\n",
            "RepartitionByExpression [city#2]\n",
            "+- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "RepartitionByExpression [city#2]\n",
            "+- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Exchange hashpartitioning(city#2, 200), REPARTITION_BY_COL, [plan_id=183]\n",
            "   +- Scan ExistingRDD[ride_id#0,user_id#1,city#2,distance_km#3,duration_seconds#4L,status#5]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EXERCISE SET 4 — JOIN WITHOUT BROADCAST (BAD DAG)"
      ],
      "metadata": {
        "id": "WsUJzu9AwGqc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 4.1\n",
        "\n",
        "Join rides_df with surge_df on city without using broadcast.\n",
        "\n",
        "Tasks:\n",
        "*  Run explain(True)\n",
        "*  Identify:\n",
        "    *  Join type\n",
        "    *  Exchange operators\n",
        "    *  Sort operations\n",
        "    *  Stage boundaries"
      ],
      "metadata": {
        "id": "nl9dFiC_1Dn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "join_df = rides_df.join(surge_df, \"city\")\n",
        "\n",
        "join_df.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gthZa27818-d",
        "outputId": "02017eb3-69bd-49e3-e43c-f14e8f488428"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Join UsingJoin(Inner, [city])\n",
            ":- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "+- LogicalRDD [city#27, surge_multiplier#28], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "city: string, ride_id: string, user_id: string, distance_km: double, duration_seconds: bigint, status: string, surge_multiplier: double\n",
            "Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#28]\n",
            "+- Join Inner, (city#2 = city#27)\n",
            "   :- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "   +- LogicalRDD [city#27, surge_multiplier#28], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#28]\n",
            "+- Join Inner, (city#2 = city#27)\n",
            "   :- Filter isnotnull(city#2)\n",
            "   :  +- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "   +- Filter isnotnull(city#27)\n",
            "      +- LogicalRDD [city#27, surge_multiplier#28], false\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#28]\n",
            "   +- SortMergeJoin [city#2], [city#27], Inner\n",
            "      :- Sort [city#2 ASC NULLS FIRST], false, 0\n",
            "      :  +- Exchange hashpartitioning(city#2, 200), ENSURE_REQUIREMENTS, [plan_id=210]\n",
            "      :     +- Filter isnotnull(city#2)\n",
            "      :        +- Scan ExistingRDD[ride_id#0,user_id#1,city#2,distance_km#3,duration_seconds#4L,status#5]\n",
            "      +- Sort [city#27 ASC NULLS FIRST], false, 0\n",
            "         +- Exchange hashpartitioning(city#27, 200), ENSURE_REQUIREMENTS, [plan_id=211]\n",
            "            +- Filter isnotnull(city#27)\n",
            "               +- Scan ExistingRDD[city#27,surge_multiplier#28]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exercise 4.2\n",
        "\n",
        "Apply a filter ( distance_km > 10 ) before the join.\n",
        "\n",
        "Tasks:\n",
        "\n",
        "*  Observe whether shuffle is removed\n",
        "*  Explain why or why not\n"
      ],
      "metadata": {
        "id": "025tJlNg1-Ky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_join_df = (\n",
        "    rides_df\n",
        "    .filter(col(\"distance_km\") > 10)\n",
        "    .join(surge_df, \"city\")\n",
        ")\n",
        "\n",
        "filtered_join_df.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sg9aPzak2jtK",
        "outputId": "31e69080-2ccd-432d-8e0b-1f87ee761b7b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Join UsingJoin(Inner, [city])\n",
            ":- Filter (distance_km#3 > cast(10 as double))\n",
            ":  +- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "+- LogicalRDD [city#27, surge_multiplier#28], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "city: string, ride_id: string, user_id: string, distance_km: double, duration_seconds: bigint, status: string, surge_multiplier: double\n",
            "Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#28]\n",
            "+- Join Inner, (city#2 = city#27)\n",
            "   :- Filter (distance_km#3 > cast(10 as double))\n",
            "   :  +- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "   +- LogicalRDD [city#27, surge_multiplier#28], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#28]\n",
            "+- Join Inner, (city#2 = city#27)\n",
            "   :- Filter ((isnotnull(distance_km#3) AND (distance_km#3 > 10.0)) AND isnotnull(city#2))\n",
            "   :  +- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "   +- Filter isnotnull(city#27)\n",
            "      +- LogicalRDD [city#27, surge_multiplier#28], false\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#28]\n",
            "   +- SortMergeJoin [city#2], [city#27], Inner\n",
            "      :- Sort [city#2 ASC NULLS FIRST], false, 0\n",
            "      :  +- Exchange hashpartitioning(city#2, 200), ENSURE_REQUIREMENTS, [plan_id=241]\n",
            "      :     +- Filter ((isnotnull(distance_km#3) AND (distance_km#3 > 10.0)) AND isnotnull(city#2))\n",
            "      :        +- Scan ExistingRDD[ride_id#0,user_id#1,city#2,distance_km#3,duration_seconds#4L,status#5]\n",
            "      +- Sort [city#27 ASC NULLS FIRST], false, 0\n",
            "         +- Exchange hashpartitioning(city#27, 200), ENSURE_REQUIREMENTS, [plan_id=242]\n",
            "            +- Filter isnotnull(city#27)\n",
            "               +- Scan ExistingRDD[city#27,surge_multiplier#28]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EXERCISE SET 5 — BROADCAST JOIN (GOOD DAG)"
      ],
      "metadata": {
        "id": "xgfTMlF3wMt0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exercise 5.1\n",
        "\n",
        "Apply a broadcast hint to surge_df .\n",
        "\n",
        "Tasks:\n",
        "*  Run explain(True)\n",
        "*  Identify:\n",
        "    *  Join type\n",
        "    *  BroadcastExchange\n",
        "    *  Disappearance of shuffles"
      ],
      "metadata": {
        "id": "GiuAKrzK2sgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import broadcast\n",
        "broadcast_join_df = rides_df.join(\n",
        "    broadcast(surge_df),\n",
        "    \"city\"\n",
        ")\n",
        "\n",
        "broadcast_join_df.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDJLOUZ_3aiT",
        "outputId": "7be8f226-8b76-44fc-da4f-64d20a5308db"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Join UsingJoin(Inner, [city])\n",
            ":- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "+- ResolvedHint (strategy=broadcast)\n",
            "   +- LogicalRDD [city#27, surge_multiplier#28], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "city: string, ride_id: string, user_id: string, distance_km: double, duration_seconds: bigint, status: string, surge_multiplier: double\n",
            "Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#28]\n",
            "+- Join Inner, (city#2 = city#27)\n",
            "   :- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "   +- ResolvedHint (strategy=broadcast)\n",
            "      +- LogicalRDD [city#27, surge_multiplier#28], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#28]\n",
            "+- Join Inner, (city#2 = city#27), rightHint=(strategy=broadcast)\n",
            "   :- Filter isnotnull(city#2)\n",
            "   :  +- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "   +- Filter isnotnull(city#27)\n",
            "      +- LogicalRDD [city#27, surge_multiplier#28], false\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#28]\n",
            "   +- BroadcastHashJoin [city#2], [city#27], Inner, BuildRight, false\n",
            "      :- Filter isnotnull(city#2)\n",
            "      :  +- Scan ExistingRDD[ride_id#0,user_id#1,city#2,distance_km#3,duration_seconds#4L,status#5]\n",
            "      +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=271]\n",
            "         +- Filter isnotnull(city#27)\n",
            "            +- Scan ExistingRDD[city#27,surge_multiplier#28]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exercise 5.2\n",
        "\n",
        "Compare physical plans from:\n",
        "\n",
        "*  Exercise 4.1\n",
        "*  Exercise 5.1\n",
        "\n",
        "Tasks:\n",
        "*   List operators that disappeared\n",
        "*   Explain performance impact\n"
      ],
      "metadata": {
        "id": "ag3tTs_L3bZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "join_df.explain(True)          # From 4.1\n",
        "broadcast_join_df.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfkT5pCz33tN",
        "outputId": "98818962-9b33-498f-badc-eff284d8f9f7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Join UsingJoin(Inner, [city])\n",
            ":- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "+- LogicalRDD [city#27, surge_multiplier#28], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "city: string, ride_id: string, user_id: string, distance_km: double, duration_seconds: bigint, status: string, surge_multiplier: double\n",
            "Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#28]\n",
            "+- Join Inner, (city#2 = city#27)\n",
            "   :- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "   +- LogicalRDD [city#27, surge_multiplier#28], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#28]\n",
            "+- Join Inner, (city#2 = city#27)\n",
            "   :- Filter isnotnull(city#2)\n",
            "   :  +- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "   +- Filter isnotnull(city#27)\n",
            "      +- LogicalRDD [city#27, surge_multiplier#28], false\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#28]\n",
            "   +- SortMergeJoin [city#2], [city#27], Inner\n",
            "      :- Sort [city#2 ASC NULLS FIRST], false, 0\n",
            "      :  +- Exchange hashpartitioning(city#2, 200), ENSURE_REQUIREMENTS, [plan_id=210]\n",
            "      :     +- Filter isnotnull(city#2)\n",
            "      :        +- Scan ExistingRDD[ride_id#0,user_id#1,city#2,distance_km#3,duration_seconds#4L,status#5]\n",
            "      +- Sort [city#27 ASC NULLS FIRST], false, 0\n",
            "         +- Exchange hashpartitioning(city#27, 200), ENSURE_REQUIREMENTS, [plan_id=211]\n",
            "            +- Filter isnotnull(city#27)\n",
            "               +- Scan ExistingRDD[city#27,surge_multiplier#28]\n",
            "\n",
            "== Parsed Logical Plan ==\n",
            "'Join UsingJoin(Inner, [city])\n",
            ":- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "+- ResolvedHint (strategy=broadcast)\n",
            "   +- LogicalRDD [city#27, surge_multiplier#28], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "city: string, ride_id: string, user_id: string, distance_km: double, duration_seconds: bigint, status: string, surge_multiplier: double\n",
            "Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#28]\n",
            "+- Join Inner, (city#2 = city#27)\n",
            "   :- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "   +- ResolvedHint (strategy=broadcast)\n",
            "      +- LogicalRDD [city#27, surge_multiplier#28], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#28]\n",
            "+- Join Inner, (city#2 = city#27), rightHint=(strategy=broadcast)\n",
            "   :- Filter isnotnull(city#2)\n",
            "   :  +- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "   +- Filter isnotnull(city#27)\n",
            "      +- LogicalRDD [city#27, surge_multiplier#28], false\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#28]\n",
            "   +- BroadcastHashJoin [city#2], [city#27], Inner, BuildRight, false\n",
            "      :- Filter isnotnull(city#2)\n",
            "      :  +- Scan ExistingRDD[ride_id#0,user_id#1,city#2,distance_km#3,duration_seconds#4L,status#5]\n",
            "      +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=271]\n",
            "         +- Filter isnotnull(city#27)\n",
            "            +- Scan ExistingRDD[city#27,surge_multiplier#28]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EXERCISE SET 6 — DAG INTERPRETATION"
      ],
      "metadata": {
        "id": "I2c6-XeHwW9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exercise 6.1\n",
        "\n",
        "From the physical plan:\n",
        "\n",
        "*  Identify all expensive operators\n",
        "*  Classify them as CPU, memory, or network heavy\n"
      ],
      "metadata": {
        "id": "PEaUgEzd39Jx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eNP2FaHs4H3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exercise 6.2\n",
        "\n",
        "Explain why Spark defaults to SortMergeJoin ."
      ],
      "metadata": {
        "id": "AlJkOC3c4Ifr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EXERCISE SET 7 — ACTION-DRIVEN EXECUTION"
      ],
      "metadata": {
        "id": "_AzMJ7XFwa4R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercise 7.1\n",
        "\n",
        "Create a long transformation pipeline without any action.\n",
        "\n",
        "Tasks:\n",
        "*   Explain what Spark has done so far\n",
        "\n"
      ],
      "metadata": {
        "id": "nzF2HC_Dwe2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "long_df = (\n",
        "    rides_df\n",
        "    .filter(col(\"status\") == \"Completed\")\n",
        "    .filter(col(\"distance_km\") > 5)\n",
        "    .join(broadcast(surge_df), \"city\")\n",
        "    .select(\"ride_id\",\"city\",\"distance_km\",\"surge_multiplier\")\n",
        ")"
      ],
      "metadata": {
        "id": "ucKC8sIy-c-c"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercise 7.2\n",
        "\n",
        "Trigger different actions ( count , show , write ) separately.\n",
        "\n",
        "Tasks:\n",
        "*  Observe whether Spark recomputes the DAG\n",
        "*  Explain behavior\n"
      ],
      "metadata": {
        "id": "IFWpP3-Fwxnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "long_df.count()\n",
        "long_df.show()\n",
        "long_df.write.mode(\"overwrite\").parquet(\"/tmp/final_rides\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSGf9bKjxICy",
        "outputId": "3cfd6006-daca-4004-e48d-80050908e8e2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+-----------+----------------+\n",
            "|ride_id|     city|distance_km|surge_multiplier|\n",
            "+-------+---------+-----------+----------------+\n",
            "|   R001|Hyderabad|       12.5|             1.2|\n",
            "|   R002|    Delhi|        8.2|             1.5|\n",
            "|   R004|Bangalore|        5.5|             1.3|\n",
            "|   R005|Hyderabad|       20.0|             1.2|\n",
            "|   R006|    Delhi|       25.0|             1.5|\n",
            "|   R007|   Mumbai|        7.5|             1.8|\n",
            "|   R008|Bangalore|       18.0|             1.3|\n",
            "|   R010|Hyderabad|       10.0|             1.2|\n",
            "+-------+---------+-----------+----------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}