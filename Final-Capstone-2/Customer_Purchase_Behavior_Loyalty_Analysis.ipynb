{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##CASE STUDY 2\n",
        "Title: Customer Purchase Behavior & Loyalty Analysis using PySpark\n",
        "\n",
        "A retail company wants to understand how customers behave across cities and product categories.\n",
        "\n",
        "They are not interested only in revenue, but in customer patterns:\n",
        "- Who are the high-value customers?\n",
        "- Which customers are loyal?\n",
        "- Which cities have repeat buyers?\n",
        "- Which categories drive long-term engagement?"
      ],
      "metadata": {
        "id": "fFoEIMuGzQ7s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qWnXB49sK-PT"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.window import Window"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"Capstone Two\").getOrCreate()"
      ],
      "metadata": {
        "id": "f34rIx8luGjg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC7zBSmvua8u",
        "outputId": "862035e5-76be-4205-d639-b8087b5eb8b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path =\"/content/drive/MyDrive/Colab Notebooks/orders.csv\""
      ],
      "metadata": {
        "id": "uy10i4TFupX3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PHASE 1 – Ingestion & Cleaning"
      ],
      "metadata": {
        "id": "wZGGA-Dr0k5A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Read orders.csv as all StringType."
      ],
      "metadata": {
        "id": "WtIGUCrV0oJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_df = (spark.read\n",
        "    .option(\"header\", \"true\")\n",
        "    .option(\"inferSchema\", \"false\")\n",
        "    .csv(csv_path)\n",
        ")"
      ],
      "metadata": {
        "id": "x0-vtBWUuf5i"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Trim text columns."
      ],
      "metadata": {
        "id": "pWjw1a-E03Ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean_text = raw_df.withColumn(\"city_clean\", trim(col(\"city\")))\\\n",
        ".withColumn(\"category_clean\", trim(col(\"category\")))\\\n",
        ".withColumn(\"product_clean\", trim(col(\"product\")))\n",
        "df_clean_text.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPZ7JBOzvis6",
        "outputId": "916da140-d142-4d1c-ef17-b9442e7e4c9f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+-----------+-----------+-----------+-------+----------+---------+----------+--------------+-------------+\n",
            "|   order_id|customer_id|       city|   category|    product| amount|order_date|   status|city_clean|category_clean|product_clean|\n",
            "+-----------+-----------+-----------+-----------+-----------+-------+----------+---------+----------+--------------+-------------+\n",
            "|ORD00000000|    C000000| hyderabad |   grocery |       Oil |invalid|01/01/2024|Cancelled| hyderabad|       grocery|          Oil|\n",
            "|ORD00000001|    C000001|       Pune|    Grocery|      Sugar|  35430|2024-01-02|Completed|      Pune|       Grocery|        Sugar|\n",
            "|ORD00000002|    C000002|       Pune|Electronics|     Mobile|  65358|2024-01-03|Completed|      Pune|   Electronics|       Mobile|\n",
            "|ORD00000003|    C000003|  Bangalore|Electronics|     Laptop|   5558|2024-01-04|Completed| Bangalore|   Electronics|       Laptop|\n",
            "|ORD00000004|    C000004|       Pune|       Home|AirPurifier|  33659|2024-01-05|Completed|      Pune|          Home|  AirPurifier|\n",
            "|ORD00000005|    C000005|      Delhi|    Fashion|      Jeans|   8521|2024-01-06|Completed|     Delhi|       Fashion|        Jeans|\n",
            "|ORD00000006|    C000006|      Delhi|    Grocery|      Sugar|  42383|2024-01-07|Completed|     Delhi|       Grocery|        Sugar|\n",
            "|ORD00000007|    C000007|       Pune|    Grocery|       Rice|  45362|2024-01-08|Completed|      Pune|       Grocery|         Rice|\n",
            "|ORD00000008|    C000008|  Bangalore|    Fashion|      Jeans|  10563|2024-01-09|Completed| Bangalore|       Fashion|        Jeans|\n",
            "|ORD00000009|    C000009|    Kolkata|Electronics|     Laptop|  63715|2024-01-10|Completed|   Kolkata|   Electronics|       Laptop|\n",
            "|ORD00000010|    C000010|  Bangalore|    Grocery|      Sugar|  66576|2024-01-11|Completed| Bangalore|       Grocery|        Sugar|\n",
            "|ORD00000011|    C000011|    Kolkata|Electronics|     Tablet|  50318|12/01/2024|Completed|   Kolkata|   Electronics|       Tablet|\n",
            "|ORD00000012|    C000012|  Bangalore|    Grocery|      Sugar|  84768|2024-01-13|Completed| Bangalore|       Grocery|        Sugar|\n",
            "|ORD00000013|    C000013|       Pune|    Fashion|     TShirt|  79121|2024/01/14|Completed|      Pune|       Fashion|       TShirt|\n",
            "|ORD00000014|    C000014|     Mumbai|Electronics|     Tablet|  79469|2024-01-15|Completed|    Mumbai|   Electronics|       Tablet|\n",
            "|ORD00000015|    C000015|       Pune|Electronics|     Mobile|  81018|2024-01-16|Completed|      Pune|   Electronics|       Mobile|\n",
            "|ORD00000016|    C000016|     Mumbai|       Home|      Mixer|  64225|2024-01-17|Completed|    Mumbai|          Home|        Mixer|\n",
            "|ORD00000017|    C000017| bangalore |    Grocery|        Oil|  69582|2024-01-18|Completed| bangalore|       Grocery|          Oil|\n",
            "|ORD00000018|    C000018|    Kolkata|    Fashion|      Jeans|  50424|2024-01-19|Completed|   Kolkata|       Fashion|        Jeans|\n",
            "|ORD00000019|    C000019|     Mumbai|Electronics|     Mobile|invalid|2024-01-20|Completed|    Mumbai|   Electronics|       Mobile|\n",
            "+-----------+-----------+-----------+-----------+-----------+-------+----------+---------+----------+--------------+-------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Normalize city, category, product."
      ],
      "metadata": {
        "id": "mn3zhENd07BL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean_text = df_clean_text.withColumn(\"city_clean\", lower(col(\"city_clean\"))) \\\n",
        "    .withColumn(\"category_clean\", lower(col(\"category_clean\"))) \\\n",
        "    .withColumn(\"product_clean\", lower(col(\"product_clean\")))\n",
        "df_clean_text.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUdXmcAowEAh",
        "outputId": "afeb3b5f-7621-43e1-bdc6-2e67832969c8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+-----------+-----------+-----------+-------+----------+---------+----------+--------------+-------------+\n",
            "|   order_id|customer_id|       city|   category|    product| amount|order_date|   status|city_clean|category_clean|product_clean|\n",
            "+-----------+-----------+-----------+-----------+-----------+-------+----------+---------+----------+--------------+-------------+\n",
            "|ORD00000000|    C000000| hyderabad |   grocery |       Oil |invalid|01/01/2024|Cancelled| hyderabad|       grocery|          oil|\n",
            "|ORD00000001|    C000001|       Pune|    Grocery|      Sugar|  35430|2024-01-02|Completed|      pune|       grocery|        sugar|\n",
            "|ORD00000002|    C000002|       Pune|Electronics|     Mobile|  65358|2024-01-03|Completed|      pune|   electronics|       mobile|\n",
            "|ORD00000003|    C000003|  Bangalore|Electronics|     Laptop|   5558|2024-01-04|Completed| bangalore|   electronics|       laptop|\n",
            "|ORD00000004|    C000004|       Pune|       Home|AirPurifier|  33659|2024-01-05|Completed|      pune|          home|  airpurifier|\n",
            "|ORD00000005|    C000005|      Delhi|    Fashion|      Jeans|   8521|2024-01-06|Completed|     delhi|       fashion|        jeans|\n",
            "|ORD00000006|    C000006|      Delhi|    Grocery|      Sugar|  42383|2024-01-07|Completed|     delhi|       grocery|        sugar|\n",
            "|ORD00000007|    C000007|       Pune|    Grocery|       Rice|  45362|2024-01-08|Completed|      pune|       grocery|         rice|\n",
            "|ORD00000008|    C000008|  Bangalore|    Fashion|      Jeans|  10563|2024-01-09|Completed| bangalore|       fashion|        jeans|\n",
            "|ORD00000009|    C000009|    Kolkata|Electronics|     Laptop|  63715|2024-01-10|Completed|   kolkata|   electronics|       laptop|\n",
            "|ORD00000010|    C000010|  Bangalore|    Grocery|      Sugar|  66576|2024-01-11|Completed| bangalore|       grocery|        sugar|\n",
            "|ORD00000011|    C000011|    Kolkata|Electronics|     Tablet|  50318|12/01/2024|Completed|   kolkata|   electronics|       tablet|\n",
            "|ORD00000012|    C000012|  Bangalore|    Grocery|      Sugar|  84768|2024-01-13|Completed| bangalore|       grocery|        sugar|\n",
            "|ORD00000013|    C000013|       Pune|    Fashion|     TShirt|  79121|2024/01/14|Completed|      pune|       fashion|       tshirt|\n",
            "|ORD00000014|    C000014|     Mumbai|Electronics|     Tablet|  79469|2024-01-15|Completed|    mumbai|   electronics|       tablet|\n",
            "|ORD00000015|    C000015|       Pune|Electronics|     Mobile|  81018|2024-01-16|Completed|      pune|   electronics|       mobile|\n",
            "|ORD00000016|    C000016|     Mumbai|       Home|      Mixer|  64225|2024-01-17|Completed|    mumbai|          home|        mixer|\n",
            "|ORD00000017|    C000017| bangalore |    Grocery|        Oil|  69582|2024-01-18|Completed| bangalore|       grocery|          oil|\n",
            "|ORD00000018|    C000018|    Kolkata|    Fashion|      Jeans|  50424|2024-01-19|Completed|   kolkata|       fashion|        jeans|\n",
            "|ORD00000019|    C000019|     Mumbai|Electronics|     Mobile|invalid|2024-01-20|Completed|    mumbai|   electronics|       mobile|\n",
            "+-----------+-----------+-----------+-----------+-----------+-------+----------+---------+----------+--------------+-------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Clean amount:\n",
        "- Remove commas\n",
        "- Convert to IntegerType\n",
        "- Handle invalid values safely."
      ],
      "metadata": {
        "id": "nHBQWnS_0-iz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_amount_clean = df_clean_text.withColumn(\"amount_clean\", regexp_replace(col(\"amount\"), \",\", \"\"))\\\n",
        ".withColumn(\"amount_clean\",\n",
        "    when(col(\"amount_clean\").rlike(\"^[0-9]+$\"), col(\"amount_clean\").cast(IntegerType()))\\\n",
        "    .otherwise(None)\n",
        ")\n",
        "df_amount_clean.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLOlVe-KwO70",
        "outputId": "d0e2dcf9-6362-44b9-8a2f-b93be104f396"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+-----------+-----------+-----------+-------+----------+---------+----------+--------------+-------------+------------+\n",
            "|   order_id|customer_id|       city|   category|    product| amount|order_date|   status|city_clean|category_clean|product_clean|amount_clean|\n",
            "+-----------+-----------+-----------+-----------+-----------+-------+----------+---------+----------+--------------+-------------+------------+\n",
            "|ORD00000000|    C000000| hyderabad |   grocery |       Oil |invalid|01/01/2024|Cancelled| hyderabad|       grocery|          oil|        NULL|\n",
            "|ORD00000001|    C000001|       Pune|    Grocery|      Sugar|  35430|2024-01-02|Completed|      pune|       grocery|        sugar|       35430|\n",
            "|ORD00000002|    C000002|       Pune|Electronics|     Mobile|  65358|2024-01-03|Completed|      pune|   electronics|       mobile|       65358|\n",
            "|ORD00000003|    C000003|  Bangalore|Electronics|     Laptop|   5558|2024-01-04|Completed| bangalore|   electronics|       laptop|        5558|\n",
            "|ORD00000004|    C000004|       Pune|       Home|AirPurifier|  33659|2024-01-05|Completed|      pune|          home|  airpurifier|       33659|\n",
            "+-----------+-----------+-----------+-----------+-----------+-------+----------+---------+----------+--------------+-------------+------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Parse order_date into DateType → order_date_clean ."
      ],
      "metadata": {
        "id": "aHRQ1xVx1RBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_date_clean = df_amount_clean.withColumn(\"order_date_clean\",coalesce(\n",
        "    try_to_timestamp(col(\"order_date\"), lit(\"yyyy-MM-dd\")).cast(DateType()),\n",
        "    try_to_timestamp(col(\"order_date\"), lit(\"dd/MM/yyyy\")).cast(DateType()),\n",
        "    try_to_timestamp(col(\"order_date\"), lit(\"yyyy/MM/dd\")).cast(DateType())\n",
        "))\n",
        "df_date_clean.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSlX2cIGwY8C",
        "outputId": "e2261d80-ccb4-4eef-f5a2-2ca9a0380c6a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+-----------+-----------+-----------+-------+----------+---------+----------+--------------+-------------+------------+----------------+\n",
            "|   order_id|customer_id|       city|   category|    product| amount|order_date|   status|city_clean|category_clean|product_clean|amount_clean|order_date_clean|\n",
            "+-----------+-----------+-----------+-----------+-----------+-------+----------+---------+----------+--------------+-------------+------------+----------------+\n",
            "|ORD00000000|    C000000| hyderabad |   grocery |       Oil |invalid|01/01/2024|Cancelled| hyderabad|       grocery|          oil|        NULL|      2024-01-01|\n",
            "|ORD00000001|    C000001|       Pune|    Grocery|      Sugar|  35430|2024-01-02|Completed|      pune|       grocery|        sugar|       35430|      2024-01-02|\n",
            "|ORD00000002|    C000002|       Pune|Electronics|     Mobile|  65358|2024-01-03|Completed|      pune|   electronics|       mobile|       65358|      2024-01-03|\n",
            "|ORD00000003|    C000003|  Bangalore|Electronics|     Laptop|   5558|2024-01-04|Completed| bangalore|   electronics|       laptop|        5558|      2024-01-04|\n",
            "|ORD00000004|    C000004|       Pune|       Home|AirPurifier|  33659|2024-01-05|Completed|      pune|          home|  airpurifier|       33659|      2024-01-05|\n",
            "+-----------+-----------+-----------+-----------+-----------+-------+----------+---------+----------+--------------+-------------+------------+----------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Remove duplicate order_id."
      ],
      "metadata": {
        "id": "GEuYL1r31irX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_deduped = df_date_clean.groupBy(\"order_id\").count().filter(col(\"count\") > 1)\n",
        "df_deduped.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hF2k9wawn-I",
        "outputId": "c46ec378-54d2-4690-822b-b5de552944bc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+\n",
            "|order_id|count|\n",
            "+--------+-----+\n",
            "+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Keep only Completed orders."
      ],
      "metadata": {
        "id": "XcaXhrMX1kll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean_orders = df_date_clean.filter(col(\"status\") == \"Completed\").dropDuplicates([\"order_id\"])\n",
        "df_clean_orders.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfmQcvXrwy9v",
        "outputId": "34c252d5-8b54-42ff-bb61-b06251bac344"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+---------+-----------+-------+------+----------+---------+----------+--------------+-------------+------------+----------------+\n",
            "|   order_id|customer_id|     city|   category|product|amount|order_date|   status|city_clean|category_clean|product_clean|amount_clean|order_date_clean|\n",
            "+-----------+-----------+---------+-----------+-------+------+----------+---------+----------+--------------+-------------+------------+----------------+\n",
            "|ORD00000001|    C000001|     Pune|    Grocery|  Sugar| 35430|2024-01-02|Completed|      pune|       grocery|        sugar|       35430|      2024-01-02|\n",
            "|ORD00000007|    C000007|     Pune|    Grocery|   Rice| 45362|2024-01-08|Completed|      pune|       grocery|         rice|       45362|      2024-01-08|\n",
            "|ORD00000008|    C000008|Bangalore|    Fashion|  Jeans| 10563|2024-01-09|Completed| bangalore|       fashion|        jeans|       10563|      2024-01-09|\n",
            "|ORD00000010|    C000010|Bangalore|    Grocery|  Sugar| 66576|2024-01-11|Completed| bangalore|       grocery|        sugar|       66576|      2024-01-11|\n",
            "|ORD00000011|    C000011|  Kolkata|Electronics| Tablet| 50318|12/01/2024|Completed|   kolkata|   electronics|       tablet|       50318|      2024-01-12|\n",
            "+-----------+-----------+---------+-----------+-------+------+----------+---------+----------+--------------+-------------+------------+----------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PHASE 2 – Customer Metrics"
      ],
      "metadata": {
        "id": "okxntiVc1qOD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Total number of orders"
      ],
      "metadata": {
        "id": "vZwtVSS53QLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_orders = df_clean_orders.count()\n",
        "print(f\"Total number of orders: {total_orders}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9ZyJmswy5IN",
        "outputId": "d607309c-1434-43b0-8216-296856f7e75f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of orders: 285000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Total spending."
      ],
      "metadata": {
        "id": "6s0SIos482YG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_spending = df_clean_orders.select(sum(col(\"amount_clean\"))).collect()[0][0]\n",
        "print(f\"Total spending: {total_spending}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8jOojz0zDD7",
        "outputId": "554abfc4-7bd2-4f91-dc21-9d4363bf5d44"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total spending: 11436490724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Average order value."
      ],
      "metadata": {
        "id": "lyI9MbQB86oT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "average_order_value = total_spending / total_orders\n",
        "print(f\"Average order value: {average_order_value:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeKILulYzlVD",
        "outputId": "0fa1e1ca-f94a-4aec-a5c1-717e3da6f59b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average order value: 40128.04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. First purchase date."
      ],
      "metadata": {
        "id": "DsjbMcJY8-nS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_purchase_date = df_clean_orders.select(min(col(\"order_date_clean\"))).collect()[0][0]\n",
        "print(f\"First purchase date: {first_purchase_date}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceL37uwkzsJ2",
        "outputId": "510b3181-d4ed-4e3c-94f6-742322be99e4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First purchase date: 2024-01-02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Last purchase date."
      ],
      "metadata": {
        "id": "50KFEony9ArE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "last_purchase_date = df_clean_orders.select(max(col(\"order_date_clean\"))).collect()[0][0]\n",
        "print(f\"Last purchase date: {last_purchase_date}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB1LoC8fz11o",
        "outputId": "bd51c5fc-25ed-43f9-e2f4-7c6ec88dc0dc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last purchase date: 2024-02-29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 6. Number of distinct cities ordered from."
      ],
      "metadata": {
        "id": "QRPVj5-i9G_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distinct_cities = df_clean_orders.select(\"city_clean\").distinct().count()\n",
        "print(f\"Number of distinct cities ordered from: {distinct_cities}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rgraurzd0E6x",
        "outputId": "81f4e116-4dd2-4697-c5bf-48eb34323f66"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of distinct cities ordered from: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Number of distinct categories ordered from."
      ],
      "metadata": {
        "id": "E3hsuL-29J-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distinct_categories = df_clean_orders.select(\"category_clean\").distinct().count()\n",
        "print(f\"Number of distinct categories ordered from: {distinct_categories}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKuyFiRC0N9V",
        "outputId": "bd78170d-0675-481d-95e8-0a123345ddd8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of distinct categories ordered from: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PHASE 3 – Customer Segmentation"
      ],
      "metadata": {
        "id": "jza1GuBK9UNg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create customer segments using business logic:\n",
        "\n",
        "Total Spend >= 200000 AND Orders >= 5  → \"VIP\"\n",
        "\n",
        "Total Spend >= 100000                  → \"Premium\"\n",
        "\n",
        "Else                                   → \"Regular\"\n",
        "\n",
        "Add a column:\n",
        "\n",
        "customer_segment\n",
        "\n",
        "Count customers in each segment."
      ],
      "metadata": {
        "id": "c0RQ6FhV9Ybs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customer_metrics = df_clean_orders.groupBy(\"customer_id\").agg(\n",
        "    sum(\"amount_clean\").alias(\"total_spend\"),\n",
        "    count(\"order_id\").alias(\"total_orders\")\n",
        ")\n",
        "\n",
        "customer_segments = customer_metrics.withColumn(\"customer_segment\",\n",
        "    when((col(\"total_spend\") >= 200000) & (col(\"total_orders\") >= 5), \"VIP\")\n",
        "    .when(col(\"total_spend\") >= 100000, \"Premium\")\n",
        "    .otherwise(\"Regular\")\n",
        ")\n",
        "\n",
        "print(\"Customer segments and their counts:\")\n",
        "customer_segments.groupBy(\"customer_segment\").count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-C4pyU40biq",
        "outputId": "52ccddad-d302-48f6-f4a7-2bda79f37b39"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customer segments and their counts:\n",
            "+----------------+-----+\n",
            "|customer_segment|count|\n",
            "+----------------+-----+\n",
            "|         Premium|12485|\n",
            "|         Regular|  623|\n",
            "|             VIP|34392|\n",
            "+----------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PHASE 4 – Window Functions"
      ],
      "metadata": {
        "id": "JNQ0ibjY9gYg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Rank customers by total spending (overall)."
      ],
      "metadata": {
        "id": "hVYGqRZK9vHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "window_spec_overall = Window.orderBy(col(\"total_spend\").desc())\n",
        "\n",
        "customer_ranking_overall = customer_metrics.withColumn(\"overall_rank\", dense_rank().over(window_spec_overall))\n",
        "\n",
        "print(\"Customers ranked by total spending (overall):\")\n",
        "customer_ranking_overall.orderBy(\"overall_rank\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0TnToan0u4e",
        "outputId": "396e68d2-295e-4b06-9f2a-418141debee6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customers ranked by total spending (overall):\n",
            "+-----------+-----------+------------+------------+\n",
            "|customer_id|total_spend|total_orders|overall_rank|\n",
            "+-----------+-----------+------------+------------+\n",
            "|    C043076|     493949|           6|           1|\n",
            "|    C034689|     486879|           6|           2|\n",
            "|    C039985|     484057|           6|           3|\n",
            "|    C026691|     477147|           6|           4|\n",
            "|    C038979|     477138|           6|           5|\n",
            "|    C020762|     474717|           6|           6|\n",
            "|    C044654|     471304|           6|           7|\n",
            "|    C014292|     468617|           6|           8|\n",
            "|    C019565|     467523|           6|           9|\n",
            "|    C045487|     467050|           6|          10|\n",
            "+-----------+-----------+------------+------------+\n",
            "only showing top 10 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Rank customers inside each city by total spending."
      ],
      "metadata": {
        "id": "DX4flk9k9y-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customer_city_metrics = df_clean_orders.groupBy(\"customer_id\", \"city_clean\").agg(\n",
        "    sum(\"amount_clean\").alias(\"total_spend\"),\n",
        "    count(\"order_id\").alias(\"total_orders\")\n",
        ")\n",
        "\n",
        "window_spec_city = Window.partitionBy(\"city_clean\").orderBy(col(\"total_spend\").desc())\n",
        "\n",
        "customer_ranking_city = customer_city_metrics.withColumn(\"city_rank\", dense_rank().over(window_spec_city))\n",
        "\n",
        "print(\"Customers ranked by total spending within each city:\")\n",
        "customer_ranking_city.orderBy(\"city_clean\", \"city_rank\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbz9znQ-06Tv",
        "outputId": "54d5ec38-a783-4da8-bad4-b689d8103ace"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customers ranked by total spending within each city:\n",
            "+-----------+----------+-----------+------------+---------+\n",
            "|customer_id|city_clean|total_spend|total_orders|city_rank|\n",
            "+-----------+----------+-----------+------------+---------+\n",
            "|    C011518| bangalore|     332527|           5|        1|\n",
            "|    C024935| bangalore|     315622|           4|        2|\n",
            "|    C025451| bangalore|     303208|           4|        3|\n",
            "|    C008486| bangalore|     300843|           5|        4|\n",
            "|    C039191| bangalore|     294970|           4|        5|\n",
            "|    C006114| bangalore|     290915|           4|        6|\n",
            "|    C029163| bangalore|     286115|           4|        7|\n",
            "|    C028773| bangalore|     285105|           4|        8|\n",
            "|    C045363| bangalore|     283538|           4|        9|\n",
            "|    C043646| bangalore|     272357|           4|       10|\n",
            "+-----------+----------+-----------+------------+---------+\n",
            "only showing top 10 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Identify top 3 customers per city."
      ],
      "metadata": {
        "id": "Jh517XeE-hf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_3_customers_per_city = customer_ranking_city.filter(col(\"city_rank\") <= 3)\n",
        "\n",
        "print(\"Top 3 customers per city:\")\n",
        "top_3_customers_per_city.orderBy(\"city_clean\", \"city_rank\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lJUtqDT1IEn",
        "outputId": "ecad398f-b02d-4ee5-9ee4-2fbcea3ecf90"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 customers per city:\n",
            "+-----------+----------+-----------+------------+---------+\n",
            "|customer_id|city_clean|total_spend|total_orders|city_rank|\n",
            "+-----------+----------+-----------+------------+---------+\n",
            "|    C011518| bangalore|     332527|           5|        1|\n",
            "|    C024935| bangalore|     315622|           4|        2|\n",
            "|    C025451| bangalore|     303208|           4|        3|\n",
            "|    C028121|   chennai|     340890|           5|        1|\n",
            "|    C027841|   chennai|     287392|           5|        2|\n",
            "|    C030712|   chennai|     284466|           4|        3|\n",
            "|    C016309|     delhi|     325001|           5|        1|\n",
            "|    C022599|     delhi|     314625|           4|        2|\n",
            "|    C018688|     delhi|     306692|           4|        3|\n",
            "|    C032833| hyderabad|     318097|           5|        1|\n",
            "|    C023269| hyderabad|     292791|           5|        2|\n",
            "|    C013263| hyderabad|     291679|           4|        3|\n",
            "|    C032246|   kolkata|     304480|           4|        1|\n",
            "|    C022131|   kolkata|     296888|           5|        2|\n",
            "|    C028450|   kolkata|     296653|           4|        3|\n",
            "|    C048696|    mumbai|     334732|           6|        1|\n",
            "|    C047887|    mumbai|     307401|           4|        2|\n",
            "|    C022721|    mumbai|     306800|           4|        3|\n",
            "|    C002564|      pune|     315172|           5|        1|\n",
            "|    C023148|      pune|     310061|           4|        2|\n",
            "+-----------+----------+-----------+------------+---------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Identify top 10 customers across all cities."
      ],
      "metadata": {
        "id": "APubyyhh-lDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "window_spec_global = Window.partitionBy(lit(1)).orderBy(col(\"total_spend\").desc())\n",
        "\n",
        "top_10_customers_overall = customer_metrics.withColumn(\"global_rank\", dense_rank().over(window_spec_global))\n",
        "\n",
        "print(\"Top 10 customers across all cities:\")\n",
        "top_10_customers_overall.filter(col(\"global_rank\") <= 10).orderBy(\"global_rank\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCDSXbKs1TM4",
        "outputId": "21bd4766-19e6-4ede-dba7-834a457b321c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 customers across all cities:\n",
            "+-----------+-----------+------------+-----------+\n",
            "|customer_id|total_spend|total_orders|global_rank|\n",
            "+-----------+-----------+------------+-----------+\n",
            "|    C043076|     493949|           6|          1|\n",
            "|    C034689|     486879|           6|          2|\n",
            "|    C039985|     484057|           6|          3|\n",
            "|    C026691|     477147|           6|          4|\n",
            "|    C038979|     477138|           6|          5|\n",
            "|    C020762|     474717|           6|          6|\n",
            "|    C044654|     471304|           6|          7|\n",
            "|    C014292|     468617|           6|          8|\n",
            "|    C019565|     467523|           6|          9|\n",
            "|    C045487|     467050|           6|         10|\n",
            "+-----------+-----------+------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PHASE 5 – Customer Loyalty Analysis"
      ],
      "metadata": {
        "id": "WIjdSrRw-pqB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A loyal customer is one who:\n",
        "- Has purchases on at least 3 different dates\n",
        "- Has ordered from at least 2 different categories"
      ],
      "metadata": {
        "id": "Q02Vb_0d-tzB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Identify loyal customers"
      ],
      "metadata": {
        "id": "NMk00zh_-3tA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import countDistinct, col\n",
        "\n",
        "customer_loyalty_metrics = df_clean_orders.groupBy(\"customer_id\").agg(\n",
        "    countDistinct(\"order_date_clean\").alias(\"distinct_purchase_dates\"),\n",
        "    countDistinct(\"category_clean\").alias(\"distinct_categories_ordered\")\n",
        ")\n",
        "\n",
        "loyal_customers = customer_loyalty_metrics.filter(\n",
        "    (col(\"distinct_purchase_dates\") >= 3) & (col(\"distinct_categories_ordered\") >= 2)\n",
        ")\n",
        "\n",
        "print(\"Loyal Customers:\")\n",
        "loyal_customers.show(5)\n",
        "print(f\"Total loyal customers: {loyal_customers.count()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHrvR-tV1gzZ",
        "outputId": "9eb60e58-779e-4bd1-9eef-146c9197b6b8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loyal Customers:\n",
            "+-----------+-----------------------+---------------------------+\n",
            "|customer_id|distinct_purchase_dates|distinct_categories_ordered|\n",
            "+-----------+-----------------------+---------------------------+\n",
            "|    C009896|                      3|                          3|\n",
            "|    C041802|                      3|                          4|\n",
            "|    C041216|                      3|                          3|\n",
            "|    C006517|                      3|                          3|\n",
            "|    C030828|                      3|                          3|\n",
            "+-----------+-----------------------+---------------------------+\n",
            "only showing top 5 rows\n",
            "Total loyal customers: 47439\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Count loyal customers per city."
      ],
      "metadata": {
        "id": "pBJeWFBe-8CZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customer_city_map = df_clean_orders.select(\"customer_id\", \"city_clean\").distinct()\n",
        "\n",
        "loyal_customers_with_city = loyal_customers.join(customer_city_map, \"customer_id\", \"inner\")\n",
        "\n",
        "loyal_customers_per_city = loyal_customers_with_city.groupBy(\"city_clean\").count().alias(\"loyal_customer_count\")\n",
        "\n",
        "print(\"Loyal Customers per City:\")\n",
        "loyal_customers_per_city.orderBy(col(\"count\").desc()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd-d4vay1zG-",
        "outputId": "676e32a6-9350-487e-cf9f-568cb3bacf73"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loyal Customers per City:\n",
            "+----------+-----+\n",
            "|city_clean|count|\n",
            "+----------+-----+\n",
            "| hyderabad|28827|\n",
            "|     delhi|28761|\n",
            "|      pune|28714|\n",
            "|   chennai|28669|\n",
            "|   kolkata|28581|\n",
            "|    mumbai|28532|\n",
            "| bangalore|28514|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Compare loyal vs non-loyal customer revenue contribution."
      ],
      "metadata": {
        "id": "5HUX_O79BnIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loyal_customer_ids = loyal_customers.select(\"customer_id\")\n",
        "\n",
        "revenue_loyal = customer_metrics.join(loyal_customer_ids, \"customer_id\", \"inner\")\\\n",
        "    .select(sum(\"total_spend\")).collect()[0][0]\n",
        "\n",
        "revenue_non_loyal = customer_metrics.join(loyal_customer_ids, \"customer_id\", \"left_anti\")\\\n",
        "    .select(sum(\"total_spend\")).collect()[0][0]\n",
        "\n",
        "print(f\"Total revenue from loyal customers: {revenue_loyal}\")\n",
        "print(f\"Total revenue from non-loyal customers: {revenue_non_loyal}\")\n",
        "print(f\"Difference (Loyal - Non-Loyal): {revenue_loyal - revenue_non_loyal}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJO_Osad2CLq",
        "outputId": "499a469b-6698-476e-c16d-06a5383efef3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total revenue from loyal customers: 11421590547\n",
            "Total revenue from non-loyal customers: 14900177\n",
            "Difference (Loyal - Non-Loyal): 11406690370\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PHASE 6 – Time-Based Analysis"
      ],
      "metadata": {
        "id": "2LoZjpghBsZW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Compute monthly revenue per city."
      ],
      "metadata": {
        "id": "a7hkbqYnBwLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_revenue_city = df_clean_orders.filter(col(\"order_date_clean\").isNotNull())\\\n",
        "    .withColumn(\"city_clean\", lower(col(\"city_clean\")))\\\n",
        "    .withColumn(\"order_month\", date_trunc(\"month\", col(\"order_date_clean\")))\\\n",
        "    .groupBy(\"order_month\", \"city_clean\").agg(sum(\"amount_clean\").alias(\"monthly_revenue\"))\n",
        "\n",
        "print(\"Monthly Revenue per City:\")\n",
        "monthly_revenue_city.orderBy(\"order_month\", col(\"monthly_revenue\").desc()).show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EuULVOE2R39",
        "outputId": "1f5cc350-da54-4077-bc8e-a40bcf21794b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Monthly Revenue per City:\n",
            "+-------------------+----------+---------------+\n",
            "|        order_month|city_clean|monthly_revenue|\n",
            "+-------------------+----------+---------------+\n",
            "|2024-01-01 00:00:00|      pune|      833507124|\n",
            "|2024-01-01 00:00:00| hyderabad|      833063605|\n",
            "|2024-01-01 00:00:00|   kolkata|      824920456|\n",
            "|2024-01-01 00:00:00| bangalore|      822339117|\n",
            "|2024-01-01 00:00:00|   chennai|      818567389|\n",
            "|2024-01-01 00:00:00|     delhi|      817332633|\n",
            "|2024-01-01 00:00:00|    mumbai|      816636150|\n",
            "|2024-02-01 00:00:00|     delhi|      805877007|\n",
            "|2024-02-01 00:00:00|      pune|      797779557|\n",
            "|2024-02-01 00:00:00|   chennai|      796361427|\n",
            "+-------------------+----------+---------------+\n",
            "only showing top 10 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Compute monthly order count per category."
      ],
      "metadata": {
        "id": "HNGgVKI2B0NP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_order_count_perctg = df_clean_orders.filter(col(\"order_date_clean\").isNotNull())\\\n",
        "    .withColumn(\"order_month\", date_trunc(\"month\", col(\"order_date_clean\")))\\\n",
        "    .withColumn(\"category_clean\", lower(col(\"category_clean\")))\\\n",
        "    .groupBy(\"order_month\", \"category_clean\").agg(count(\"order_id\").alias(\"monthly_order_count\"))\n",
        "\n",
        "print(\"Monthly Order Count per Category:\")\n",
        "monthly_order_count_perctg.orderBy(\"order_month\", col(\"monthly_order_count\").desc()).show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rl5uJl-12fNX",
        "outputId": "630e1a2b-6e2c-4b0b-9a5c-eab221d17e11"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Monthly Order Count per Category:\n",
            "+-------------------+--------------+-------------------+\n",
            "|        order_month|category_clean|monthly_order_count|\n",
            "+-------------------+--------------+-------------------+\n",
            "|2024-01-01 00:00:00|          home|              36163|\n",
            "|2024-01-01 00:00:00|       grocery|              36018|\n",
            "|2024-01-01 00:00:00|   electronics|              35994|\n",
            "|2024-01-01 00:00:00|       fashion|              35571|\n",
            "|2024-02-01 00:00:00|   electronics|              34766|\n",
            "|2024-02-01 00:00:00|       fashion|              34720|\n",
            "|2024-02-01 00:00:00|       grocery|              34672|\n",
            "|2024-02-01 00:00:00|          home|              34631|\n",
            "+-------------------+--------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Identify growth or decline trends."
      ],
      "metadata": {
        "id": "IGPcXs7_B4Q8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "window_spec_month_city = Window.partitionBy(\"city_clean\").orderBy(\"order_month\")\n",
        "\n",
        "revenue_trends = monthly_revenue_city.withColumn(\"previous_month_revenue\", lag(\"monthly_revenue\", 1).over(window_spec_month_city))\n",
        "\n",
        "revenue_trends = revenue_trends.withColumn(\"revenue_change_percent\",\n",
        "    when(col(\"previous_month_revenue\").isNotNull(),\n",
        "        (col(\"monthly_revenue\") - col(\"previous_month_revenue\")) / col(\"previous_month_revenue\") * 100\n",
        "    ).otherwise(None)\n",
        ")\n",
        "\n",
        "print(\"Monthly Revenue Growth/Decline Trends:\")\n",
        "revenue_trends.orderBy(\"city_clean\", \"order_month\").show()\n",
        "\n",
        "window_spec_month_category = Window.partitionBy(\"category_clean\").orderBy(\"order_month\")\n",
        "\n",
        "order_count_trends = monthly_order_count_perctg.withColumn(\"previous_month_orders\", lag(\"monthly_order_count\", 1).over(window_spec_month_category))\n",
        "\n",
        "order_count_trends = order_count_trends.withColumn(\"order_count_change_percent\",\n",
        "    when(col(\"previous_month_orders\").isNotNull(),\n",
        "        (col(\"monthly_order_count\") - col(\"previous_month_orders\")) / col(\"previous_month_orders\") * 100\n",
        "    ).otherwise(None)\n",
        ")\n",
        "\n",
        "print(\"\\nMonthly Order Count Growth/Decline Trends:\")\n",
        "order_count_trends.orderBy(\"category_clean\", \"order_month\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "go1g928m22mB",
        "outputId": "9a841357-03b7-48a7-fd7f-9e05a781234e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Monthly Revenue Growth/Decline Trends:\n",
            "+-------------------+----------+---------------+----------------------+----------------------+\n",
            "|        order_month|city_clean|monthly_revenue|previous_month_revenue|revenue_change_percent|\n",
            "+-------------------+----------+---------------+----------------------+----------------------+\n",
            "|2024-01-01 00:00:00| bangalore|      822339117|                  NULL|                  NULL|\n",
            "|2024-02-01 00:00:00| bangalore|      792163305|             822339117|   -3.6695094975033276|\n",
            "|2024-01-01 00:00:00|   chennai|      818567389|                  NULL|                  NULL|\n",
            "|2024-02-01 00:00:00|   chennai|      796361427|             818567389|   -2.7127836142028374|\n",
            "|2024-01-01 00:00:00|     delhi|      817332633|                  NULL|                  NULL|\n",
            "|2024-02-01 00:00:00|     delhi|      805877007|             817332633|   -1.4015867637576633|\n",
            "|2024-01-01 00:00:00| hyderabad|      833063605|                  NULL|                  NULL|\n",
            "|2024-02-01 00:00:00| hyderabad|      796252807|             833063605|    -4.418725986715024|\n",
            "|2024-01-01 00:00:00|   kolkata|      824920456|                  NULL|                  NULL|\n",
            "|2024-02-01 00:00:00|   kolkata|      785096186|             824920456|    -4.827649709780018|\n",
            "|2024-01-01 00:00:00|    mumbai|      816636150|                  NULL|                  NULL|\n",
            "|2024-02-01 00:00:00|    mumbai|      795736235|             816636150|   -2.5592688983949583|\n",
            "|2024-01-01 00:00:00|      pune|      833507124|                  NULL|                  NULL|\n",
            "|2024-02-01 00:00:00|      pune|      797779557|             833507124|    -4.286414113480331|\n",
            "+-------------------+----------+---------------+----------------------+----------------------+\n",
            "\n",
            "\n",
            "Monthly Order Count Growth/Decline Trends:\n",
            "+-------------------+--------------+-------------------+---------------------+--------------------------+\n",
            "|        order_month|category_clean|monthly_order_count|previous_month_orders|order_count_change_percent|\n",
            "+-------------------+--------------+-------------------+---------------------+--------------------------+\n",
            "|2024-01-01 00:00:00|   electronics|              35994|                 NULL|                      NULL|\n",
            "|2024-02-01 00:00:00|   electronics|              34766|                35994|        -3.411679724398511|\n",
            "|2024-01-01 00:00:00|       fashion|              35571|                 NULL|                      NULL|\n",
            "|2024-02-01 00:00:00|       fashion|              34720|                35571|        -2.392398301987574|\n",
            "|2024-01-01 00:00:00|       grocery|              36018|                 NULL|                      NULL|\n",
            "|2024-02-01 00:00:00|       grocery|              34672|                36018|        -3.737020378699539|\n",
            "|2024-01-01 00:00:00|          home|              36163|                 NULL|                      NULL|\n",
            "|2024-02-01 00:00:00|          home|              34631|                36163|        -4.236374194618809|\n",
            "+-------------------+--------------+-------------------+---------------------+--------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PHASE 7 – Performance Engineering"
      ],
      "metadata": {
        "id": "-1Z7Q1lWB9TA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Identify which DataFrames are reused."
      ],
      "metadata": {
        "id": "pb-5RKE9CAgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reused DataFrames:\n",
        "#- `df_clean_orders`: Used for various customer metrics, customer segmentation, loyalty analysis, and time-based analysis.\n",
        "#- `customer_metrics`: Used for customer segmentation, overall customer ranking, and loyal vs. non-loyal customer revenue comparison."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYqJQs1S3Ecy",
        "outputId": "7ddfef3f-7cbd-4a0f-ed7b-37b1b9da8a9b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reused DataFrames:\n",
            "- `df_clean_orders`: Used for various customer metrics, customer segmentation, loyalty analysis, and time-based analysis.\n",
            "- `customer_metrics`: Used for customer segmentation, overall customer ranking, and loyal vs. non-loyal customer revenue comparison.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Apply caching"
      ],
      "metadata": {
        "id": "RnCmphYeCGTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean_orders.cache()\n",
        "customer_metrics.cache()\n",
        "print(\"DataFrames `df_clean_orders` and `customer_metrics` have been cached.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwXbLuN13w4U",
        "outputId": "4614bb7b-5af8-47de-9aa9-5ef01c298e43"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrames `df_clean_orders` and `customer_metrics` have been cached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Use explain(True) on:\n",
        "- Customer aggregation\n",
        "- Window rankin"
      ],
      "metadata": {
        "id": "4K0z9SBwCITn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Execution plan for Customer Aggregation (customer_metrics):\")\n",
        "customer_metrics.explain(True)\n",
        "\n",
        "print(\"\\nExecution plan for Overall Window Ranking (customer_ranking_overall):\")\n",
        "customer_ranking_overall.explain(True)\n",
        "\n",
        "print(\"\\nExecution plan for City-wise Window Ranking (customer_ranking_city):\")\n",
        "customer_ranking_city.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iueg9NGT32oc",
        "outputId": "e06df020-5ccf-4639-df14-1a974c8ee822"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution plan for Customer Aggregation (customer_metrics):\n",
            "== Parsed Logical Plan ==\n",
            "'Aggregate ['customer_id], ['customer_id, 'sum('amount_clean) AS total_spend#970, 'count('order_id) AS total_orders#971]\n",
            "+- Deduplicate [order_id#17]\n",
            "   +- Filter (status#24 = Completed)\n",
            "      +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, amount_clean#117, coalesce(cast(try_to_timestamp(order_date#23, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false) as date)) AS order_date_clean#163]\n",
            "         +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, CASE WHEN RLIKE(amount_clean#116, ^[0-9]+$) THEN cast(amount_clean#116 as int) ELSE cast(null as int) END AS amount_clean#117]\n",
            "            +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, regexp_replace(amount#22, ,, , 1) AS amount_clean#116]\n",
            "               +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, lower(product_clean#28) AS product_clean#73]\n",
            "                  +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, lower(category_clean#27) AS category_clean#72, product_clean#28]\n",
            "                     +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, lower(city_clean#26) AS city_clean#71, category_clean#27, product_clean#28]\n",
            "                        +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#26, category_clean#27, trim(product#21, None) AS product_clean#28]\n",
            "                           +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#26, trim(category#20, None) AS category_clean#27]\n",
            "                              +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, trim(city#19, None) AS city_clean#26]\n",
            "                                 +- Relation [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] csv\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "customer_id: string, total_spend: bigint, total_orders: bigint\n",
            "Aggregate [customer_id#18], [customer_id#18, sum(amount_clean#117) AS total_spend#970L, count(order_id#17) AS total_orders#971L]\n",
            "+- Deduplicate [order_id#17]\n",
            "   +- Filter (status#24 = Completed)\n",
            "      +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, amount_clean#117, coalesce(cast(try_to_timestamp(order_date#23, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false) as date)) AS order_date_clean#163]\n",
            "         +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, CASE WHEN RLIKE(amount_clean#116, ^[0-9]+$) THEN cast(amount_clean#116 as int) ELSE cast(null as int) END AS amount_clean#117]\n",
            "            +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, regexp_replace(amount#22, ,, , 1) AS amount_clean#116]\n",
            "               +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, lower(product_clean#28) AS product_clean#73]\n",
            "                  +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, lower(category_clean#27) AS category_clean#72, product_clean#28]\n",
            "                     +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, lower(city_clean#26) AS city_clean#71, category_clean#27, product_clean#28]\n",
            "                        +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#26, category_clean#27, trim(product#21, None) AS product_clean#28]\n",
            "                           +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#26, trim(category#20, None) AS category_clean#27]\n",
            "                              +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, trim(city#19, None) AS city_clean#26]\n",
            "                                 +- Relation [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] csv\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "InMemoryRelation [customer_id#18, total_spend#970L, total_orders#971L], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "   +- AdaptiveSparkPlan isFinalPlan=false\n",
            "      +- HashAggregate(keys=[customer_id#18], functions=[sum(amount_clean#117), count(order_id#17)], output=[customer_id#18, total_spend#970L, total_orders#971L])\n",
            "         +- Exchange hashpartitioning(customer_id#18, 200), ENSURE_REQUIREMENTS, [plan_id=6382]\n",
            "            +- HashAggregate(keys=[customer_id#18], functions=[partial_sum(amount_clean#117), partial_count(order_id#17)], output=[customer_id#18, sum#2929L, count#1025L])\n",
            "               +- InMemoryTableScan [order_id#17, customer_id#18, amount_clean#117]\n",
            "                     +- InMemoryRelation [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, amount_clean#117, order_date_clean#163], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                           +- AdaptiveSparkPlan isFinalPlan=false\n",
            "                              +- SortAggregate(key=[order_id#17], functions=[first(customer_id#18, false), first(city#19, false), first(category#20, false), first(product#21, false), first(amount#22, false), first(order_date#23, false), first(status#24, false), first(city_clean#71, false), first(category_clean#72, false), first(product_clean#73, false), first(amount_clean#117, false), first(order_date_clean#163, false)], output=[order_id#17, customer_id#2597, city#2599, category#2601, product#2603, amount#2605, order_date#2607, status#2609, city_clean#2611, category_clean#2613, product_clean#2615, amount_clean#2617, order_date_clean#2619])\n",
            "                                 +- Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                                    +- Exchange hashpartitioning(order_id#17, 200), ENSURE_REQUIREMENTS, [plan_id=6368]\n",
            "                                       +- SortAggregate(key=[order_id#17], functions=[partial_first(customer_id#18, false), partial_first(city#19, false), partial_first(category#20, false), partial_first(product#21, false), partial_first(amount#22, false), partial_first(order_date#23, false), partial_first(status#24, false), partial_first(city_clean#71, false), partial_first(category_clean#72, false), partial_first(product_clean#73, false), partial_first(amount_clean#117, false), partial_first(order_date_clean#163, false)], output=[order_id#17, first#2644, valueSet#2645, first#2646, valueSet#2647, first#2648, valueSet#2649, first#2650, valueSet#2651, first#2652, valueSet#2653, first#2654, valueSet#2655, first#2656, valueSet#2657, first#2658, valueSet#2659, first#2660, valueSet#2661, first#2662, valueSet#2663, first#2664, valueSet#2665, first#2666, valueSet#2667])\n",
            "                                          +- Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                                             +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, CASE WHEN RLIKE(amount_clean#116, ^[0-9]+$) THEN cast(amount_clean#116 as int) END AS amount_clean#117, coalesce(cast(gettimestamp(order_date#23, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date_clean#163]\n",
            "                                                +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, lower(trim(city#19, None)) AS city_clean#71, lower(trim(category#20, None)) AS category_clean#72, lower(trim(product#21, None)) AS product_clean#73, regexp_replace(amount#22, ,, , 1) AS amount_clean#116]\n",
            "                                                   +- Filter (isnotnull(status#24) AND (status#24 = Completed))\n",
            "                                                      +- FileScan csv [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] Batched: false, DataFilters: [isnotnull(status#24), (status#24 = Completed)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/drive/MyDrive/Colab Notebooks/orders.csv], PartitionFilters: [], PushedFilters: [IsNotNull(status), EqualTo(status,Completed)], ReadSchema: struct<order_id:string,customer_id:string,city:string,category:string,product:string,amount:strin...\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- InMemoryTableScan [customer_id#18, total_spend#970L, total_orders#971L]\n",
            "      +- InMemoryRelation [customer_id#18, total_spend#970L, total_orders#971L], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "            +- AdaptiveSparkPlan isFinalPlan=false\n",
            "               +- HashAggregate(keys=[customer_id#18], functions=[sum(amount_clean#117), count(order_id#17)], output=[customer_id#18, total_spend#970L, total_orders#971L])\n",
            "                  +- Exchange hashpartitioning(customer_id#18, 200), ENSURE_REQUIREMENTS, [plan_id=6382]\n",
            "                     +- HashAggregate(keys=[customer_id#18], functions=[partial_sum(amount_clean#117), partial_count(order_id#17)], output=[customer_id#18, sum#2929L, count#1025L])\n",
            "                        +- InMemoryTableScan [order_id#17, customer_id#18, amount_clean#117]\n",
            "                              +- InMemoryRelation [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, amount_clean#117, order_date_clean#163], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                                    +- AdaptiveSparkPlan isFinalPlan=false\n",
            "                                       +- SortAggregate(key=[order_id#17], functions=[first(customer_id#18, false), first(city#19, false), first(category#20, false), first(product#21, false), first(amount#22, false), first(order_date#23, false), first(status#24, false), first(city_clean#71, false), first(category_clean#72, false), first(product_clean#73, false), first(amount_clean#117, false), first(order_date_clean#163, false)], output=[order_id#17, customer_id#2597, city#2599, category#2601, product#2603, amount#2605, order_date#2607, status#2609, city_clean#2611, category_clean#2613, product_clean#2615, amount_clean#2617, order_date_clean#2619])\n",
            "                                          +- Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                                             +- Exchange hashpartitioning(order_id#17, 200), ENSURE_REQUIREMENTS, [plan_id=6368]\n",
            "                                                +- SortAggregate(key=[order_id#17], functions=[partial_first(customer_id#18, false), partial_first(city#19, false), partial_first(category#20, false), partial_first(product#21, false), partial_first(amount#22, false), partial_first(order_date#23, false), partial_first(status#24, false), partial_first(city_clean#71, false), partial_first(category_clean#72, false), partial_first(product_clean#73, false), partial_first(amount_clean#117, false), partial_first(order_date_clean#163, false)], output=[order_id#17, first#2644, valueSet#2645, first#2646, valueSet#2647, first#2648, valueSet#2649, first#2650, valueSet#2651, first#2652, valueSet#2653, first#2654, valueSet#2655, first#2656, valueSet#2657, first#2658, valueSet#2659, first#2660, valueSet#2661, first#2662, valueSet#2663, first#2664, valueSet#2665, first#2666, valueSet#2667])\n",
            "                                                   +- Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                                                      +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, CASE WHEN RLIKE(amount_clean#116, ^[0-9]+$) THEN cast(amount_clean#116 as int) END AS amount_clean#117, coalesce(cast(gettimestamp(order_date#23, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date_clean#163]\n",
            "                                                         +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, lower(trim(city#19, None)) AS city_clean#71, lower(trim(category#20, None)) AS category_clean#72, lower(trim(product#21, None)) AS product_clean#73, regexp_replace(amount#22, ,, , 1) AS amount_clean#116]\n",
            "                                                            +- Filter (isnotnull(status#24) AND (status#24 = Completed))\n",
            "                                                               +- FileScan csv [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] Batched: false, DataFilters: [isnotnull(status#24), (status#24 = Completed)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/drive/MyDrive/Colab Notebooks/orders.csv], PartitionFilters: [], PushedFilters: [IsNotNull(status), EqualTo(status,Completed)], ReadSchema: struct<order_id:string,customer_id:string,city:string,category:string,product:string,amount:strin...\n",
            "\n",
            "\n",
            "Execution plan for Overall Window Ranking (customer_ranking_overall):\n",
            "== Parsed Logical Plan ==\n",
            "'Project [unresolvedstarwithcolumns(overall_rank, 'dense_rank() windowspecdefinition('total_spend DESC NULLS LAST, unspecifiedframe$()), None)]\n",
            "+- Aggregate [customer_id#18], [customer_id#18, sum(amount_clean#117) AS total_spend#970L, count(order_id#17) AS total_orders#971L]\n",
            "   +- Deduplicate [order_id#17]\n",
            "      +- Filter (status#24 = Completed)\n",
            "         +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, amount_clean#117, coalesce(cast(try_to_timestamp(order_date#23, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false) as date)) AS order_date_clean#163]\n",
            "            +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, CASE WHEN RLIKE(amount_clean#116, ^[0-9]+$) THEN cast(amount_clean#116 as int) ELSE cast(null as int) END AS amount_clean#117]\n",
            "               +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, regexp_replace(amount#22, ,, , 1) AS amount_clean#116]\n",
            "                  +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, lower(product_clean#28) AS product_clean#73]\n",
            "                     +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, lower(category_clean#27) AS category_clean#72, product_clean#28]\n",
            "                        +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, lower(city_clean#26) AS city_clean#71, category_clean#27, product_clean#28]\n",
            "                           +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#26, category_clean#27, trim(product#21, None) AS product_clean#28]\n",
            "                              +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#26, trim(category#20, None) AS category_clean#27]\n",
            "                                 +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, trim(city#19, None) AS city_clean#26]\n",
            "                                    +- Relation [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] csv\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "customer_id: string, total_spend: bigint, total_orders: bigint, overall_rank: int\n",
            "Project [customer_id#18, total_spend#970L, total_orders#971L, overall_rank#1069]\n",
            "+- Project [customer_id#18, total_spend#970L, total_orders#971L, overall_rank#1069, overall_rank#1069]\n",
            "   +- Window [dense_rank(total_spend#970L) windowspecdefinition(total_spend#970L DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS overall_rank#1069], [total_spend#970L DESC NULLS LAST]\n",
            "      +- Project [customer_id#18, total_spend#970L, total_orders#971L]\n",
            "         +- Aggregate [customer_id#18], [customer_id#18, sum(amount_clean#117) AS total_spend#970L, count(order_id#17) AS total_orders#971L]\n",
            "            +- Deduplicate [order_id#17]\n",
            "               +- Filter (status#24 = Completed)\n",
            "                  +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, amount_clean#117, coalesce(cast(try_to_timestamp(order_date#23, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false) as date)) AS order_date_clean#163]\n",
            "                     +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, CASE WHEN RLIKE(amount_clean#116, ^[0-9]+$) THEN cast(amount_clean#116 as int) ELSE cast(null as int) END AS amount_clean#117]\n",
            "                        +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, regexp_replace(amount#22, ,, , 1) AS amount_clean#116]\n",
            "                           +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, lower(product_clean#28) AS product_clean#73]\n",
            "                              +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, lower(category_clean#27) AS category_clean#72, product_clean#28]\n",
            "                                 +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, lower(city_clean#26) AS city_clean#71, category_clean#27, product_clean#28]\n",
            "                                    +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#26, category_clean#27, trim(product#21, None) AS product_clean#28]\n",
            "                                       +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#26, trim(category#20, None) AS category_clean#27]\n",
            "                                          +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, trim(city#19, None) AS city_clean#26]\n",
            "                                             +- Relation [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] csv\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Window [dense_rank(total_spend#970L) windowspecdefinition(total_spend#970L DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS overall_rank#1069], [total_spend#970L DESC NULLS LAST]\n",
            "+- InMemoryRelation [customer_id#18, total_spend#970L, total_orders#971L], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "      +- AdaptiveSparkPlan isFinalPlan=false\n",
            "         +- HashAggregate(keys=[customer_id#18], functions=[sum(amount_clean#117), count(order_id#17)], output=[customer_id#18, total_spend#970L, total_orders#971L])\n",
            "            +- Exchange hashpartitioning(customer_id#18, 200), ENSURE_REQUIREMENTS, [plan_id=6382]\n",
            "               +- HashAggregate(keys=[customer_id#18], functions=[partial_sum(amount_clean#117), partial_count(order_id#17)], output=[customer_id#18, sum#2929L, count#1025L])\n",
            "                  +- InMemoryTableScan [order_id#17, customer_id#18, amount_clean#117]\n",
            "                        +- InMemoryRelation [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, amount_clean#117, order_date_clean#163], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                              +- AdaptiveSparkPlan isFinalPlan=false\n",
            "                                 +- SortAggregate(key=[order_id#17], functions=[first(customer_id#18, false), first(city#19, false), first(category#20, false), first(product#21, false), first(amount#22, false), first(order_date#23, false), first(status#24, false), first(city_clean#71, false), first(category_clean#72, false), first(product_clean#73, false), first(amount_clean#117, false), first(order_date_clean#163, false)], output=[order_id#17, customer_id#2597, city#2599, category#2601, product#2603, amount#2605, order_date#2607, status#2609, city_clean#2611, category_clean#2613, product_clean#2615, amount_clean#2617, order_date_clean#2619])\n",
            "                                    +- Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                                       +- Exchange hashpartitioning(order_id#17, 200), ENSURE_REQUIREMENTS, [plan_id=6368]\n",
            "                                          +- SortAggregate(key=[order_id#17], functions=[partial_first(customer_id#18, false), partial_first(city#19, false), partial_first(category#20, false), partial_first(product#21, false), partial_first(amount#22, false), partial_first(order_date#23, false), partial_first(status#24, false), partial_first(city_clean#71, false), partial_first(category_clean#72, false), partial_first(product_clean#73, false), partial_first(amount_clean#117, false), partial_first(order_date_clean#163, false)], output=[order_id#17, first#2644, valueSet#2645, first#2646, valueSet#2647, first#2648, valueSet#2649, first#2650, valueSet#2651, first#2652, valueSet#2653, first#2654, valueSet#2655, first#2656, valueSet#2657, first#2658, valueSet#2659, first#2660, valueSet#2661, first#2662, valueSet#2663, first#2664, valueSet#2665, first#2666, valueSet#2667])\n",
            "                                             +- Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                                                +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, CASE WHEN RLIKE(amount_clean#116, ^[0-9]+$) THEN cast(amount_clean#116 as int) END AS amount_clean#117, coalesce(cast(gettimestamp(order_date#23, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date_clean#163]\n",
            "                                                   +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, lower(trim(city#19, None)) AS city_clean#71, lower(trim(category#20, None)) AS category_clean#72, lower(trim(product#21, None)) AS product_clean#73, regexp_replace(amount#22, ,, , 1) AS amount_clean#116]\n",
            "                                                      +- Filter (isnotnull(status#24) AND (status#24 = Completed))\n",
            "                                                         +- FileScan csv [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] Batched: false, DataFilters: [isnotnull(status#24), (status#24 = Completed)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/drive/MyDrive/Colab Notebooks/orders.csv], PartitionFilters: [], PushedFilters: [IsNotNull(status), EqualTo(status,Completed)], ReadSchema: struct<order_id:string,customer_id:string,city:string,category:string,product:string,amount:strin...\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Window [dense_rank(total_spend#970L) windowspecdefinition(total_spend#970L DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS overall_rank#1069], [total_spend#970L DESC NULLS LAST]\n",
            "   +- Sort [total_spend#970L DESC NULLS LAST], false, 0\n",
            "      +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=6396]\n",
            "         +- InMemoryTableScan [customer_id#18, total_spend#970L, total_orders#971L]\n",
            "               +- InMemoryRelation [customer_id#18, total_spend#970L, total_orders#971L], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                     +- AdaptiveSparkPlan isFinalPlan=false\n",
            "                        +- HashAggregate(keys=[customer_id#18], functions=[sum(amount_clean#117), count(order_id#17)], output=[customer_id#18, total_spend#970L, total_orders#971L])\n",
            "                           +- Exchange hashpartitioning(customer_id#18, 200), ENSURE_REQUIREMENTS, [plan_id=6382]\n",
            "                              +- HashAggregate(keys=[customer_id#18], functions=[partial_sum(amount_clean#117), partial_count(order_id#17)], output=[customer_id#18, sum#2929L, count#1025L])\n",
            "                                 +- InMemoryTableScan [order_id#17, customer_id#18, amount_clean#117]\n",
            "                                       +- InMemoryRelation [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, amount_clean#117, order_date_clean#163], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                                             +- AdaptiveSparkPlan isFinalPlan=false\n",
            "                                                +- SortAggregate(key=[order_id#17], functions=[first(customer_id#18, false), first(city#19, false), first(category#20, false), first(product#21, false), first(amount#22, false), first(order_date#23, false), first(status#24, false), first(city_clean#71, false), first(category_clean#72, false), first(product_clean#73, false), first(amount_clean#117, false), first(order_date_clean#163, false)], output=[order_id#17, customer_id#2597, city#2599, category#2601, product#2603, amount#2605, order_date#2607, status#2609, city_clean#2611, category_clean#2613, product_clean#2615, amount_clean#2617, order_date_clean#2619])\n",
            "                                                   +- Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                                                      +- Exchange hashpartitioning(order_id#17, 200), ENSURE_REQUIREMENTS, [plan_id=6368]\n",
            "                                                         +- SortAggregate(key=[order_id#17], functions=[partial_first(customer_id#18, false), partial_first(city#19, false), partial_first(category#20, false), partial_first(product#21, false), partial_first(amount#22, false), partial_first(order_date#23, false), partial_first(status#24, false), partial_first(city_clean#71, false), partial_first(category_clean#72, false), partial_first(product_clean#73, false), partial_first(amount_clean#117, false), partial_first(order_date_clean#163, false)], output=[order_id#17, first#2644, valueSet#2645, first#2646, valueSet#2647, first#2648, valueSet#2649, first#2650, valueSet#2651, first#2652, valueSet#2653, first#2654, valueSet#2655, first#2656, valueSet#2657, first#2658, valueSet#2659, first#2660, valueSet#2661, first#2662, valueSet#2663, first#2664, valueSet#2665, first#2666, valueSet#2667])\n",
            "                                                            +- Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                                                               +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, CASE WHEN RLIKE(amount_clean#116, ^[0-9]+$) THEN cast(amount_clean#116 as int) END AS amount_clean#117, coalesce(cast(gettimestamp(order_date#23, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date_clean#163]\n",
            "                                                                  +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, lower(trim(city#19, None)) AS city_clean#71, lower(trim(category#20, None)) AS category_clean#72, lower(trim(product#21, None)) AS product_clean#73, regexp_replace(amount#22, ,, , 1) AS amount_clean#116]\n",
            "                                                                     +- Filter (isnotnull(status#24) AND (status#24 = Completed))\n",
            "                                                                        +- FileScan csv [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] Batched: false, DataFilters: [isnotnull(status#24), (status#24 = Completed)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/drive/MyDrive/Colab Notebooks/orders.csv], PartitionFilters: [], PushedFilters: [IsNotNull(status), EqualTo(status,Completed)], ReadSchema: struct<order_id:string,customer_id:string,city:string,category:string,product:string,amount:strin...\n",
            "\n",
            "\n",
            "Execution plan for City-wise Window Ranking (customer_ranking_city):\n",
            "== Parsed Logical Plan ==\n",
            "'Project [unresolvedstarwithcolumns(city_rank, 'dense_rank() windowspecdefinition('city_clean, 'total_spend DESC NULLS LAST, unspecifiedframe$()), None)]\n",
            "+- Aggregate [customer_id#18, city_clean#71], [customer_id#18, city_clean#71, sum(amount_clean#117) AS total_spend#1155L, count(order_id#17) AS total_orders#1156L]\n",
            "   +- Deduplicate [order_id#17]\n",
            "      +- Filter (status#24 = Completed)\n",
            "         +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, amount_clean#117, coalesce(cast(try_to_timestamp(order_date#23, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false) as date)) AS order_date_clean#163]\n",
            "            +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, CASE WHEN RLIKE(amount_clean#116, ^[0-9]+$) THEN cast(amount_clean#116 as int) ELSE cast(null as int) END AS amount_clean#117]\n",
            "               +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, regexp_replace(amount#22, ,, , 1) AS amount_clean#116]\n",
            "                  +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, lower(product_clean#28) AS product_clean#73]\n",
            "                     +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, lower(category_clean#27) AS category_clean#72, product_clean#28]\n",
            "                        +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, lower(city_clean#26) AS city_clean#71, category_clean#27, product_clean#28]\n",
            "                           +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#26, category_clean#27, trim(product#21, None) AS product_clean#28]\n",
            "                              +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#26, trim(category#20, None) AS category_clean#27]\n",
            "                                 +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, trim(city#19, None) AS city_clean#26]\n",
            "                                    +- Relation [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] csv\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "customer_id: string, city_clean: string, total_spend: bigint, total_orders: bigint, city_rank: int\n",
            "Project [customer_id#18, city_clean#71, total_spend#1155L, total_orders#1156L, city_rank#1172]\n",
            "+- Project [customer_id#18, city_clean#71, total_spend#1155L, total_orders#1156L, city_rank#1172, city_rank#1172]\n",
            "   +- Window [dense_rank(total_spend#1155L) windowspecdefinition(city_clean#71, total_spend#1155L DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS city_rank#1172], [city_clean#71], [total_spend#1155L DESC NULLS LAST]\n",
            "      +- Project [customer_id#18, city_clean#71, total_spend#1155L, total_orders#1156L]\n",
            "         +- Aggregate [customer_id#18, city_clean#71], [customer_id#18, city_clean#71, sum(amount_clean#117) AS total_spend#1155L, count(order_id#17) AS total_orders#1156L]\n",
            "            +- Deduplicate [order_id#17]\n",
            "               +- Filter (status#24 = Completed)\n",
            "                  +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, amount_clean#117, coalesce(cast(try_to_timestamp(order_date#23, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false) as date)) AS order_date_clean#163]\n",
            "                     +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, CASE WHEN RLIKE(amount_clean#116, ^[0-9]+$) THEN cast(amount_clean#116 as int) ELSE cast(null as int) END AS amount_clean#117]\n",
            "                        +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, regexp_replace(amount#22, ,, , 1) AS amount_clean#116]\n",
            "                           +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, lower(product_clean#28) AS product_clean#73]\n",
            "                              +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, lower(category_clean#27) AS category_clean#72, product_clean#28]\n",
            "                                 +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, lower(city_clean#26) AS city_clean#71, category_clean#27, product_clean#28]\n",
            "                                    +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#26, category_clean#27, trim(product#21, None) AS product_clean#28]\n",
            "                                       +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#26, trim(category#20, None) AS category_clean#27]\n",
            "                                          +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, trim(city#19, None) AS city_clean#26]\n",
            "                                             +- Relation [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] csv\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Window [dense_rank(total_spend#1155L) windowspecdefinition(city_clean#71, total_spend#1155L DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS city_rank#1172], [city_clean#71], [total_spend#1155L DESC NULLS LAST]\n",
            "+- Aggregate [customer_id#18, city_clean#71], [customer_id#18, city_clean#71, sum(amount_clean#117) AS total_spend#1155L, count(order_id#17) AS total_orders#1156L]\n",
            "   +- Project [order_id#17, customer_id#18, city_clean#71, amount_clean#117]\n",
            "      +- InMemoryRelation [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, amount_clean#117, order_date_clean#163], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "            +- AdaptiveSparkPlan isFinalPlan=false\n",
            "               +- SortAggregate(key=[order_id#17], functions=[first(customer_id#18, false), first(city#19, false), first(category#20, false), first(product#21, false), first(amount#22, false), first(order_date#23, false), first(status#24, false), first(city_clean#71, false), first(category_clean#72, false), first(product_clean#73, false), first(amount_clean#117, false), first(order_date_clean#163, false)], output=[order_id#17, customer_id#2597, city#2599, category#2601, product#2603, amount#2605, order_date#2607, status#2609, city_clean#2611, category_clean#2613, product_clean#2615, amount_clean#2617, order_date_clean#2619])\n",
            "                  +- Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                     +- Exchange hashpartitioning(order_id#17, 200), ENSURE_REQUIREMENTS, [plan_id=6368]\n",
            "                        +- SortAggregate(key=[order_id#17], functions=[partial_first(customer_id#18, false), partial_first(city#19, false), partial_first(category#20, false), partial_first(product#21, false), partial_first(amount#22, false), partial_first(order_date#23, false), partial_first(status#24, false), partial_first(city_clean#71, false), partial_first(category_clean#72, false), partial_first(product_clean#73, false), partial_first(amount_clean#117, false), partial_first(order_date_clean#163, false)], output=[order_id#17, first#2644, valueSet#2645, first#2646, valueSet#2647, first#2648, valueSet#2649, first#2650, valueSet#2651, first#2652, valueSet#2653, first#2654, valueSet#2655, first#2656, valueSet#2657, first#2658, valueSet#2659, first#2660, valueSet#2661, first#2662, valueSet#2663, first#2664, valueSet#2665, first#2666, valueSet#2667])\n",
            "                           +- Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                              +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, CASE WHEN RLIKE(amount_clean#116, ^[0-9]+$) THEN cast(amount_clean#116 as int) END AS amount_clean#117, coalesce(cast(gettimestamp(order_date#23, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date_clean#163]\n",
            "                                 +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, lower(trim(city#19, None)) AS city_clean#71, lower(trim(category#20, None)) AS category_clean#72, lower(trim(product#21, None)) AS product_clean#73, regexp_replace(amount#22, ,, , 1) AS amount_clean#116]\n",
            "                                    +- Filter (isnotnull(status#24) AND (status#24 = Completed))\n",
            "                                       +- FileScan csv [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] Batched: false, DataFilters: [isnotnull(status#24), (status#24 = Completed)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/drive/MyDrive/Colab Notebooks/orders.csv], PartitionFilters: [], PushedFilters: [IsNotNull(status), EqualTo(status,Completed)], ReadSchema: struct<order_id:string,customer_id:string,city:string,category:string,product:string,amount:strin...\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Window [dense_rank(total_spend#1155L) windowspecdefinition(city_clean#71, total_spend#1155L DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS city_rank#1172], [city_clean#71], [total_spend#1155L DESC NULLS LAST]\n",
            "   +- Sort [city_clean#71 ASC NULLS FIRST, total_spend#1155L DESC NULLS LAST], false, 0\n",
            "      +- Exchange hashpartitioning(city_clean#71, 200), ENSURE_REQUIREMENTS, [plan_id=6417]\n",
            "         +- HashAggregate(keys=[customer_id#18, city_clean#71], functions=[sum(amount_clean#117), count(order_id#17)], output=[customer_id#18, city_clean#71, total_spend#1155L, total_orders#1156L])\n",
            "            +- Exchange hashpartitioning(customer_id#18, city_clean#71, 200), ENSURE_REQUIREMENTS, [plan_id=6414]\n",
            "               +- HashAggregate(keys=[customer_id#18, city_clean#71], functions=[partial_sum(amount_clean#117), partial_count(order_id#17)], output=[customer_id#18, city_clean#71, sum#3243L, count#1213L])\n",
            "                  +- InMemoryTableScan [order_id#17, customer_id#18, city_clean#71, amount_clean#117]\n",
            "                        +- InMemoryRelation [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, amount_clean#117, order_date_clean#163], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                              +- AdaptiveSparkPlan isFinalPlan=false\n",
            "                                 +- SortAggregate(key=[order_id#17], functions=[first(customer_id#18, false), first(city#19, false), first(category#20, false), first(product#21, false), first(amount#22, false), first(order_date#23, false), first(status#24, false), first(city_clean#71, false), first(category_clean#72, false), first(product_clean#73, false), first(amount_clean#117, false), first(order_date_clean#163, false)], output=[order_id#17, customer_id#2597, city#2599, category#2601, product#2603, amount#2605, order_date#2607, status#2609, city_clean#2611, category_clean#2613, product_clean#2615, amount_clean#2617, order_date_clean#2619])\n",
            "                                    +- Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                                       +- Exchange hashpartitioning(order_id#17, 200), ENSURE_REQUIREMENTS, [plan_id=6368]\n",
            "                                          +- SortAggregate(key=[order_id#17], functions=[partial_first(customer_id#18, false), partial_first(city#19, false), partial_first(category#20, false), partial_first(product#21, false), partial_first(amount#22, false), partial_first(order_date#23, false), partial_first(status#24, false), partial_first(city_clean#71, false), partial_first(category_clean#72, false), partial_first(product_clean#73, false), partial_first(amount_clean#117, false), partial_first(order_date_clean#163, false)], output=[order_id#17, first#2644, valueSet#2645, first#2646, valueSet#2647, first#2648, valueSet#2649, first#2650, valueSet#2651, first#2652, valueSet#2653, first#2654, valueSet#2655, first#2656, valueSet#2657, first#2658, valueSet#2659, first#2660, valueSet#2661, first#2662, valueSet#2663, first#2664, valueSet#2665, first#2666, valueSet#2667])\n",
            "                                             +- Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                                                +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, CASE WHEN RLIKE(amount_clean#116, ^[0-9]+$) THEN cast(amount_clean#116 as int) END AS amount_clean#117, coalesce(cast(gettimestamp(order_date#23, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date_clean#163]\n",
            "                                                   +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, lower(trim(city#19, None)) AS city_clean#71, lower(trim(category#20, None)) AS category_clean#72, lower(trim(product#21, None)) AS product_clean#73, regexp_replace(amount#22, ,, , 1) AS amount_clean#116]\n",
            "                                                      +- Filter (isnotnull(status#24) AND (status#24 = Completed))\n",
            "                                                         +- FileScan csv [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] Batched: false, DataFilters: [isnotnull(status#24), (status#24 = Completed)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/drive/MyDrive/Colab Notebooks/orders.csv], PartitionFilters: [], PushedFilters: [IsNotNull(status), EqualTo(status,Completed)], ReadSchema: struct<order_id:string,customer_id:string,city:string,category:string,product:string,amount:strin...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Identify shuffle stages"
      ],
      "metadata": {
        "id": "5gu2bZkbCQpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shuffle stages (indicated by 'Exchange hashpartitioning' or 'Exchange SinglePartition'):\")\n",
        "print(\"1. Customer Aggregation (`customer_metrics`):\")\n",
        "print(\"   - Exchange hashpartitioning(customer_id#18, 200): This shuffle happens before the final hash aggregation to ensure all data for a given customer_id is on the same partition, allowing sum and `count` to be computed correctly.\")\n",
        "print(\"   - Exchange hashpartitioning(order_id#17, 200): This shuffle happens during the deduplication process within `clean_orders_df` creation to group records by order_id.\")\n",
        "\n",
        "print(\"\\n2. Overall Window Ranking (customer_ranking_overall):\")\n",
        "print(\"   - Exchange SinglePartition: This shuffle occurs before the window function application when ordering globally. All data is collected into a single partition to allow for a global ranking based on `total_spend`. This can be a bottleneck for very large datasets.\")\n",
        "\n",
        "print(\"\\n3. City-wise Window Ranking (customer_ranking_city):\")\n",
        "print(\"   - Exchange hashpartitioning(city_clean#26, 200): This shuffle occurs before the window function application to group data by city_clean. This ensures that the ranking for each city happens independently within its own partition.\")\n",
        "print(\"   - Exchange hashpartitioning(customer_id#18, city_clean#26, 200): This shuffle happens during the aggregation for customer_city_metrics to group data by both customer_id and city_clean.\")\n",
        "print(\"   - Additional Exchange hashpartitioning(order_id#17, 200) stages originating from df_clean_orders as it's reused.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N00ebDX039jZ",
        "outputId": "5255dd19-db5e-42c9-b5ee-a338d86ab1f4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shuffle stages (indicated by 'Exchange hashpartitioning' or 'Exchange SinglePartition'):\n",
            "1. Customer Aggregation (`customer_metrics`):\n",
            "   - Exchange hashpartitioning(customer_id#18, 200): This shuffle happens before the final hash aggregation to ensure all data for a given customer_id is on the same partition, allowing sum and `count` to be computed correctly.\n",
            "   - Exchange hashpartitioning(order_id#17, 200): This shuffle happens during the deduplication process within `clean_orders_df` creation to group records by order_id.\n",
            "\n",
            "2. Overall Window Ranking (customer_ranking_overall):\n",
            "   - Exchange SinglePartition: This shuffle occurs before the window function application when ordering globally. All data is collected into a single partition to allow for a global ranking based on `total_spend`. This can be a bottleneck for very large datasets.\n",
            "\n",
            "3. City-wise Window Ranking (customer_ranking_city):\n",
            "   - Exchange hashpartitioning(city_clean#26, 200): This shuffle occurs before the window function application to group data by city_clean. This ensures that the ranking for each city happens independently within its own partition.\n",
            "   - Exchange hashpartitioning(customer_id#18, city_clean#26, 200): This shuffle happens during the aggregation for customer_city_metrics to group data by both customer_id and city_clean.\n",
            "   - Additional Exchange hashpartitioning(order_id#17, 200) stages originating from df_clean_orders as it's reused.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Justify any repartitioning strategy"
      ],
      "metadata": {
        "id": "dBWQOwiHCVKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Justification of Repartitioning Strategy:\")\n",
        "print(\"Spark performs repartitioning (shuffles) for several key reasons, primarily to ensure data correctness and enable parallel processing for certain operations. The identified shuffle stages are necessary as follows:\")\n",
        "print(\"\\n1. **Hash Partitioning (e.g., `Exchange hashpartitioning(customer_id, 200)`):**\")\n",
        "print(\"   - **Purpose**: Used for operations that require grouping data by one or more keys, such as aggregations (sum, count) and window functions partitioned by specific columns. By hashing the key(s), Spark ensures that all data points belonging to a particular key are co-located on the same partition. This is fundamental for correctly computing results for each group.\")\n",
        "print(\"   - **Examples in our pipeline**:\")\n",
        "print(\"     - Aggregation for `customer_metrics` (`hashpartitioning(customer_id)`): Ensures all orders for a given customer are on the same partition to accurately sum their spending and count their orders.\")\n",
        "print(\"     - Deduplication within `clean_orders_df` (`hashpartitioning(order_id)`): Groups identical `order_id`s together to facilitate efficient removal of duplicates.\")\n",
        "print(\"     - City-wise window ranking (`hashpartitioning(city_clean)` and `hashpartitioning(customer_id, city_clean)`): Ensures that all data for a specific city, or customer within a city, is processed together, allowing for correct city-specific aggregations and rankings.\")\n",
        "\n",
        "print(\"\\n2. **Single Partition (e.g., `Exchange SinglePartition`):**\")\n",
        "print(\"   - **Purpose**: This strategy is employed when an operation requires a global ordering or processing of the entire dataset as a single unit, such as an overall ranking (`dense_rank()` across all customers). All data is collected into one partition to establish a single, coherent order.\")\n",
        "print(\"   - **Example in our pipeline**:\")\n",
        "print(\"     - Overall Window Ranking (`customer_ranking_overall`): To rank customers by `total_spend` globally, all data must be sorted and processed together. While ensuring correctness, this can be a performance bottleneck for very large datasets as it limits parallelism to a single executor.\")\n",
        "\n",
        "print(\"\\nIn summary, shuffles are a trade-off between network I/O and disk I/O (for data movement) and computational correctness. While they can be expensive, they are often indispensable for complex data transformations and aggregations in distributed systems like Spark.\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k413Xo9_4FJ5",
        "outputId": "0a0a098a-ff30-4cd7-a25c-53ec054ab94d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Justification of Repartitioning Strategy:\n",
            "Spark performs repartitioning (shuffles) for several key reasons, primarily to ensure data correctness and enable parallel processing for certain operations. The identified shuffle stages are necessary as follows:\n",
            "\n",
            "1. **Hash Partitioning (e.g., `Exchange hashpartitioning(customer_id, 200)`):**\n",
            "   - **Purpose**: Used for operations that require grouping data by one or more keys, such as aggregations (sum, count) and window functions partitioned by specific columns. By hashing the key(s), Spark ensures that all data points belonging to a particular key are co-located on the same partition. This is fundamental for correctly computing results for each group.\n",
            "   - **Examples in our pipeline**:\n",
            "     - Aggregation for `customer_metrics` (`hashpartitioning(customer_id)`): Ensures all orders for a given customer are on the same partition to accurately sum their spending and count their orders.\n",
            "     - Deduplication within `clean_orders_df` (`hashpartitioning(order_id)`): Groups identical `order_id`s together to facilitate efficient removal of duplicates.\n",
            "     - City-wise window ranking (`hashpartitioning(city_clean)` and `hashpartitioning(customer_id, city_clean)`): Ensures that all data for a specific city, or customer within a city, is processed together, allowing for correct city-specific aggregations and rankings.\n",
            "\n",
            "2. **Single Partition (e.g., `Exchange SinglePartition`):**\n",
            "   - **Purpose**: This strategy is employed when an operation requires a global ordering or processing of the entire dataset as a single unit, such as an overall ranking (`dense_rank()` across all customers). All data is collected into one partition to establish a single, coherent order.\n",
            "   - **Example in our pipeline**:\n",
            "     - Overall Window Ranking (`customer_ranking_overall`): To rank customers by `total_spend` globally, all data must be sorted and processed together. While ensuring correctness, this can be a performance bottleneck for very large datasets as it limits parallelism to a single executor.\n",
            "\n",
            "In summary, shuffles are a trade-off between network I/O and disk I/O (for data movement) and computational correctness. While they can be expensive, they are often indispensable for complex data transformations and aggregations in distributed systems like Spark.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PHASE 8 – Broadcast Join (Light Use)\n",
        "- Create a small lookup:\n",
        "\n",
        "segment_code,segment_label\n",
        "\n",
        "1,VIP\n",
        "\n",
        "2,Premium\n",
        "\n",
        "3,Regular\n",
        "- Map:\n",
        "\n",
        "VIP     → 1\n",
        "\n",
        "Premium → 2  \n",
        "\n",
        "Regular → 3"
      ],
      "metadata": {
        "id": "hKGFvD51CZaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Create this as a small DataFrame."
      ],
      "metadata": {
        "id": "BNNzvdVJCtos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "segment_data = [\n",
        "    (1, \"VIP\"),\n",
        "    (2, \"Premium\"),\n",
        "    (3, \"Regular\")\n",
        "]\n",
        "\n",
        "segment_lookup_df = spark.createDataFrame(segment_data, [\"segment_code\", \"segment_label\"])\n",
        "segment_lookup_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLKc2bm75ORi",
        "outputId": "8a3f50f7-db69-4a0a-d9d1-feb90120debc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------------+\n",
            "|segment_code|segment_label|\n",
            "+------------+-------------+\n",
            "|           1|          VIP|\n",
            "|           2|      Premium|\n",
            "|           3|      Regular|\n",
            "+------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Join with customer segmentation output."
      ],
      "metadata": {
        "id": "S7SmQnn6Cw5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import broadcast\n",
        "\n",
        "customer_segments_with_lookup = customer_segments.join(\n",
        "    broadcast(segment_lookup_df),\n",
        "    customer_segments[\"customer_segment\"] == segment_lookup_df[\"segment_label\"],\n",
        "    \"inner\"\n",
        ")\n",
        "\n",
        "print(\"Customer segments joined with lookup:\")\n",
        "customer_segments_with_lookup.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBoIUaig5UYq",
        "outputId": "9964ffb4-52b0-414b-9eb3-00f744ada103"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customer segments joined with lookup:\n",
            "+-----------+-----------+------------+----------------+------------+-------------+\n",
            "|customer_id|total_spend|total_orders|customer_segment|segment_code|segment_label|\n",
            "+-----------+-----------+------------+----------------+------------+-------------+\n",
            "|    C007013|     241427|           6|             VIP|           1|          VIP|\n",
            "|    C016502|     318813|           6|             VIP|           1|          VIP|\n",
            "|    C030046|     276423|           6|             VIP|           1|          VIP|\n",
            "|    C036809|     284063|           6|             VIP|           1|          VIP|\n",
            "|    C022166|     266454|           6|             VIP|           1|          VIP|\n",
            "+-----------+-----------+------------+----------------+------------+-------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Force broadcast join."
      ],
      "metadata": {
        "id": "EcogUMMRC0Ul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customer_segments_with_lookup_forced_broadcast = customer_segments.join(broadcast(segment_lookup_df),customer_segments[\"customer_segment\"] == segment_lookup_df[\"segment_label\"],\"inner\")\n",
        "print(\"Broadcast join applied successfully (if segment_lookup_df is small enough).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7X_JnYW5md1",
        "outputId": "9eb09b0e-14e3-4fae-b41f-5b4b35bae3fb"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Broadcast join applied successfully (if segment_lookup_df is small enough).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Verify BroadcastHashJoin in plan."
      ],
      "metadata": {
        "id": "1n19fqyHC4ii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Execution plan for Broadcast Join verification:\")\n",
        "customer_segments_with_lookup_forced_broadcast.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8i1IbXK51ey",
        "outputId": "6a200cbe-f7c1-480b-f424-e3ace6374fc7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution plan for Broadcast Join verification:\n",
            "== Parsed Logical Plan ==\n",
            "Join Inner, (customer_segment#987 = segment_label#3245)\n",
            ":- Project [customer_id#18, total_spend#970L, total_orders#971L, CASE WHEN ((total_spend#970L >= cast(200000 as bigint)) AND (total_orders#971L >= cast(5 as bigint))) THEN VIP WHEN (total_spend#970L >= cast(100000 as bigint)) THEN Premium ELSE Regular END AS customer_segment#987]\n",
            ":  +- Aggregate [customer_id#18], [customer_id#18, sum(amount_clean#117) AS total_spend#970L, count(order_id#17) AS total_orders#971L]\n",
            ":     +- Deduplicate [order_id#17]\n",
            ":        +- Filter (status#24 = Completed)\n",
            ":           +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, amount_clean#117, coalesce(cast(try_to_timestamp(order_date#23, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false) as date)) AS order_date_clean#163]\n",
            ":              +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, CASE WHEN RLIKE(amount_clean#116, ^[0-9]+$) THEN cast(amount_clean#116 as int) ELSE cast(null as int) END AS amount_clean#117]\n",
            ":                 +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, regexp_replace(amount#22, ,, , 1) AS amount_clean#116]\n",
            ":                    +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, lower(product_clean#28) AS product_clean#73]\n",
            ":                       +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, lower(category_clean#27) AS category_clean#72, product_clean#28]\n",
            ":                          +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, lower(city_clean#26) AS city_clean#71, category_clean#27, product_clean#28]\n",
            ":                             +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#26, category_clean#27, trim(product#21, None) AS product_clean#28]\n",
            ":                                +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#26, trim(category#20, None) AS category_clean#27]\n",
            ":                                   +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, trim(city#19, None) AS city_clean#26]\n",
            ":                                      +- Relation [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] csv\n",
            "+- ResolvedHint (strategy=broadcast)\n",
            "   +- LogicalRDD [segment_code#3244L, segment_label#3245], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "customer_id: string, total_spend: bigint, total_orders: bigint, customer_segment: string, segment_code: bigint, segment_label: string\n",
            "Join Inner, (customer_segment#987 = segment_label#3245)\n",
            ":- Project [customer_id#18, total_spend#970L, total_orders#971L, CASE WHEN ((total_spend#970L >= cast(200000 as bigint)) AND (total_orders#971L >= cast(5 as bigint))) THEN VIP WHEN (total_spend#970L >= cast(100000 as bigint)) THEN Premium ELSE Regular END AS customer_segment#987]\n",
            ":  +- Aggregate [customer_id#18], [customer_id#18, sum(amount_clean#117) AS total_spend#970L, count(order_id#17) AS total_orders#971L]\n",
            ":     +- Deduplicate [order_id#17]\n",
            ":        +- Filter (status#24 = Completed)\n",
            ":           +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, amount_clean#117, coalesce(cast(try_to_timestamp(order_date#23, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#23, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false) as date)) AS order_date_clean#163]\n",
            ":              +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, CASE WHEN RLIKE(amount_clean#116, ^[0-9]+$) THEN cast(amount_clean#116 as int) ELSE cast(null as int) END AS amount_clean#117]\n",
            ":                 +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, regexp_replace(amount#22, ,, , 1) AS amount_clean#116]\n",
            ":                    +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, lower(product_clean#28) AS product_clean#73]\n",
            ":                       +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, lower(category_clean#27) AS category_clean#72, product_clean#28]\n",
            ":                          +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, lower(city_clean#26) AS city_clean#71, category_clean#27, product_clean#28]\n",
            ":                             +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#26, category_clean#27, trim(product#21, None) AS product_clean#28]\n",
            ":                                +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#26, trim(category#20, None) AS category_clean#27]\n",
            ":                                   +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, trim(city#19, None) AS city_clean#26]\n",
            ":                                      +- Relation [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] csv\n",
            "+- ResolvedHint (strategy=broadcast)\n",
            "   +- LogicalRDD [segment_code#3244L, segment_label#3245], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Join Inner, (customer_segment#987 = segment_label#3245), rightHint=(strategy=broadcast)\n",
            ":- Project [customer_id#18, total_spend#970L, total_orders#971L, CASE WHEN ((total_spend#970L >= 200000) AND (total_orders#971L >= 5)) THEN VIP WHEN (total_spend#970L >= 100000) THEN Premium ELSE Regular END AS customer_segment#987]\n",
            ":  +- InMemoryRelation [customer_id#18, total_spend#970L, total_orders#971L], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            ":        +- AdaptiveSparkPlan isFinalPlan=true\n",
            "            +- == Final Plan ==\n",
            "               ResultQueryStage 2\n",
            "               +- *(2) HashAggregate(keys=[customer_id#18], functions=[sum(amount_clean#117), count(order_id#17)], output=[customer_id#18, total_spend#970L, total_orders#971L])\n",
            "                  +- ShuffleQueryStage 1\n",
            "                     +- Exchange hashpartitioning(customer_id#18, 200), ENSURE_REQUIREMENTS, [plan_id=6544]\n",
            "                        +- *(1) HashAggregate(keys=[customer_id#18], functions=[partial_sum(amount_clean#117), partial_count(order_id#17)], output=[customer_id#18, sum#2929L, count#1025L])\n",
            "                           +- TableCacheQueryStage 0\n",
            "                              +- InMemoryTableScan [order_id#17, customer_id#18, amount_clean#117]\n",
            "                                    +- InMemoryRelation [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, amount_clean#117, order_date_clean#163], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                                          +- AdaptiveSparkPlan isFinalPlan=true\n",
            "                              +- == Final Plan ==\n",
            "                                 ResultQueryStage 1\n",
            "                                 +- SortAggregate(key=[order_id#17], functions=[first(customer_id#18, false), first(city#19, false), first(category#20, false), first(product#21, false), first(amount#22, false), first(order_date#23, false), first(status#24, false), first(city_clean#71, false), first(category_clean#72, false), first(product_clean#73, false), first(amount_clean#117, false), first(order_date_clean#163, false)], output=[order_id#17, customer_id#2597, city#2599, category#2601, product#2603, amount#2605, order_date#2607, status#2609, city_clean#2611, category_clean#2613, product_clean#2615, amount_clean#2617, order_date_clean#2619])\n",
            "                                    +- *(2) Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                                       +- ShuffleQueryStage 0\n",
            "                                          +- Exchange hashpartitioning(order_id#17, 200), ENSURE_REQUIREMENTS, [plan_id=6505]\n",
            "                                             +- SortAggregate(key=[order_id#17], functions=[partial_first(customer_id#18, false), partial_first(city#19, false), partial_first(category#20, false), partial_first(product#21, false), partial_first(amount#22, false), partial_first(order_date#23, false), partial_first(status#24, false), partial_first(city_clean#71, false), partial_first(category_clean#72, false), partial_first(product_clean#73, false), partial_first(amount_clean#117, false), partial_first(order_date_clean#163, false)], output=[order_id#17, first#2644, valueSet#2645, first#2646, valueSet#2647, first#2648, valueSet#2649, first#2650, valueSet#2651, first#2652, valueSet#2653, first#2654, valueSet#2655, first#2656, valueSet#2657, first#2658, valueSet#2659, first#2660, valueSet#2661, first#2662, valueSet#2663, first#2664, valueSet#2665, first#2666, valueSet#2667])\n",
            "                                                +- *(1) Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                                                   +- *(1) Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, CASE WHEN RLIKE(amount_clean#116, ^[0-9]+$) THEN cast(amount_clean#116 as int) END AS amount_clean#117, coalesce(cast(gettimestamp(order_date#23, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date_clean#163]\n",
            "                                                      +- *(1) Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, lower(trim(city#19, None)) AS city_clean#71, lower(trim(category#20, None)) AS category_clean#72, lower(trim(product#21, None)) AS product_clean#73, regexp_replace(amount#22, ,, , 1) AS amount_clean#116]\n",
            "                                                         +- *(1) Filter (isnotnull(status#24) AND (status#24 = Completed))\n",
            "                                                            +- FileScan csv [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] Batched: false, DataFilters: [isnotnull(status#24), (status#24 = Completed)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/drive/MyDrive/Colab Notebooks/orders.csv], PartitionFilters: [], PushedFilters: [IsNotNull(status), EqualTo(status,Completed)], ReadSchema: struct<order_id:string,customer_id:string,city:string,category:string,product:string,amount:strin...\n",
            "                              +- == Initial Plan ==\n",
            "                                 SortAggregate(key=[order_id#17], functions=[first(customer_id#18, false), first(city#19, false), first(category#20, false), first(product#21, false), first(amount#22, false), first(order_date#23, false), first(status#24, false), first(city_clean#71, false), first(category_clean#72, false), first(product_clean#73, false), first(amount_clean#117, false), first(order_date_clean#163, false)], output=[order_id#17, customer_id#2597, city#2599, category#2601, product#2603, amount#2605, order_date#2607, status#2609, city_clean#2611, category_clean#2613, product_clean#2615, amount_clean#2617, order_date_clean#2619])\n",
            "                                 +- Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                                    +- Exchange hashpartitioning(order_id#17, 200), ENSURE_REQUIREMENTS, [plan_id=6368]\n",
            "                                       +- SortAggregate(key=[order_id#17], functions=[partial_first(customer_id#18, false), partial_first(city#19, false), partial_first(category#20, false), partial_first(product#21, false), partial_first(amount#22, false), partial_first(order_date#23, false), partial_first(status#24, false), partial_first(city_clean#71, false), partial_first(category_clean#72, false), partial_first(product_clean#73, false), partial_first(amount_clean#117, false), partial_first(order_date_clean#163, false)], output=[order_id#17, first#2644, valueSet#2645, first#2646, valueSet#2647, first#2648, valueSet#2649, first#2650, valueSet#2651, first#2652, valueSet#2653, first#2654, valueSet#2655, first#2656, valueSet#2657, first#2658, valueSet#2659, first#2660, valueSet#2661, first#2662, valueSet#2663, first#2664, valueSet#2665, first#2666, valueSet#2667])\n",
            "                                          +- Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                                             +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, CASE WHEN RLIKE(amount_clean#116, ^[0-9]+$) THEN cast(amount_clean#116 as int) END AS amount_clean#117, coalesce(cast(gettimestamp(order_date#23, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date_clean#163]\n",
            "                                                +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, lower(trim(city#19, None)) AS city_clean#71, lower(trim(category#20, None)) AS category_clean#72, lower(trim(product#21, None)) AS product_clean#73, regexp_replace(amount#22, ,, , 1) AS amount_clean#116]\n",
            "                                                   +- Filter (isnotnull(status#24) AND (status#24 = Completed))\n",
            "                                                      +- FileScan csv [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] Batched: false, DataFilters: [isnotnull(status#24), (status#24 = Completed)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/drive/MyDrive/Colab Notebooks/orders.csv], PartitionFilters: [], PushedFilters: [IsNotNull(status), EqualTo(status,Completed)], ReadSchema: struct<order_id:string,customer_id:string,city:string,category:string,product:string,amount:strin...\n",
            "            +- == Initial Plan ==\n",
            "               HashAggregate(keys=[customer_id#18], functions=[sum(amount_clean#117), count(order_id#17)], output=[customer_id#18, total_spend#970L, total_orders#971L])\n",
            "               +- Exchange hashpartitioning(customer_id#18, 200), ENSURE_REQUIREMENTS, [plan_id=6382]\n",
            "                  +- HashAggregate(keys=[customer_id#18], functions=[partial_sum(amount_clean#117), partial_count(order_id#17)], output=[customer_id#18, sum#2929L, count#1025L])\n",
            "                     +- InMemoryTableScan [order_id#17, customer_id#18, amount_clean#117]\n",
            "                           +- InMemoryRelation [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, amount_clean#117, order_date_clean#163], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                                 +- AdaptiveSparkPlan isFinalPlan=true\n",
            "                     +- == Final Plan ==\n",
            "                        ResultQueryStage 1\n",
            "                        +- SortAggregate(key=[order_id#17], functions=[first(customer_id#18, false), first(city#19, false), first(category#20, false), first(product#21, false), first(amount#22, false), first(order_date#23, false), first(status#24, false), first(city_clean#71, false), first(category_clean#72, false), first(product_clean#73, false), first(amount_clean#117, false), first(order_date_clean#163, false)], output=[order_id#17, customer_id#2597, city#2599, category#2601, product#2603, amount#2605, order_date#2607, status#2609, city_clean#2611, category_clean#2613, product_clean#2615, amount_clean#2617, order_date_clean#2619])\n",
            "                           +- *(2) Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                              +- ShuffleQueryStage 0\n",
            "                                 +- Exchange hashpartitioning(order_id#17, 200), ENSURE_REQUIREMENTS, [plan_id=6505]\n",
            "                                    +- SortAggregate(key=[order_id#17], functions=[partial_first(customer_id#18, false), partial_first(city#19, false), partial_first(category#20, false), partial_first(product#21, false), partial_first(amount#22, false), partial_first(order_date#23, false), partial_first(status#24, false), partial_first(city_clean#71, false), partial_first(category_clean#72, false), partial_first(product_clean#73, false), partial_first(amount_clean#117, false), partial_first(order_date_clean#163, false)], output=[order_id#17, first#2644, valueSet#2645, first#2646, valueSet#2647, first#2648, valueSet#2649, first#2650, valueSet#2651, first#2652, valueSet#2653, first#2654, valueSet#2655, first#2656, valueSet#2657, first#2658, valueSet#2659, first#2660, valueSet#2661, first#2662, valueSet#2663, first#2664, valueSet#2665, first#2666, valueSet#2667])\n",
            "                                       +- *(1) Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                                          +- *(1) Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, CASE WHEN RLIKE(amount_clean#116, ^[0-9]+$) THEN cast(amount_clean#116 as int) END AS amount_clean#117, coalesce(cast(gettimestamp(order_date#23, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date_clean#163]\n",
            "                                             +- *(1) Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, lower(trim(city#19, None)) AS city_clean#71, lower(trim(category#20, None)) AS category_clean#72, lower(trim(product#21, None)) AS product_clean#73, regexp_replace(amount#22, ,, , 1) AS amount_clean#116]\n",
            "                                                +- *(1) Filter (isnotnull(status#24) AND (status#24 = Completed))\n",
            "                                                   +- FileScan csv [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] Batched: false, DataFilters: [isnotnull(status#24), (status#24 = Completed)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/drive/MyDrive/Colab Notebooks/orders.csv], PartitionFilters: [], PushedFilters: [IsNotNull(status), EqualTo(status,Completed)], ReadSchema: struct<order_id:string,customer_id:string,city:string,category:string,product:string,amount:strin...\n",
            "                     +- == Initial Plan ==\n",
            "                        SortAggregate(key=[order_id#17], functions=[first(customer_id#18, false), first(city#19, false), first(category#20, false), first(product#21, false), first(amount#22, false), first(order_date#23, false), first(status#24, false), first(city_clean#71, false), first(category_clean#72, false), first(product_clean#73, false), first(amount_clean#117, false), first(order_date_clean#163, false)], output=[order_id#17, customer_id#2597, city#2599, category#2601, product#2603, amount#2605, order_date#2607, status#2609, city_clean#2611, category_clean#2613, product_clean#2615, amount_clean#2617, order_date_clean#2619])\n",
            "                        +- Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                           +- Exchange hashpartitioning(order_id#17, 200), ENSURE_REQUIREMENTS, [plan_id=6368]\n",
            "                              +- SortAggregate(key=[order_id#17], functions=[partial_first(customer_id#18, false), partial_first(city#19, false), partial_first(category#20, false), partial_first(product#21, false), partial_first(amount#22, false), partial_first(order_date#23, false), partial_first(status#24, false), partial_first(city_clean#71, false), partial_first(category_clean#72, false), partial_first(product_clean#73, false), partial_first(amount_clean#117, false), partial_first(order_date_clean#163, false)], output=[order_id#17, first#2644, valueSet#2645, first#2646, valueSet#2647, first#2648, valueSet#2649, first#2650, valueSet#2651, first#2652, valueSet#2653, first#2654, valueSet#2655, first#2656, valueSet#2657, first#2658, valueSet#2659, first#2660, valueSet#2661, first#2662, valueSet#2663, first#2664, valueSet#2665, first#2666, valueSet#2667])\n",
            "                                 +- Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                                    +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, CASE WHEN RLIKE(amount_clean#116, ^[0-9]+$) THEN cast(amount_clean#116 as int) END AS amount_clean#117, coalesce(cast(gettimestamp(order_date#23, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date_clean#163]\n",
            "                                       +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, lower(trim(city#19, None)) AS city_clean#71, lower(trim(category#20, None)) AS category_clean#72, lower(trim(product#21, None)) AS product_clean#73, regexp_replace(amount#22, ,, , 1) AS amount_clean#116]\n",
            "                                          +- Filter (isnotnull(status#24) AND (status#24 = Completed))\n",
            "                                             +- FileScan csv [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] Batched: false, DataFilters: [isnotnull(status#24), (status#24 = Completed)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/drive/MyDrive/Colab Notebooks/orders.csv], PartitionFilters: [], PushedFilters: [IsNotNull(status), EqualTo(status,Completed)], ReadSchema: struct<order_id:string,customer_id:string,city:string,category:string,product:string,amount:strin...\n",
            "+- Filter isnotnull(segment_label#3245)\n",
            "   +- LogicalRDD [segment_code#3244L, segment_label#3245], false\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- BroadcastHashJoin [customer_segment#987], [segment_label#3245], Inner, BuildRight, false\n",
            "   :- Project [customer_id#18, total_spend#970L, total_orders#971L, CASE WHEN ((total_spend#970L >= 200000) AND (total_orders#971L >= 5)) THEN VIP WHEN (total_spend#970L >= 100000) THEN Premium ELSE Regular END AS customer_segment#987]\n",
            "   :  +- InMemoryTableScan [customer_id#18, total_orders#971L, total_spend#970L]\n",
            "   :        +- InMemoryRelation [customer_id#18, total_spend#970L, total_orders#971L], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "   :              +- AdaptiveSparkPlan isFinalPlan=true\n",
            "                     +- == Final Plan ==\n",
            "                        ResultQueryStage 2\n",
            "                        +- *(2) HashAggregate(keys=[customer_id#18], functions=[sum(amount_clean#117), count(order_id#17)], output=[customer_id#18, total_spend#970L, total_orders#971L])\n",
            "                           +- ShuffleQueryStage 1\n",
            "                              +- Exchange hashpartitioning(customer_id#18, 200), ENSURE_REQUIREMENTS, [plan_id=6544]\n",
            "                                 +- *(1) HashAggregate(keys=[customer_id#18], functions=[partial_sum(amount_clean#117), partial_count(order_id#17)], output=[customer_id#18, sum#2929L, count#1025L])\n",
            "                                    +- TableCacheQueryStage 0\n",
            "                                       +- InMemoryTableScan [order_id#17, customer_id#18, amount_clean#117]\n",
            "                                             +- InMemoryRelation [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, amount_clean#117, order_date_clean#163], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                                                   +- AdaptiveSparkPlan isFinalPlan=true\n",
            "                              +- == Final Plan ==\n",
            "                                 ResultQueryStage 1\n",
            "                                 +- SortAggregate(key=[order_id#17], functions=[first(customer_id#18, false), first(city#19, false), first(category#20, false), first(product#21, false), first(amount#22, false), first(order_date#23, false), first(status#24, false), first(city_clean#71, false), first(category_clean#72, false), first(product_clean#73, false), first(amount_clean#117, false), first(order_date_clean#163, false)], output=[order_id#17, customer_id#2597, city#2599, category#2601, product#2603, amount#2605, order_date#2607, status#2609, city_clean#2611, category_clean#2613, product_clean#2615, amount_clean#2617, order_date_clean#2619])\n",
            "                                    +- *(2) Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                                       +- ShuffleQueryStage 0\n",
            "                                          +- Exchange hashpartitioning(order_id#17, 200), ENSURE_REQUIREMENTS, [plan_id=6505]\n",
            "                                             +- SortAggregate(key=[order_id#17], functions=[partial_first(customer_id#18, false), partial_first(city#19, false), partial_first(category#20, false), partial_first(product#21, false), partial_first(amount#22, false), partial_first(order_date#23, false), partial_first(status#24, false), partial_first(city_clean#71, false), partial_first(category_clean#72, false), partial_first(product_clean#73, false), partial_first(amount_clean#117, false), partial_first(order_date_clean#163, false)], output=[order_id#17, first#2644, valueSet#2645, first#2646, valueSet#2647, first#2648, valueSet#2649, first#2650, valueSet#2651, first#2652, valueSet#2653, first#2654, valueSet#2655, first#2656, valueSet#2657, first#2658, valueSet#2659, first#2660, valueSet#2661, first#2662, valueSet#2663, first#2664, valueSet#2665, first#2666, valueSet#2667])\n",
            "                                                +- *(1) Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                                                   +- *(1) Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, CASE WHEN RLIKE(amount_clean#116, ^[0-9]+$) THEN cast(amount_clean#116 as int) END AS amount_clean#117, coalesce(cast(gettimestamp(order_date#23, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date_clean#163]\n",
            "                                                      +- *(1) Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, lower(trim(city#19, None)) AS city_clean#71, lower(trim(category#20, None)) AS category_clean#72, lower(trim(product#21, None)) AS product_clean#73, regexp_replace(amount#22, ,, , 1) AS amount_clean#116]\n",
            "                                                         +- *(1) Filter (isnotnull(status#24) AND (status#24 = Completed))\n",
            "                                                            +- FileScan csv [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] Batched: false, DataFilters: [isnotnull(status#24), (status#24 = Completed)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/drive/MyDrive/Colab Notebooks/orders.csv], PartitionFilters: [], PushedFilters: [IsNotNull(status), EqualTo(status,Completed)], ReadSchema: struct<order_id:string,customer_id:string,city:string,category:string,product:string,amount:strin...\n",
            "                              +- == Initial Plan ==\n",
            "                                 SortAggregate(key=[order_id#17], functions=[first(customer_id#18, false), first(city#19, false), first(category#20, false), first(product#21, false), first(amount#22, false), first(order_date#23, false), first(status#24, false), first(city_clean#71, false), first(category_clean#72, false), first(product_clean#73, false), first(amount_clean#117, false), first(order_date_clean#163, false)], output=[order_id#17, customer_id#2597, city#2599, category#2601, product#2603, amount#2605, order_date#2607, status#2609, city_clean#2611, category_clean#2613, product_clean#2615, amount_clean#2617, order_date_clean#2619])\n",
            "                                 +- Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                                    +- Exchange hashpartitioning(order_id#17, 200), ENSURE_REQUIREMENTS, [plan_id=6368]\n",
            "                                       +- SortAggregate(key=[order_id#17], functions=[partial_first(customer_id#18, false), partial_first(city#19, false), partial_first(category#20, false), partial_first(product#21, false), partial_first(amount#22, false), partial_first(order_date#23, false), partial_first(status#24, false), partial_first(city_clean#71, false), partial_first(category_clean#72, false), partial_first(product_clean#73, false), partial_first(amount_clean#117, false), partial_first(order_date_clean#163, false)], output=[order_id#17, first#2644, valueSet#2645, first#2646, valueSet#2647, first#2648, valueSet#2649, first#2650, valueSet#2651, first#2652, valueSet#2653, first#2654, valueSet#2655, first#2656, valueSet#2657, first#2658, valueSet#2659, first#2660, valueSet#2661, first#2662, valueSet#2663, first#2664, valueSet#2665, first#2666, valueSet#2667])\n",
            "                                          +- Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                                             +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, CASE WHEN RLIKE(amount_clean#116, ^[0-9]+$) THEN cast(amount_clean#116 as int) END AS amount_clean#117, coalesce(cast(gettimestamp(order_date#23, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date_clean#163]\n",
            "                                                +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, lower(trim(city#19, None)) AS city_clean#71, lower(trim(category#20, None)) AS category_clean#72, lower(trim(product#21, None)) AS product_clean#73, regexp_replace(amount#22, ,, , 1) AS amount_clean#116]\n",
            "                                                   +- Filter (isnotnull(status#24) AND (status#24 = Completed))\n",
            "                                                      +- FileScan csv [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] Batched: false, DataFilters: [isnotnull(status#24), (status#24 = Completed)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/drive/MyDrive/Colab Notebooks/orders.csv], PartitionFilters: [], PushedFilters: [IsNotNull(status), EqualTo(status,Completed)], ReadSchema: struct<order_id:string,customer_id:string,city:string,category:string,product:string,amount:strin...\n",
            "                     +- == Initial Plan ==\n",
            "                        HashAggregate(keys=[customer_id#18], functions=[sum(amount_clean#117), count(order_id#17)], output=[customer_id#18, total_spend#970L, total_orders#971L])\n",
            "                        +- Exchange hashpartitioning(customer_id#18, 200), ENSURE_REQUIREMENTS, [plan_id=6382]\n",
            "                           +- HashAggregate(keys=[customer_id#18], functions=[partial_sum(amount_clean#117), partial_count(order_id#17)], output=[customer_id#18, sum#2929L, count#1025L])\n",
            "                              +- InMemoryTableScan [order_id#17, customer_id#18, amount_clean#117]\n",
            "                                    +- InMemoryRelation [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, amount_clean#117, order_date_clean#163], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                                          +- AdaptiveSparkPlan isFinalPlan=true\n",
            "                     +- == Final Plan ==\n",
            "                        ResultQueryStage 1\n",
            "                        +- SortAggregate(key=[order_id#17], functions=[first(customer_id#18, false), first(city#19, false), first(category#20, false), first(product#21, false), first(amount#22, false), first(order_date#23, false), first(status#24, false), first(city_clean#71, false), first(category_clean#72, false), first(product_clean#73, false), first(amount_clean#117, false), first(order_date_clean#163, false)], output=[order_id#17, customer_id#2597, city#2599, category#2601, product#2603, amount#2605, order_date#2607, status#2609, city_clean#2611, category_clean#2613, product_clean#2615, amount_clean#2617, order_date_clean#2619])\n",
            "                           +- *(2) Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                              +- ShuffleQueryStage 0\n",
            "                                 +- Exchange hashpartitioning(order_id#17, 200), ENSURE_REQUIREMENTS, [plan_id=6505]\n",
            "                                    +- SortAggregate(key=[order_id#17], functions=[partial_first(customer_id#18, false), partial_first(city#19, false), partial_first(category#20, false), partial_first(product#21, false), partial_first(amount#22, false), partial_first(order_date#23, false), partial_first(status#24, false), partial_first(city_clean#71, false), partial_first(category_clean#72, false), partial_first(product_clean#73, false), partial_first(amount_clean#117, false), partial_first(order_date_clean#163, false)], output=[order_id#17, first#2644, valueSet#2645, first#2646, valueSet#2647, first#2648, valueSet#2649, first#2650, valueSet#2651, first#2652, valueSet#2653, first#2654, valueSet#2655, first#2656, valueSet#2657, first#2658, valueSet#2659, first#2660, valueSet#2661, first#2662, valueSet#2663, first#2664, valueSet#2665, first#2666, valueSet#2667])\n",
            "                                       +- *(1) Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                                          +- *(1) Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, CASE WHEN RLIKE(amount_clean#116, ^[0-9]+$) THEN cast(amount_clean#116 as int) END AS amount_clean#117, coalesce(cast(gettimestamp(order_date#23, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date_clean#163]\n",
            "                                             +- *(1) Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, lower(trim(city#19, None)) AS city_clean#71, lower(trim(category#20, None)) AS category_clean#72, lower(trim(product#21, None)) AS product_clean#73, regexp_replace(amount#22, ,, , 1) AS amount_clean#116]\n",
            "                                                +- *(1) Filter (isnotnull(status#24) AND (status#24 = Completed))\n",
            "                                                   +- FileScan csv [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] Batched: false, DataFilters: [isnotnull(status#24), (status#24 = Completed)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/drive/MyDrive/Colab Notebooks/orders.csv], PartitionFilters: [], PushedFilters: [IsNotNull(status), EqualTo(status,Completed)], ReadSchema: struct<order_id:string,customer_id:string,city:string,category:string,product:string,amount:strin...\n",
            "                     +- == Initial Plan ==\n",
            "                        SortAggregate(key=[order_id#17], functions=[first(customer_id#18, false), first(city#19, false), first(category#20, false), first(product#21, false), first(amount#22, false), first(order_date#23, false), first(status#24, false), first(city_clean#71, false), first(category_clean#72, false), first(product_clean#73, false), first(amount_clean#117, false), first(order_date_clean#163, false)], output=[order_id#17, customer_id#2597, city#2599, category#2601, product#2603, amount#2605, order_date#2607, status#2609, city_clean#2611, category_clean#2613, product_clean#2615, amount_clean#2617, order_date_clean#2619])\n",
            "                        +- Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                           +- Exchange hashpartitioning(order_id#17, 200), ENSURE_REQUIREMENTS, [plan_id=6368]\n",
            "                              +- SortAggregate(key=[order_id#17], functions=[partial_first(customer_id#18, false), partial_first(city#19, false), partial_first(category#20, false), partial_first(product#21, false), partial_first(amount#22, false), partial_first(order_date#23, false), partial_first(status#24, false), partial_first(city_clean#71, false), partial_first(category_clean#72, false), partial_first(product_clean#73, false), partial_first(amount_clean#117, false), partial_first(order_date_clean#163, false)], output=[order_id#17, first#2644, valueSet#2645, first#2646, valueSet#2647, first#2648, valueSet#2649, first#2650, valueSet#2651, first#2652, valueSet#2653, first#2654, valueSet#2655, first#2656, valueSet#2657, first#2658, valueSet#2659, first#2660, valueSet#2661, first#2662, valueSet#2663, first#2664, valueSet#2665, first#2666, valueSet#2667])\n",
            "                                 +- Sort [order_id#17 ASC NULLS FIRST], false, 0\n",
            "                                    +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, city_clean#71, category_clean#72, product_clean#73, CASE WHEN RLIKE(amount_clean#116, ^[0-9]+$) THEN cast(amount_clean#116 as int) END AS amount_clean#117, coalesce(cast(gettimestamp(order_date#23, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#23, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date_clean#163]\n",
            "                                       +- Project [order_id#17, customer_id#18, city#19, category#20, product#21, amount#22, order_date#23, status#24, lower(trim(city#19, None)) AS city_clean#71, lower(trim(category#20, None)) AS category_clean#72, lower(trim(product#21, None)) AS product_clean#73, regexp_replace(amount#22, ,, , 1) AS amount_clean#116]\n",
            "                                          +- Filter (isnotnull(status#24) AND (status#24 = Completed))\n",
            "                                             +- FileScan csv [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] Batched: false, DataFilters: [isnotnull(status#24), (status#24 = Completed)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/drive/MyDrive/Colab Notebooks/orders.csv], PartitionFilters: [], PushedFilters: [IsNotNull(status), EqualTo(status,Completed)], ReadSchema: struct<order_id:string,customer_id:string,city:string,category:string,product:string,amount:strin...\n",
            "   +- BroadcastExchange HashedRelationBroadcastMode(List(input[1, string, false]),false), [plan_id=6605]\n",
            "      +- Filter isnotnull(segment_label#3245)\n",
            "         +- Scan ExistingRDD[segment_code#3244L,segment_label#3245]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PHASE 9 – Sorting & Set Operations"
      ],
      "metadata": {
        "id": "6yrSqA1KC8jo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Sort customers by:\n",
        "- Total spend descending\n",
        "- Order count descending"
      ],
      "metadata": {
        "id": "ZMomJVHpDQGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customer_metrics_sorted = customer_metrics.orderBy(col(\"total_spend\").desc(), col(\"total_orders\").desc())\n",
        "\n",
        "print(\"Customers sorted by total spend (descending) and order count (descending):\")\n",
        "customer_metrics_sorted.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pwLmdnh57nb",
        "outputId": "69b84afb-d5b7-4d6a-f2df-4f1fe2dcda25"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customers sorted by total spend (descending) and order count (descending):\n",
            "+-----------+-----------+------------+\n",
            "|customer_id|total_spend|total_orders|\n",
            "+-----------+-----------+------------+\n",
            "|    C043076|     493949|           6|\n",
            "|    C034689|     486879|           6|\n",
            "|    C039985|     484057|           6|\n",
            "|    C026691|     477147|           6|\n",
            "|    C038979|     477138|           6|\n",
            "|    C020762|     474717|           6|\n",
            "|    C044654|     471304|           6|\n",
            "|    C014292|     468617|           6|\n",
            "|    C019565|     467523|           6|\n",
            "|    C045487|     467050|           6|\n",
            "+-----------+-----------+------------+\n",
            "only showing top 10 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Create two sets:\n",
        "- Customers who bought Electronics\n",
        "- Customers who bought Grocery"
      ],
      "metadata": {
        "id": "oyrpPBiiDWny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customers_electronics = df_clean_orders.filter(col(\"category_clean\") == \"electronics\").select(\"customer_id\").distinct()\n",
        "customers_grocery = df_clean_orders.filter(col(\"category_clean\") == \"grocery\").select(\"customer_id\").distinct()\n",
        "\n",
        "print(\"Customers who bought Electronics (first 5):\")\n",
        "customers_electronics.show(5)\n",
        "print(\"Customers who bought Grocery (first 5):\")\n",
        "customers_grocery.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6ir-7jP6C4M",
        "outputId": "a1800ce3-d11e-483b-c3f8-9b72ce76b5b8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customers who bought Electronics (first 5):\n",
            "+-----------+\n",
            "|customer_id|\n",
            "+-----------+\n",
            "|    C036809|\n",
            "|    C041216|\n",
            "|    C016502|\n",
            "|    C049309|\n",
            "|    C047477|\n",
            "+-----------+\n",
            "only showing top 5 rows\n",
            "Customers who bought Grocery (first 5):\n",
            "+-----------+\n",
            "|customer_id|\n",
            "+-----------+\n",
            "|    C016502|\n",
            "|    C022166|\n",
            "|    C036542|\n",
            "|    C013083|\n",
            "|    C009472|\n",
            "+-----------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Find:\n",
        "- Customers in both sets\n",
        "- Customers in only one set"
      ],
      "metadata": {
        "id": "kJHlLMopDfPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customers_both_sets = customers_electronics.intersect(customers_grocery)\n",
        "print(\"Customers who bought both Electronics and Grocery (first 5):\")\n",
        "customers_both_sets.show(5)\n",
        "print(f\"Total customers who bought both: {customers_both_sets.count()}\")\n",
        "\n",
        "customers_only_electronics = customers_electronics.exceptAll(customers_grocery)\n",
        "customers_only_grocery = customers_grocery.exceptAll(customers_electronics)\n",
        "\n",
        "customers_only_one_set = customers_only_electronics.union(customers_only_grocery)\n",
        "print(\"\\nCustomers who bought only one of Electronics or Grocery (first 5):\")\n",
        "customers_only_one_set.show(5)\n",
        "print(f\"Total customers who bought only one set: {customers_only_one_set.count()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Rs0SdXJ6Q4H",
        "outputId": "6693ce8f-638d-4313-b182-5f3764bf1b44"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customers who bought both Electronics and Grocery (first 5):\n",
            "+-----------+\n",
            "|customer_id|\n",
            "+-----------+\n",
            "|    C036809|\n",
            "|    C041216|\n",
            "|    C016502|\n",
            "|    C049309|\n",
            "|    C008796|\n",
            "+-----------+\n",
            "only showing top 5 rows\n",
            "Total customers who bought both: 31274\n",
            "\n",
            "Customers who bought only one of Electronics or Grocery (first 5):\n",
            "+-----------+\n",
            "|customer_id|\n",
            "+-----------+\n",
            "|    C047477|\n",
            "|    C033572|\n",
            "|    C031912|\n",
            "|    C025351|\n",
            "|    C006738|\n",
            "+-----------+\n",
            "only showing top 5 rows\n",
            "Total customers who bought only one set: 15453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PHASE 10 – Storage Strategy"
      ],
      "metadata": {
        "id": "2LrPuIkdDlPw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Write customer master dataset to:\n",
        "\n",
        "Parquet\n",
        "\n",
        "Partitioned by:\n",
        "customer_segment"
      ],
      "metadata": {
        "id": "zCUGN1TXDoVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customer_master_df = customer_segments.alias(\"customer_master\")\n",
        "\n",
        "customer_master_df.write.mode(\"overwrite\").partitionBy(\"customer_segment\").parquet(\"customer_master.parquet\")"
      ],
      "metadata": {
        "id": "vD9A4r596tgE"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Write monthly analytics to:\n",
        "\n",
        "ORC"
      ],
      "metadata": {
        "id": "s5vP8-cIDxcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_revenue_city.write.mode(\"overwrite\").orc(\"monthly_revenue_city.orc\")\n",
        "\n",
        "monthly_order_count_perctg.write.mode(\"overwrite\").orc(\"monthly_order_count_category.orc\")"
      ],
      "metadata": {
        "id": "bSnWAKBr7EPI"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Read back and validate."
      ],
      "metadata": {
        "id": "SP5PNYhjD5X1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customer_master_read = spark.read.parquet(\"customer_master.parquet\")\n",
        "print(\"Customer Master (read from Parquet):\")\n",
        "customer_master_read.show(5)\n",
        "\n",
        "monthly_revenue_city_read = spark.read.orc(\"monthly_revenue_city.orc\")\n",
        "print(\"Monthly Revenue per City (read from ORC):\")\n",
        "monthly_revenue_city_read.show(5)\n",
        "\n",
        "monthly_order_count_category_read = spark.read.orc(\"monthly_order_count_category.orc\")\n",
        "print(\"Monthly Order Count per Category (read from ORC):\")\n",
        "monthly_order_count_category_read.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Njk-vhqy7j74",
        "outputId": "bac9406b-3a81-4b84-a7b5-b767efa84301"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customer Master (read from Parquet):\n",
            "+-----------+-----------+------------+----------------+\n",
            "|customer_id|total_spend|total_orders|customer_segment|\n",
            "+-----------+-----------+------------+----------------+\n",
            "|    C017846|     259374|           6|             VIP|\n",
            "|    C031570|     265242|           6|             VIP|\n",
            "|    C008283|     329252|           6|             VIP|\n",
            "|    C035348|     258062|           6|             VIP|\n",
            "|    C042917|     291846|           6|             VIP|\n",
            "+-----------+-----------+------------+----------------+\n",
            "only showing top 5 rows\n",
            "Monthly Revenue per City (read from ORC):\n",
            "+-------------------+----------+---------------+\n",
            "|        order_month|city_clean|monthly_revenue|\n",
            "+-------------------+----------+---------------+\n",
            "|2024-02-01 00:00:00| bangalore|      792163305|\n",
            "|2024-01-01 00:00:00| bangalore|      822339117|\n",
            "|2024-01-01 00:00:00| hyderabad|      833063605|\n",
            "|2024-01-01 00:00:00|   kolkata|      824920456|\n",
            "|2024-01-01 00:00:00|    mumbai|      816636150|\n",
            "+-------------------+----------+---------------+\n",
            "only showing top 5 rows\n",
            "Monthly Order Count per Category (read from ORC):\n",
            "+-------------------+--------------+-------------------+\n",
            "|        order_month|category_clean|monthly_order_count|\n",
            "+-------------------+--------------+-------------------+\n",
            "|2024-01-01 00:00:00|       grocery|              36018|\n",
            "|2024-01-01 00:00:00|       fashion|              35571|\n",
            "|2024-01-01 00:00:00|   electronics|              35994|\n",
            "|2024-02-01 00:00:00|   electronics|              34766|\n",
            "|2024-02-01 00:00:00|       grocery|              34672|\n",
            "+-------------------+--------------+-------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PHASE 11 – Debugging"
      ],
      "metadata": {
        "id": "gB-Fi5JcD8oO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain why this is dangerous:\n",
        "\n",
        "df = df.groupBy(\"customer_id\").sum(\"amount\").show()\n",
        "\n",
        "Explain:\n",
        "- What df becomes\n",
        "- Why pipeline breaks\n",
        "- Correct approac"
      ],
      "metadata": {
        "id": "XHiay2dnEDMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Explain why this is dangerous:\n",
        "# df = df.groupBy(\"customer_id\").sum(\"amount\").show()\n",
        "\n",
        "# What df becomes:\n",
        "# The `.show()` method is an action in Spark DataFrames. It triggers the computation and prints the results to the console. However, it returns `None`. Therefore, `df` would become `None`.\n",
        "\n",
        "# Why pipeline breaks:\n",
        "# If `df` becomes `None`, any subsequent operations or transformations attempted on `df` will raise an `AttributeError` (e.g., 'NoneType' object has no attribute 'withColumn') because `df` is no longer a DataFrame object.\n",
        "\n",
        "# Correct approach:\n",
        "# The action (`.show()`) should not be chained with an assignment back to the DataFrame variable if you intend to continue using the DataFrame. Instead, separate the action:\n",
        "#\n",
        "# # Option 1: Assign the result of transformations to a new DataFrame variable\n",
        "# aggregated_df = df.groupBy(\"customer_id\").sum(\"amount\")\n",
        "# aggregated_df.show()\n",
        "#\n",
        "# # Option 2: Perform the action as a separate step if you intend to reuse the original DataFrame reference (not recommended if the aggregation is the desired next step in the pipeline)\n",
        "# df_aggregated = df.groupBy(\"customer_id\").sum(\"amount\")\n",
        "# df_aggregated.show()"
      ],
      "metadata": {
        "id": "69YmF_kJD3y5"
      },
      "execution_count": 52,
      "outputs": []
    }
  ]
}