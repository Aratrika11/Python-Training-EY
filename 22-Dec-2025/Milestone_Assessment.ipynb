{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VFml4ZNGxS16"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Driver Analytics Case Study\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DATASET 1 — DRIVER MASTER (CORRUPTED)"
      ],
      "metadata": {
        "id": "4oPfBL0ax3_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_drivers = [\n",
        "(\"D001\",\"Ramesh\",\"35\",\"Hyderabad\",\"Car,Bike\"),\n",
        "(\"D002\",\"Suresh\",\"Forty\",\"Bangalore\",\"Auto\"),\n",
        "(\"D003\",\"Anita\",None,\"Mumbai\",[\"Car\"]),\n",
        "(\"D004\",\"Kiran\",\"29\",\"Delhi\",\"Car|Bike\"),\n",
        "(\"D005\",\"\", \"42\",\"Chennai\",None)\n",
        "]\n",
        "\n",
        "dr_schema = StructType([\n",
        "    StructField(\"driver_id\", StringType(), True),\n",
        "    StructField(\"dnam\", StringType(), True),\n",
        "    StructField(\"age_raw\", StringType(), True),\n",
        "    StructField(\"city\", StringType(), True),\n",
        "    StructField(\"vehicle_raw\", StringType(), True)\n",
        "])\n",
        "dr_df = spark.createDataFrame(raw_drivers, dr_schema)\n",
        "dr_df.show(truncate=False)\n",
        "dr_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WsET2mdZx7xB",
        "outputId": "83ba3d5e-7855-4c47-9fa3-611f27d5b4e6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------+-------+---------+-----------+\n",
            "|driver_id|dnam  |age_raw|city     |vehicle_raw|\n",
            "+---------+------+-------+---------+-----------+\n",
            "|D001     |Ramesh|35     |Hyderabad|Car,Bike   |\n",
            "|D002     |Suresh|Forty  |Bangalore|Auto       |\n",
            "|D003     |Anita |NULL   |Mumbai   |[Car]      |\n",
            "|D004     |Kiran |29     |Delhi    |Car|Bike   |\n",
            "|D005     |      |42     |Chennai  |NULL       |\n",
            "+---------+------+-------+---------+-----------+\n",
            "\n",
            "root\n",
            " |-- driver_id: string (nullable = true)\n",
            " |-- dnam: string (nullable = true)\n",
            " |-- age_raw: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- vehicle_raw: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DATASET 2 — CITY MASTER (SMALL LOOKUP)"
      ],
      "metadata": {
        "id": "JUADziW803cL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_cities = [\n",
        "(\"Hyderabad\",\"South\"),\n",
        "(\"Bangalore\",\"South\"),\n",
        "(\"Mumbai\",\"West\"),\n",
        "(\"Delhi\",\"North\"),\n",
        "(\"Chennai\",\"South\")\n",
        "]\n",
        "\n",
        "city_schema = StructType([\n",
        "    StructField(\"city\", StringType(), True),\n",
        "    StructField(\"region\", StringType(), True),\n",
        "])\n",
        "\n",
        "city_df = spark.createDataFrame(raw_cities, city_schema)\n",
        "city_df.show(truncate=False)\n",
        "city_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pwdi7o3lzQHJ",
        "outputId": "5d386700-ea32-4143-898f-47cf70624319"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------+\n",
            "|city     |region|\n",
            "+---------+------+\n",
            "|Hyderabad|South |\n",
            "|Bangalore|South |\n",
            "|Mumbai   |West  |\n",
            "|Delhi    |North |\n",
            "|Chennai  |South |\n",
            "+---------+------+\n",
            "\n",
            "root\n",
            " |-- city: string (nullable = true)\n",
            " |-- region: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DATASET 3 — TRIPS DATA"
      ],
      "metadata": {
        "id": "EqWISBPb00Zk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_trips = [\n",
        "(\"T001\",\"D001\",\"Hyderabad\",\"2024-01-05\",\"Completed\",\"450\"),\n",
        "(\"T002\",\"D002\",\"Bangalore\",\"05/01/2024\",\"Cancelled\",\"0\"),\n",
        "(\"T003\",\"D003\",\"Mumbai\",\"2024/01/06\",\"Completed\",\"620\"),\n",
        "(\"T004\",\"D004\",\"Delhi\",\"invalid_date\",\"Completed\",\"540\"),\n",
        "(\"T005\",\"D001\",\"Hyderabad\",\"2024-01-10\",\"Completed\",\"700\"),\n",
        "(\"T006\",\"D005\",\"Chennai\",\"2024-01-12\",\"Completed\",\"350\")\n",
        "]\n",
        "\n",
        "trip_schema = StructType([\n",
        "    StructField(\"trip_id\", StringType(), True),\n",
        "    StructField(\"driver_id\", StringType(), True),\n",
        "    StructField(\"city\", StringType(), True),\n",
        "    StructField(\"date_raw\", StringType(), True),\n",
        "    StructField(\"status\", StringType(), True),\n",
        "    StructField(\"fare_raw\", StringType(), True),\n",
        "])\n",
        "\n",
        "tdf = spark.createDataFrame(raw_trips, trip_schema)\n",
        "tdf.show(truncate=False)\n",
        "tdf.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2Eo7qxn0TT6",
        "outputId": "fa2400a5-68bc-4c67-a96b-bb5780194869"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+---------+------------+---------+--------+\n",
            "|trip_id|driver_id|city     |date_raw    |status   |fare_raw|\n",
            "+-------+---------+---------+------------+---------+--------+\n",
            "|T001   |D001     |Hyderabad|2024-01-05  |Completed|450     |\n",
            "|T002   |D002     |Bangalore|05/01/2024  |Cancelled|0       |\n",
            "|T003   |D003     |Mumbai   |2024/01/06  |Completed|620     |\n",
            "|T004   |D004     |Delhi    |invalid_date|Completed|540     |\n",
            "|T005   |D001     |Hyderabad|2024-01-10  |Completed|700     |\n",
            "|T006   |D005     |Chennai  |2024-01-12  |Completed|350     |\n",
            "+-------+---------+---------+------------+---------+--------+\n",
            "\n",
            "root\n",
            " |-- trip_id: string (nullable = true)\n",
            " |-- driver_id: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- date_raw: string (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            " |-- fare_raw: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DATASET 4 — DRIVER ACTIVITY LOGS"
      ],
      "metadata": {
        "id": "B7cqTmlU07NU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_activity = [\n",
        "(\"D001\",\"login,accept_trip,logout\",\"{'device':'mobile'}\",180),\n",
        "(\"D002\",[\"login\",\"logout\"],\"device=laptop\",60),\n",
        "(\"D003\",\"login|accept_trip\",None,120),\n",
        "(\"D004\",None,\"{'device':'tablet'}\",90),\n",
        "(\"D005\",\"login\",\"{'device':'mobile'}\",30)\n",
        "]\n",
        "act_schema = StructType([\n",
        "    StructField(\"driver_id\", StringType(), True),\n",
        "    StructField(\"actions_raw\", StringType(), True),\n",
        "    StructField(\"metadata_raw\", StringType(), True),\n",
        "    StructField(\"duration\", StringType(), True)\n",
        "])\n",
        "\n",
        "acdf = spark.createDataFrame(raw_activity, act_schema)\n",
        "acdf.show(truncate=False)\n",
        "acdf.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWa0NuvQ0-P6",
        "outputId": "3a0d1eff-0c92-43cb-9248-e5e8fce7d382"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------------------+-------------------+--------+\n",
            "|driver_id|actions_raw             |metadata_raw       |duration|\n",
            "+---------+------------------------+-------------------+--------+\n",
            "|D001     |login,accept_trip,logout|{'device':'mobile'}|180     |\n",
            "|D002     |[login, logout]         |device=laptop      |60      |\n",
            "|D003     |login|accept_trip       |NULL               |120     |\n",
            "|D004     |NULL                    |{'device':'tablet'}|90      |\n",
            "|D005     |login                   |{'device':'mobile'}|30      |\n",
            "+---------+------------------------+-------------------+--------+\n",
            "\n",
            "root\n",
            " |-- driver_id: string (nullable = true)\n",
            " |-- actions_raw: string (nullable = true)\n",
            " |-- metadata_raw: string (nullable = true)\n",
            " |-- duration: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART A — DATA CLEANING & STRUCTURING\n",
        "\n",
        "- Design explicit schemas for all datasets\n",
        "- Normalize:\n",
        "\n",
        "Age\n",
        "\n",
        "Fare\n",
        "\n",
        "Dates\n",
        "\n",
        "3. Convert vehicle types and actions into arrays\n",
        "4. Handle missing and invalid records gracefully\n",
        "5. Produce clean DataFrames:\n",
        "drivers_df\n",
        "\n",
        "cities_df\n",
        "\n",
        "trips_df\n",
        "\n",
        "activity_df"
      ],
      "metadata": {
        "id": "VMqGhQm61ge7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1"
      ],
      "metadata": {
        "id": "QUvaMy5x3CWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = dr_df.withColumn(\"dnam\", when(trim(col(\"dnam\")) == \"\", None).otherwise(col(\"dnam\")))\\\n",
        "    .withColumn(\"age\",when(col(\"age_raw\").rlike(\"^[0-9]+$\"), col(\"age_raw\").cast(\"int\"))\n",
        "    ) \\\n",
        "    .withColumn(\"vehicles\",split(regexp_replace(coalesce(col(\"vehicle_raw\"), lit(\"\")), \"[|]\", \",\"),\",\")\n",
        "    ) \\\n",
        "    .drop(\"age_raw\", \"vehicle_raw\")\n",
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftpTywPX1wQP",
        "outputId": "1fe25e2b-5316-4299-a55f-eba9d827e441"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------+---------+----+-----------+\n",
            "|driver_id|  dnam|     city| age|   vehicles|\n",
            "+---------+------+---------+----+-----------+\n",
            "|     D001|Ramesh|Hyderabad|  35|[Car, Bike]|\n",
            "|     D002|Suresh|Bangalore|NULL|     [Auto]|\n",
            "|     D003| Anita|   Mumbai|NULL|    [[Car]]|\n",
            "|     D004| Kiran|    Delhi|  29|[Car, Bike]|\n",
            "|     D005|  NULL|  Chennai|  42|         []|\n",
            "+---------+------+---------+----+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2"
      ],
      "metadata": {
        "id": "Qjk-X3NJ25sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = tdf.withColumn(\"trip_date\",coalesce(\n",
        "            to_date(try_to_timestamp(col(\"date_raw\"),lit(\"yyyy-MM-dd\"))),\n",
        "                                        to_date(try_to_timestamp(col(\"date_raw\"),lit(\"dd/MM/yyyy\"))),\n",
        "                                        to_date(try_to_timestamp(col(\"date_raw\"),lit(\"yyyy/MM/dd\")))\n",
        "        )).withColumn(\"fare\", col(\"fare_raw\").cast(\"double\")) \\\n",
        "    .drop(\"date_raw\", \"fare_raw\")\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWmDQbWu3Oet",
        "outputId": "46ab4127-82e1-49ed-d9a3-a43e4cb3c10d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+---------+---------+----------+-----+\n",
            "|trip_id|driver_id|     city|   status| trip_date| fare|\n",
            "+-------+---------+---------+---------+----------+-----+\n",
            "|   T001|     D001|Hyderabad|Completed|2024-01-05|450.0|\n",
            "|   T002|     D002|Bangalore|Cancelled|2024-01-05|  0.0|\n",
            "|   T003|     D003|   Mumbai|Completed|2024-01-06|620.0|\n",
            "|   T004|     D004|    Delhi|Completed|      NULL|540.0|\n",
            "|   T005|     D001|Hyderabad|Completed|2024-01-10|700.0|\n",
            "|   T006|     D005|  Chennai|Completed|2024-01-12|350.0|\n",
            "+-------+---------+---------+---------+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import split, regexp_replace, col, lit, when\n",
        "\n",
        "df3 = acdf.withColumn(\"actions\",when(col(\"actions_raw\").isNull(), array())\n",
        "        .otherwise(split(regexp_replace(col(\"actions_raw\"),\"[|]\",\",\"),\",\"))\n",
        "    ) \\\n",
        "    .withColumn(\"metadata\",\n",
        "        from_json(col(\"metadata_raw\"), MapType(StringType(),StringType()))\n",
        "    ).drop(\"actions_raw\",\"metadata_raw\")\n",
        "df3.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8YEJU1c5huZ",
        "outputId": "cdebb035-03d3-4904-b062-0318d4675198"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+----------------------------+------------------+\n",
            "|driver_id|duration|actions                     |metadata          |\n",
            "+---------+--------+----------------------------+------------------+\n",
            "|D001     |180     |[login, accept_trip, logout]|{device -> mobile}|\n",
            "|D002     |60      |[[login,  logout]]          |NULL              |\n",
            "|D003     |120     |[login, accept_trip]        |NULL              |\n",
            "|D004     |90      |[]                          |{device -> tablet}|\n",
            "|D005     |30      |[login]                     |{device -> mobile}|\n",
            "+---------+--------+----------------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART B — DATA INTEGRATION (JOINS)\n",
        "\n",
        "6. Join trips with drivers\n",
        "7. Join trips with cities\n",
        "8. Decide which dataset should be broadcast\n",
        "9. Prove your decision using explain(True)\n",
        "10. Remove orphan trips (drivers not in master)"
      ],
      "metadata": {
        "id": "pPuiXRHM3zm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#6\n",
        "t = df2.alias(\"t\")\n",
        "d = df1.alias(\"d\")\n",
        "\n",
        "trip_driver_df = t.join(\n",
        "    d, col(\"t.driver_id\")==col(\"d.driver_id\"), \"inner\")\n",
        "trip_driver_df.show()\n",
        "\n",
        "#7\n",
        "c = city_df.alias(\"c\")\n",
        "\n",
        "trip_full_df = trip_driver_df.join(\n",
        "    broadcast(c),col(\"t.city\")==col(\"c.city\"),\"left\")\n",
        "trip_full_df.show()\n",
        "\n",
        "#8\n",
        "#City DataFrame should be broadcast because of the very small lookup table\n",
        "\n",
        "#9\n",
        "trip_full_df.explain(True)\n",
        "\n",
        "#10\n",
        "#Orphan trips are already removed by Inner Join"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_6eFoRD83G5",
        "outputId": "8c600875-162e-4a2c-d16e-e487aa1186f8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+---------+---------+----------+-----+---------+------+---------+----+-----------+\n",
            "|trip_id|driver_id|     city|   status| trip_date| fare|driver_id|  dnam|     city| age|   vehicles|\n",
            "+-------+---------+---------+---------+----------+-----+---------+------+---------+----+-----------+\n",
            "|   T001|     D001|Hyderabad|Completed|2024-01-05|450.0|     D001|Ramesh|Hyderabad|  35|[Car, Bike]|\n",
            "|   T005|     D001|Hyderabad|Completed|2024-01-10|700.0|     D001|Ramesh|Hyderabad|  35|[Car, Bike]|\n",
            "|   T002|     D002|Bangalore|Cancelled|2024-01-05|  0.0|     D002|Suresh|Bangalore|NULL|     [Auto]|\n",
            "|   T003|     D003|   Mumbai|Completed|2024-01-06|620.0|     D003| Anita|   Mumbai|NULL|    [[Car]]|\n",
            "|   T004|     D004|    Delhi|Completed|      NULL|540.0|     D004| Kiran|    Delhi|  29|[Car, Bike]|\n",
            "|   T006|     D005|  Chennai|Completed|2024-01-12|350.0|     D005|  NULL|  Chennai|  42|         []|\n",
            "+-------+---------+---------+---------+----------+-----+---------+------+---------+----+-----------+\n",
            "\n",
            "+-------+---------+---------+---------+----------+-----+---------+------+---------+----+-----------+---------+------+\n",
            "|trip_id|driver_id|     city|   status| trip_date| fare|driver_id|  dnam|     city| age|   vehicles|     city|region|\n",
            "+-------+---------+---------+---------+----------+-----+---------+------+---------+----+-----------+---------+------+\n",
            "|   T001|     D001|Hyderabad|Completed|2024-01-05|450.0|     D001|Ramesh|Hyderabad|  35|[Car, Bike]|Hyderabad| South|\n",
            "|   T005|     D001|Hyderabad|Completed|2024-01-10|700.0|     D001|Ramesh|Hyderabad|  35|[Car, Bike]|Hyderabad| South|\n",
            "|   T002|     D002|Bangalore|Cancelled|2024-01-05|  0.0|     D002|Suresh|Bangalore|NULL|     [Auto]|Bangalore| South|\n",
            "|   T003|     D003|   Mumbai|Completed|2024-01-06|620.0|     D003| Anita|   Mumbai|NULL|    [[Car]]|   Mumbai|  West|\n",
            "|   T004|     D004|    Delhi|Completed|      NULL|540.0|     D004| Kiran|    Delhi|  29|[Car, Bike]|    Delhi| North|\n",
            "|   T006|     D005|  Chennai|Completed|2024-01-12|350.0|     D005|  NULL|  Chennai|  42|         []|  Chennai| South|\n",
            "+-------+---------+---------+---------+----------+-----+---------+------+---------+----+-----------+---------+------+\n",
            "\n",
            "== Parsed Logical Plan ==\n",
            "Join LeftOuter, (city#32 = city#21)\n",
            ":- Join Inner, (driver_id#31 = driver_id#0)\n",
            ":  :- SubqueryAlias t\n",
            ":  :  +- Project [trip_id#30, driver_id#31, city#32, status#34, trip_date#91, fare#92]\n",
            ":  :     +- Project [trip_id#30, driver_id#31, city#32, date_raw#33, status#34, fare_raw#35, trip_date#91, cast(fare_raw#35 as double) AS fare#92]\n",
            ":  :        +- Project [trip_id#30, driver_id#31, city#32, date_raw#33, status#34, fare_raw#35, coalesce(to_date(try_to_timestamp(date_raw#33, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true), to_date(try_to_timestamp(date_raw#33, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true), to_date(try_to_timestamp(date_raw#33, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true)) AS trip_date#91]\n",
            ":  :           +- LogicalRDD [trip_id#30, driver_id#31, city#32, date_raw#33, status#34, fare_raw#35], false\n",
            ":  +- SubqueryAlias d\n",
            ":     +- Project [driver_id#0, dnam#72, city#3, age#73, vehicles#74]\n",
            ":        +- Project [driver_id#0, dnam#72, age_raw#2, city#3, vehicle_raw#4, age#73, split(regexp_replace(coalesce(vehicle_raw#4, ), [|], ,, 1), ,, -1) AS vehicles#74]\n",
            ":           +- Project [driver_id#0, dnam#72, age_raw#2, city#3, vehicle_raw#4, CASE WHEN RLIKE(age_raw#2, ^[0-9]+$) THEN cast(age_raw#2 as int) END AS age#73]\n",
            ":              +- Project [driver_id#0, CASE WHEN (trim(dnam#1, None) = ) THEN cast(null as string) ELSE dnam#1 END AS dnam#72, age_raw#2, city#3, vehicle_raw#4]\n",
            ":                 +- LogicalRDD [driver_id#0, dnam#1, age_raw#2, city#3, vehicle_raw#4], false\n",
            "+- ResolvedHint (strategy=broadcast)\n",
            "   +- SubqueryAlias c\n",
            "      +- LogicalRDD [city#21, region#22], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "trip_id: string, driver_id: string, city: string, status: string, trip_date: date, fare: double, driver_id: string, dnam: string, city: string, age: int, vehicles: array<string>, city: string, region: string\n",
            "Join LeftOuter, (city#32 = city#21)\n",
            ":- Join Inner, (driver_id#31 = driver_id#0)\n",
            ":  :- SubqueryAlias t\n",
            ":  :  +- Project [trip_id#30, driver_id#31, city#32, status#34, trip_date#91, fare#92]\n",
            ":  :     +- Project [trip_id#30, driver_id#31, city#32, date_raw#33, status#34, fare_raw#35, trip_date#91, cast(fare_raw#35 as double) AS fare#92]\n",
            ":  :        +- Project [trip_id#30, driver_id#31, city#32, date_raw#33, status#34, fare_raw#35, coalesce(to_date(try_to_timestamp(date_raw#33, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true), to_date(try_to_timestamp(date_raw#33, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true), to_date(try_to_timestamp(date_raw#33, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true)) AS trip_date#91]\n",
            ":  :           +- LogicalRDD [trip_id#30, driver_id#31, city#32, date_raw#33, status#34, fare_raw#35], false\n",
            ":  +- SubqueryAlias d\n",
            ":     +- Project [driver_id#0, dnam#72, city#3, age#73, vehicles#74]\n",
            ":        +- Project [driver_id#0, dnam#72, age_raw#2, city#3, vehicle_raw#4, age#73, split(regexp_replace(coalesce(vehicle_raw#4, ), [|], ,, 1), ,, -1) AS vehicles#74]\n",
            ":           +- Project [driver_id#0, dnam#72, age_raw#2, city#3, vehicle_raw#4, CASE WHEN RLIKE(age_raw#2, ^[0-9]+$) THEN cast(age_raw#2 as int) END AS age#73]\n",
            ":              +- Project [driver_id#0, CASE WHEN (trim(dnam#1, None) = ) THEN cast(null as string) ELSE dnam#1 END AS dnam#72, age_raw#2, city#3, vehicle_raw#4]\n",
            ":                 +- LogicalRDD [driver_id#0, dnam#1, age_raw#2, city#3, vehicle_raw#4], false\n",
            "+- ResolvedHint (strategy=broadcast)\n",
            "   +- SubqueryAlias c\n",
            "      +- LogicalRDD [city#21, region#22], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Join LeftOuter, (city#32 = city#21), rightHint=(strategy=broadcast)\n",
            ":- Join Inner, (driver_id#31 = driver_id#0)\n",
            ":  :- Project [trip_id#30, driver_id#31, city#32, status#34, coalesce(cast(gettimestamp(date_raw#33, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(date_raw#33, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(date_raw#33, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS trip_date#91, cast(fare_raw#35 as double) AS fare#92]\n",
            ":  :  +- Filter isnotnull(driver_id#31)\n",
            ":  :     +- LogicalRDD [trip_id#30, driver_id#31, city#32, date_raw#33, status#34, fare_raw#35], false\n",
            ":  +- Project [driver_id#0, CASE WHEN (trim(dnam#1, None) = ) THEN null ELSE dnam#1 END AS dnam#72, city#3, CASE WHEN RLIKE(age_raw#2, ^[0-9]+$) THEN cast(age_raw#2 as int) END AS age#73, split(regexp_replace(coalesce(vehicle_raw#4, ), [|], ,, 1), ,, -1) AS vehicles#74]\n",
            ":     +- Filter isnotnull(driver_id#0)\n",
            ":        +- LogicalRDD [driver_id#0, dnam#1, age_raw#2, city#3, vehicle_raw#4], false\n",
            "+- Filter isnotnull(city#21)\n",
            "   +- LogicalRDD [city#21, region#22], false\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- BroadcastHashJoin [city#32], [city#21], LeftOuter, BuildRight, false\n",
            "   :- SortMergeJoin [driver_id#31], [driver_id#0], Inner\n",
            "   :  :- Sort [driver_id#31 ASC NULLS FIRST], false, 0\n",
            "   :  :  +- Exchange hashpartitioning(driver_id#31, 200), ENSURE_REQUIREMENTS, [plan_id=1074]\n",
            "   :  :     +- Project [trip_id#30, driver_id#31, city#32, status#34, coalesce(cast(gettimestamp(date_raw#33, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(date_raw#33, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(date_raw#33, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS trip_date#91, cast(fare_raw#35 as double) AS fare#92]\n",
            "   :  :        +- Filter isnotnull(driver_id#31)\n",
            "   :  :           +- Scan ExistingRDD[trip_id#30,driver_id#31,city#32,date_raw#33,status#34,fare_raw#35]\n",
            "   :  +- Sort [driver_id#0 ASC NULLS FIRST], false, 0\n",
            "   :     +- Exchange hashpartitioning(driver_id#0, 200), ENSURE_REQUIREMENTS, [plan_id=1075]\n",
            "   :        +- Project [driver_id#0, CASE WHEN (trim(dnam#1, None) = ) THEN null ELSE dnam#1 END AS dnam#72, city#3, CASE WHEN RLIKE(age_raw#2, ^[0-9]+$) THEN cast(age_raw#2 as int) END AS age#73, split(regexp_replace(coalesce(vehicle_raw#4, ), [|], ,, 1), ,, -1) AS vehicles#74]\n",
            "   :           +- Filter isnotnull(driver_id#0)\n",
            "   :              +- Scan ExistingRDD[driver_id#0,dnam#1,age_raw#2,city#3,vehicle_raw#4]\n",
            "   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=1080]\n",
            "      +- Filter isnotnull(city#21)\n",
            "         +- Scan ExistingRDD[city#21,region#22]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART C — ANALYTICS & AGGREGATIONS\n",
        "\n",
        "11. Total trips per city\n",
        "12. Total revenue per city\n",
        "13. Average fare per driver\n",
        "14. Total completed trips per driver\n",
        "15. Identify drivers with no completed trips"
      ],
      "metadata": {
        "id": "tSznFUYL3-hd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#11\n",
        "trip_full_df.groupBy(col(\"t.city\").alias(\"city\")).count().show()\n",
        "\n",
        "#12\n",
        "trip_full_df.filter(col(\"t.status\")==\"Completed\").groupBy(col(\"t.city\").alias(\"city\")) \\\n",
        "    .agg(sum(\"fare\").alias(\"total_revenue\")).show()\n",
        "\n",
        "#13\n",
        "trip_full_df.filter(col(\"t.status\")==\"Completed\").groupBy(\"d.driver_id\") \\\n",
        "    .agg(avg(\"fare\").alias(\"avg_fare\")).show()\n",
        "\n",
        "#14\n",
        "trip_full_df.filter(col(\"t.status\")==\"Completed\").groupBy(\"t.driver_id\").count().show()\n",
        "\n",
        "#15\n",
        "completed = trip_full_df.filter(col(\"t.status\")==\"Completed\").select(\"t.driver_id\").distinct()\n",
        "\n",
        "dr_df.select(\"driver_id\").subtract(completed).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJkFwX1S-JLG",
        "outputId": "d4037355-f9fc-4bc6-a42b-c6078d9ff357"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+\n",
            "|     city|count|\n",
            "+---------+-----+\n",
            "|Bangalore|    1|\n",
            "|  Chennai|    1|\n",
            "|   Mumbai|    1|\n",
            "|    Delhi|    1|\n",
            "|Hyderabad|    2|\n",
            "+---------+-----+\n",
            "\n",
            "+---------+-------------+\n",
            "|     city|total_revenue|\n",
            "+---------+-------------+\n",
            "|  Chennai|        350.0|\n",
            "|   Mumbai|        620.0|\n",
            "|    Delhi|        540.0|\n",
            "|Hyderabad|       1150.0|\n",
            "+---------+-------------+\n",
            "\n",
            "+---------+--------+\n",
            "|driver_id|avg_fare|\n",
            "+---------+--------+\n",
            "|     D001|   575.0|\n",
            "|     D003|   620.0|\n",
            "|     D004|   540.0|\n",
            "|     D005|   350.0|\n",
            "+---------+--------+\n",
            "\n",
            "+---------+-----+\n",
            "|driver_id|count|\n",
            "+---------+-----+\n",
            "|     D001|    2|\n",
            "|     D003|    1|\n",
            "|     D004|    1|\n",
            "|     D005|    1|\n",
            "+---------+-----+\n",
            "\n",
            "+---------+\n",
            "|driver_id|\n",
            "+---------+\n",
            "|     D002|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART D — WINDOW FUNCTIONS\n",
        "\n",
        "16. Rank drivers by total revenue (overall)\n",
        "17. Rank drivers by revenue within each city\n",
        "18. Calculate running revenue per city by date\n",
        "19. Compare GroupBy vs Window for one metric"
      ],
      "metadata": {
        "id": "AyCr-l654Fdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#16\n",
        "rev_df = trip_full_df.filter(col(\"t.status\")==\"Completed\").groupBy(\"t.driver_id\").agg(sum(\"fare\").alias(\"revenue\"))\n",
        "\n",
        "w = Window.orderBy(desc(\"revenue\"))\n",
        "\n",
        "rev_df.withColumn(\"rank\", dense_rank().over(w)).show()\n",
        "\n",
        "#17\n",
        "city_rev = trip_full_df.filter(col(\"t.status\")==\"Completed\").groupBy(col(\"t.city\"),\"t.driver_id\").agg(sum(\"fare\").alias(\"revenue\"))\n",
        "\n",
        "w_city = Window.partitionBy(\"city\").orderBy(desc(\"revenue\"))\n",
        "\n",
        "city_rev.withColumn(\"city_rank\", dense_rank().over(w_city)).show()\n",
        "\n",
        "#18\n",
        "w_run = Window.partitionBy(\"t.city\").orderBy(\"trip_date\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
        "\n",
        "trip_full_df.filter(col(\"t.status\")==\"Completed\").withColumn(\"running_revenue\", sum(\"fare\").over(w_run)).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEePHJ01WQ1i",
        "outputId": "f7b4489c-7126-43b9-9b83-be85f6e520f8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+----+\n",
            "|driver_id|revenue|rank|\n",
            "+---------+-------+----+\n",
            "|     D001| 1150.0|   1|\n",
            "|     D003|  620.0|   2|\n",
            "|     D004|  540.0|   3|\n",
            "|     D005|  350.0|   4|\n",
            "+---------+-------+----+\n",
            "\n",
            "+---------+---------+-------+---------+\n",
            "|     city|driver_id|revenue|city_rank|\n",
            "+---------+---------+-------+---------+\n",
            "|  Chennai|     D005|  350.0|        1|\n",
            "|    Delhi|     D004|  540.0|        1|\n",
            "|Hyderabad|     D001| 1150.0|        1|\n",
            "|   Mumbai|     D003|  620.0|        1|\n",
            "+---------+---------+-------+---------+\n",
            "\n",
            "+-------+---------+---------+---------+----------+-----+---------+------+---------+----+-----------+---------+------+---------------+\n",
            "|trip_id|driver_id|     city|   status| trip_date| fare|driver_id|  dnam|     city| age|   vehicles|     city|region|running_revenue|\n",
            "+-------+---------+---------+---------+----------+-----+---------+------+---------+----+-----------+---------+------+---------------+\n",
            "|   T006|     D005|  Chennai|Completed|2024-01-12|350.0|     D005|  NULL|  Chennai|  42|         []|  Chennai| South|          350.0|\n",
            "|   T004|     D004|    Delhi|Completed|      NULL|540.0|     D004| Kiran|    Delhi|  29|[Car, Bike]|    Delhi| North|          540.0|\n",
            "|   T001|     D001|Hyderabad|Completed|2024-01-05|450.0|     D001|Ramesh|Hyderabad|  35|[Car, Bike]|Hyderabad| South|          450.0|\n",
            "|   T005|     D001|Hyderabad|Completed|2024-01-10|700.0|     D001|Ramesh|Hyderabad|  35|[Car, Bike]|Hyderabad| South|         1150.0|\n",
            "|   T003|     D003|   Mumbai|Completed|2024-01-06|620.0|     D003| Anita|   Mumbai|NULL|    [[Car]]|   Mumbai|  West|          620.0|\n",
            "+-------+---------+---------+---------+----------+-----+---------+------+---------+----+-----------+---------+------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "19\n",
        "###GroupBy\n",
        "- it collapses the rows\n",
        "- Gives aggregated results\n",
        "\n",
        "###Window\n",
        "- it retains the rows\n",
        "- does row level analytics"
      ],
      "metadata": {
        "id": "3TDHSzX6XSKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART E — UDF (ONLY IF REQUIRED)\n",
        "\n",
        "20. Classify drivers into performance levels:\n",
        "\n",
        "High\n",
        "Medium\n",
        "Low\n",
        "\n",
        "Rules:\n",
        "\n",
        "Prefer built-in functions,\n",
        "Use UDF only if unavoidable,\n",
        "Justify your choice"
      ],
      "metadata": {
        "id": "OOD-C-EI4Lac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rev_df2 = rev_df.withColumn(\n",
        "    \"performance\",when(col(\"revenue\")>=600,\"High\")\n",
        "    .when(col(\"revenue\")>=400,\"Medium\")\n",
        "    .otherwise(\"Low\"))\n",
        "\n",
        "print(\"Classifying drivers into performance levels\\n\")\n",
        "rev_df2.show()\n",
        "\n",
        "# Justification for not using a UDF:\n",
        "# PySpark's `when().otherwise()` provides native, optimized functionality for conditional logic.\n",
        "# It is executed within the Spark engine, benefiting from Catalyst Optimizer and Tungsten execution engine,\n",
        "# leading to significantly better performance compared to Python UDFs. UDFs involve serialization/deserialization\n",
        "# overhead and context switching between JVM and Python, which can be very slow for large datasets.\n",
        "# Since `when().otherwise()` perfectly handles the tier classification logic, a UDF is unnecessary and less efficient"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOIonEeNXoye",
        "outputId": "2425e6fe-4bb4-4b38-c226-7dfddfe0e3b2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifying drivers into performance levels\n",
            "\n",
            "+---------+-------+-----------+\n",
            "|driver_id|revenue|performance|\n",
            "+---------+-------+-----------+\n",
            "|     D001| 1150.0|       High|\n",
            "|     D003|  620.0|       High|\n",
            "|     D004|  540.0|     Medium|\n",
            "|     D005|  350.0|        Low|\n",
            "+---------+-------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART F — SORTING & ORDERING\n",
        "\n",
        "21. Sort cities by total revenue (descending)\n",
        "22. Sort drivers by revenue within each city\n",
        "23. Explain why sorting caused a shuffle"
      ],
      "metadata": {
        "id": "PXA9Nekp4ZjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#21\n",
        "city_rev.orderBy(desc(\"revenue\")).show()\n",
        "\n",
        "\n",
        "#22\n",
        "city_rev.orderBy(\"city\", desc(\"revenue\")).show()\n",
        "\n",
        "#23\n",
        "# Sorting a DataFrame in Spark often triggers a 'shuffle' operation.\n",
        "# A shuffle is the process of redistributing data across partitions (and potentially across machines in a cluster).\n",
        "# This is necessary because to perform a global sort (or even a sort within groups if data is not pre-partitioned\n",
        "# or pre-sorted), all data relevant to a specific sort key range might need to be collected on the same partition.\n",
        "# For example, when sorting categories by total revenue, Spark needs to know the total revenue for all categories\n",
        "# to correctly order them. If different parts of a category's data reside on different partitions,\n",
        "# Spark must move this data to ensure a consistent global order. This involves serializing data,\n",
        "# sending it over the network, and deserializing it on the receiving end, which is a resource-intensive operation."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mnt2TmCLYjF8",
        "outputId": "0af91f5a-7eec-4e9b-c504-3c2f99aefd77"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+-------+\n",
            "|     city|driver_id|revenue|\n",
            "+---------+---------+-------+\n",
            "|Hyderabad|     D001| 1150.0|\n",
            "|   Mumbai|     D003|  620.0|\n",
            "|    Delhi|     D004|  540.0|\n",
            "|  Chennai|     D005|  350.0|\n",
            "+---------+---------+-------+\n",
            "\n",
            "+---------+---------+-------+\n",
            "|     city|driver_id|revenue|\n",
            "+---------+---------+-------+\n",
            "|  Chennai|     D005|  350.0|\n",
            "|    Delhi|     D004|  540.0|\n",
            "|Hyderabad|     D001| 1150.0|\n",
            "|   Mumbai|     D003|  620.0|\n",
            "+---------+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART G — SET OPERATIONS\n",
        "\n",
        "Create two DataFrames:\n",
        "Drivers who completed trips\n",
        "Drivers who were active (login)\n",
        "\n",
        "24. Find drivers who logged in but never completed trips\n",
        "25. Find drivers who completed trips and were active\n",
        "26. Explain why set operations differ from joins"
      ],
      "metadata": {
        "id": "QcyLXkjz4e0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completed_set = trip_full_df.filter(col(\"t.status\")==\"Completed\").select(\"t.driver_id\").distinct()\n",
        "completed_set.show()\n",
        "\n",
        "ac_clean_df = acdf.withColumn(\"actions\",when(col(\"actions_raw\").isNull(), array())\n",
        "    .otherwise(split(regexp_replace(col(\"actions_raw\"),\"[|]\",\",\"),\",\")))\n",
        "\n",
        "active_set = ac_clean_df.filter(array_contains(col(\"actions\"),\"login\")).select(\"driver_id\").distinct()\n",
        "\n",
        "active_set.show()\n",
        "\n",
        "\n",
        "#24\n",
        "active_set.subtract(completed_set).show()\n",
        "\n",
        "\n",
        "#25\n",
        "active_set.intersect(completed_set).show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQNxOPYxZYkh",
        "outputId": "0f555061-e793-48ca-897c-925c363d8864"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|driver_id|\n",
            "+---------+\n",
            "|     D001|\n",
            "|     D003|\n",
            "|     D004|\n",
            "|     D005|\n",
            "+---------+\n",
            "\n",
            "+---------+\n",
            "|driver_id|\n",
            "+---------+\n",
            "|     D001|\n",
            "|     D003|\n",
            "|     D005|\n",
            "+---------+\n",
            "\n",
            "+---------+\n",
            "|driver_id|\n",
            "+---------+\n",
            "+---------+\n",
            "\n",
            "+---------+\n",
            "|driver_id|\n",
            "+---------+\n",
            "|     D003|\n",
            "|     D005|\n",
            "|     D001|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#26\n",
        "# Differences between Set Operations and Joins:\n",
        "#\n",
        "# Set Operations (UNION, INTERSECT, EXCEPT/SUBTRACT):\n",
        "# - Operate on the *rows* of DataFrames.\n",
        "# - Require the DataFrames to have a compatible schema (same number of columns, same column names, and compatible data types).\n",
        "# - Combine or compare rows based on their *entire content*.\n",
        "# - The result has the same schema as the input DataFrames.\n",
        "#\n",
        "# Join Operations (INNER, LEFT, RIGHT, FULL, ANTI, SEMI):\n",
        "# - Combine *columns* from two DataFrames.\n",
        "# - Combine data based on a *common key* or a specified condition.\n",
        "# - Typically result in a wider DataFrame (more columns) by merging information from both DataFrames.\n",
        "# - The schema of the result is a combination of the schemas of the input DataFrames (excluding duplicate join keys if specified).\n",
        "\n",
        "print(\"\\n--- Set Operations (Operating on rows) ---\")\n",
        "print(\"Drivers active but never completed trips (using subtract):\")\n",
        "active_set.subtract(completed_set).show()\n",
        "\n",
        "print(\"Drivers who completed trips AND were active (using intersect):\")\n",
        "active_set.subtract(completed_set).show()\n",
        "\n",
        "print(\"\\n--- Join Operations (Operating on columns based on keys) ---\")\n",
        "print(\"Inner Join: Combining trips and drivers for matching driver_ids:\")\n",
        "t = df2.alias(\"t\")\n",
        "d = df1.alias(\"d\")\n",
        "trip_driver_df = t.join(d, col(\"t.driver_id\")==col(\"d.driver_id\"), \"inner\")\n",
        "trip_driver_df.show()\n",
        "\n",
        "print(\"Left Join: Combining trips and  cities\")\n",
        "c = city_df.alias(\"c\")\n",
        "trip_full_df = trip_driver_df.join(broadcast(c),col(\"t.city\")==col(\"c.city\"),\"left\")\n",
        "trip_full_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7QINreWe7FQ",
        "outputId": "64eab04b-3477-42c3-e9dc-f5dafed18933"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Set Operations (Operating on rows) ---\n",
            "Drivers active but never completed trips (using subtract):\n",
            "+---------+\n",
            "|driver_id|\n",
            "+---------+\n",
            "+---------+\n",
            "\n",
            "Drivers who completed trips AND were active (using intersect):\n",
            "+---------+\n",
            "|driver_id|\n",
            "+---------+\n",
            "+---------+\n",
            "\n",
            "\n",
            "--- Join Operations (Operating on columns based on keys) ---\n",
            "Inner Join: Combining trips and drivers for matching driver_ids:\n",
            "+-------+---------+---------+---------+----------+-----+---------+------+---------+----+-----------+\n",
            "|trip_id|driver_id|     city|   status| trip_date| fare|driver_id|  dnam|     city| age|   vehicles|\n",
            "+-------+---------+---------+---------+----------+-----+---------+------+---------+----+-----------+\n",
            "|   T001|     D001|Hyderabad|Completed|2024-01-05|450.0|     D001|Ramesh|Hyderabad|  35|[Car, Bike]|\n",
            "|   T005|     D001|Hyderabad|Completed|2024-01-10|700.0|     D001|Ramesh|Hyderabad|  35|[Car, Bike]|\n",
            "|   T002|     D002|Bangalore|Cancelled|2024-01-05|  0.0|     D002|Suresh|Bangalore|NULL|     [Auto]|\n",
            "|   T003|     D003|   Mumbai|Completed|2024-01-06|620.0|     D003| Anita|   Mumbai|NULL|    [[Car]]|\n",
            "|   T004|     D004|    Delhi|Completed|      NULL|540.0|     D004| Kiran|    Delhi|  29|[Car, Bike]|\n",
            "|   T006|     D005|  Chennai|Completed|2024-01-12|350.0|     D005|  NULL|  Chennai|  42|         []|\n",
            "+-------+---------+---------+---------+----------+-----+---------+------+---------+----+-----------+\n",
            "\n",
            "Left Join: Combining trips and  cities\n",
            "+-------+---------+---------+---------+----------+-----+---------+------+---------+----+-----------+---------+------+\n",
            "|trip_id|driver_id|     city|   status| trip_date| fare|driver_id|  dnam|     city| age|   vehicles|     city|region|\n",
            "+-------+---------+---------+---------+----------+-----+---------+------+---------+----+-----------+---------+------+\n",
            "|   T001|     D001|Hyderabad|Completed|2024-01-05|450.0|     D001|Ramesh|Hyderabad|  35|[Car, Bike]|Hyderabad| South|\n",
            "|   T005|     D001|Hyderabad|Completed|2024-01-10|700.0|     D001|Ramesh|Hyderabad|  35|[Car, Bike]|Hyderabad| South|\n",
            "|   T002|     D002|Bangalore|Cancelled|2024-01-05|  0.0|     D002|Suresh|Bangalore|NULL|     [Auto]|Bangalore| South|\n",
            "|   T003|     D003|   Mumbai|Completed|2024-01-06|620.0|     D003| Anita|   Mumbai|NULL|    [[Car]]|   Mumbai|  West|\n",
            "|   T004|     D004|    Delhi|Completed|      NULL|540.0|     D004| Kiran|    Delhi|  29|[Car, Bike]|    Delhi| North|\n",
            "|   T006|     D005|  Chennai|Completed|2024-01-12|350.0|     D005|  NULL|  Chennai|  42|         []|  Chennai| South|\n",
            "+-------+---------+---------+---------+----------+-----+---------+------+---------+----+-----------+---------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART H — DAG & PERFORMANCE ANALYSIS\n",
        "\n",
        "27. Run explain(True) for:\n",
        "Join with city master,\n",
        "Window ranking,\n",
        "Sorting\n",
        "28. Identify:\n",
        "Shuffles\n",
        "Broadcast joins\n",
        "Sort stages\n",
        "29. Suggest one performance improvemen"
      ],
      "metadata": {
        "id": "Wn1ArwAP4lix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#27\n",
        "trip_full_df.explain(True)\n",
        "rev_df.explain(True)\n",
        "city_rev.orderBy(desc(\"revenue\")).explain(True)\n",
        "\n",
        "#28\n",
        "#Shuffles: GroupBy, sort\n",
        "#Broadcast joins: Seller join\n",
        "#Sort stages: Window+OrderBy\n",
        "\n",
        "#29\n",
        "# Performance Improvement Suggestion:\n",
        "\n",
        "trip_full_df.cache()\n",
        "# Cache the 'orders_products_df' DataFrame.\n",
        "# This DataFrame is the result of a join and is used multiple times in subsequent calculations\n",
        "# (e.g., total revenue per category/seller, running revenue, top products).\n",
        "# Caching it will prevent Spark from recomputing this DataFrame every time it's accessed."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS-yZtgQgNYN",
        "outputId": "ebbfbefb-3bad-492a-d352-0adcf35d8075"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "Join LeftOuter, (city#32 = city#21)\n",
            ":- Join Inner, (driver_id#31 = driver_id#0)\n",
            ":  :- SubqueryAlias t\n",
            ":  :  +- Project [trip_id#30, driver_id#31, city#32, status#34, trip_date#91, fare#92]\n",
            ":  :     +- Project [trip_id#30, driver_id#31, city#32, date_raw#33, status#34, fare_raw#35, trip_date#91, cast(fare_raw#35 as double) AS fare#92]\n",
            ":  :        +- Project [trip_id#30, driver_id#31, city#32, date_raw#33, status#34, fare_raw#35, coalesce(to_date(try_to_timestamp(date_raw#33, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true), to_date(try_to_timestamp(date_raw#33, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true), to_date(try_to_timestamp(date_raw#33, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true)) AS trip_date#91]\n",
            ":  :           +- LogicalRDD [trip_id#30, driver_id#31, city#32, date_raw#33, status#34, fare_raw#35], false\n",
            ":  +- SubqueryAlias d\n",
            ":     +- Project [driver_id#0, dnam#72, city#3, age#73, vehicles#74]\n",
            ":        +- Project [driver_id#0, dnam#72, age_raw#2, city#3, vehicle_raw#4, age#73, split(regexp_replace(coalesce(vehicle_raw#4, ), [|], ,, 1), ,, -1) AS vehicles#74]\n",
            ":           +- Project [driver_id#0, dnam#72, age_raw#2, city#3, vehicle_raw#4, CASE WHEN RLIKE(age_raw#2, ^[0-9]+$) THEN cast(age_raw#2 as int) END AS age#73]\n",
            ":              +- Project [driver_id#0, CASE WHEN (trim(dnam#1, None) = ) THEN cast(null as string) ELSE dnam#1 END AS dnam#72, age_raw#2, city#3, vehicle_raw#4]\n",
            ":                 +- LogicalRDD [driver_id#0, dnam#1, age_raw#2, city#3, vehicle_raw#4], false\n",
            "+- ResolvedHint (strategy=broadcast)\n",
            "   +- SubqueryAlias c\n",
            "      +- LogicalRDD [city#21, region#22], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "trip_id: string, driver_id: string, city: string, status: string, trip_date: date, fare: double, driver_id: string, dnam: string, city: string, age: int, vehicles: array<string>, city: string, region: string\n",
            "Join LeftOuter, (city#32 = city#21)\n",
            ":- Join Inner, (driver_id#31 = driver_id#0)\n",
            ":  :- SubqueryAlias t\n",
            ":  :  +- Project [trip_id#30, driver_id#31, city#32, status#34, trip_date#91, fare#92]\n",
            ":  :     +- Project [trip_id#30, driver_id#31, city#32, date_raw#33, status#34, fare_raw#35, trip_date#91, cast(fare_raw#35 as double) AS fare#92]\n",
            ":  :        +- Project [trip_id#30, driver_id#31, city#32, date_raw#33, status#34, fare_raw#35, coalesce(to_date(try_to_timestamp(date_raw#33, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true), to_date(try_to_timestamp(date_raw#33, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true), to_date(try_to_timestamp(date_raw#33, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true)) AS trip_date#91]\n",
            ":  :           +- LogicalRDD [trip_id#30, driver_id#31, city#32, date_raw#33, status#34, fare_raw#35], false\n",
            ":  +- SubqueryAlias d\n",
            ":     +- Project [driver_id#0, dnam#72, city#3, age#73, vehicles#74]\n",
            ":        +- Project [driver_id#0, dnam#72, age_raw#2, city#3, vehicle_raw#4, age#73, split(regexp_replace(coalesce(vehicle_raw#4, ), [|], ,, 1), ,, -1) AS vehicles#74]\n",
            ":           +- Project [driver_id#0, dnam#72, age_raw#2, city#3, vehicle_raw#4, CASE WHEN RLIKE(age_raw#2, ^[0-9]+$) THEN cast(age_raw#2 as int) END AS age#73]\n",
            ":              +- Project [driver_id#0, CASE WHEN (trim(dnam#1, None) = ) THEN cast(null as string) ELSE dnam#1 END AS dnam#72, age_raw#2, city#3, vehicle_raw#4]\n",
            ":                 +- LogicalRDD [driver_id#0, dnam#1, age_raw#2, city#3, vehicle_raw#4], false\n",
            "+- ResolvedHint (strategy=broadcast)\n",
            "   +- SubqueryAlias c\n",
            "      +- LogicalRDD [city#21, region#22], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Join LeftOuter, (city#32 = city#21), rightHint=(strategy=broadcast)\n",
            ":- Join Inner, (driver_id#31 = driver_id#0)\n",
            ":  :- Project [trip_id#30, driver_id#31, city#32, status#34, coalesce(cast(gettimestamp(date_raw#33, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(date_raw#33, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(date_raw#33, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS trip_date#91, cast(fare_raw#35 as double) AS fare#92]\n",
            ":  :  +- Filter isnotnull(driver_id#31)\n",
            ":  :     +- LogicalRDD [trip_id#30, driver_id#31, city#32, date_raw#33, status#34, fare_raw#35], false\n",
            ":  +- Project [driver_id#0, CASE WHEN (trim(dnam#1, None) = ) THEN null ELSE dnam#1 END AS dnam#72, city#3, CASE WHEN RLIKE(age_raw#2, ^[0-9]+$) THEN cast(age_raw#2 as int) END AS age#73, split(regexp_replace(coalesce(vehicle_raw#4, ), [|], ,, 1), ,, -1) AS vehicles#74]\n",
            ":     +- Filter isnotnull(driver_id#0)\n",
            ":        +- LogicalRDD [driver_id#0, dnam#1, age_raw#2, city#3, vehicle_raw#4], false\n",
            "+- Filter isnotnull(city#21)\n",
            "   +- LogicalRDD [city#21, region#22], false\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- BroadcastHashJoin [city#32], [city#21], LeftOuter, BuildRight, false\n",
            "   :- SortMergeJoin [driver_id#31], [driver_id#0], Inner\n",
            "   :  :- Sort [driver_id#31 ASC NULLS FIRST], false, 0\n",
            "   :  :  +- Exchange hashpartitioning(driver_id#31, 200), ENSURE_REQUIREMENTS, [plan_id=16166]\n",
            "   :  :     +- Project [trip_id#30, driver_id#31, city#32, status#34, coalesce(cast(gettimestamp(date_raw#33, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(date_raw#33, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(date_raw#33, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS trip_date#91, cast(fare_raw#35 as double) AS fare#92]\n",
            "   :  :        +- Filter isnotnull(driver_id#31)\n",
            "   :  :           +- Scan ExistingRDD[trip_id#30,driver_id#31,city#32,date_raw#33,status#34,fare_raw#35]\n",
            "   :  +- Sort [driver_id#0 ASC NULLS FIRST], false, 0\n",
            "   :     +- Exchange hashpartitioning(driver_id#0, 200), ENSURE_REQUIREMENTS, [plan_id=16167]\n",
            "   :        +- Project [driver_id#0, CASE WHEN (trim(dnam#1, None) = ) THEN null ELSE dnam#1 END AS dnam#72, city#3, CASE WHEN RLIKE(age_raw#2, ^[0-9]+$) THEN cast(age_raw#2 as int) END AS age#73, split(regexp_replace(coalesce(vehicle_raw#4, ), [|], ,, 1), ,, -1) AS vehicles#74]\n",
            "   :           +- Filter isnotnull(driver_id#0)\n",
            "   :              +- Scan ExistingRDD[driver_id#0,dnam#1,age_raw#2,city#3,vehicle_raw#4]\n",
            "   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=16172]\n",
            "      +- Filter isnotnull(city#21)\n",
            "         +- Scan ExistingRDD[city#21,region#22]\n",
            "\n",
            "== Parsed Logical Plan ==\n",
            "'Aggregate ['t.driver_id], ['t.driver_id, 'sum('fare) AS revenue#1191]\n",
            "+- Filter (status#34 = Completed)\n",
            "   +- Join LeftOuter, (city#32 = city#21)\n",
            "      :- Join Inner, (driver_id#31 = driver_id#0)\n",
            "      :  :- SubqueryAlias t\n",
            "      :  :  +- Project [trip_id#30, driver_id#31, city#32, status#34, trip_date#91, fare#92]\n",
            "      :  :     +- Project [trip_id#30, driver_id#31, city#32, date_raw#33, status#34, fare_raw#35, trip_date#91, cast(fare_raw#35 as double) AS fare#92]\n",
            "      :  :        +- Project [trip_id#30, driver_id#31, city#32, date_raw#33, status#34, fare_raw#35, coalesce(to_date(try_to_timestamp(date_raw#33, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true), to_date(try_to_timestamp(date_raw#33, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true), to_date(try_to_timestamp(date_raw#33, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true)) AS trip_date#91]\n",
            "      :  :           +- LogicalRDD [trip_id#30, driver_id#31, city#32, date_raw#33, status#34, fare_raw#35], false\n",
            "      :  +- SubqueryAlias d\n",
            "      :     +- Project [driver_id#0, dnam#72, city#3, age#73, vehicles#74]\n",
            "      :        +- Project [driver_id#0, dnam#72, age_raw#2, city#3, vehicle_raw#4, age#73, split(regexp_replace(coalesce(vehicle_raw#4, ), [|], ,, 1), ,, -1) AS vehicles#74]\n",
            "      :           +- Project [driver_id#0, dnam#72, age_raw#2, city#3, vehicle_raw#4, CASE WHEN RLIKE(age_raw#2, ^[0-9]+$) THEN cast(age_raw#2 as int) END AS age#73]\n",
            "      :              +- Project [driver_id#0, CASE WHEN (trim(dnam#1, None) = ) THEN cast(null as string) ELSE dnam#1 END AS dnam#72, age_raw#2, city#3, vehicle_raw#4]\n",
            "      :                 +- LogicalRDD [driver_id#0, dnam#1, age_raw#2, city#3, vehicle_raw#4], false\n",
            "      +- ResolvedHint (strategy=broadcast)\n",
            "         +- SubqueryAlias c\n",
            "            +- LogicalRDD [city#21, region#22], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "driver_id: string, revenue: double\n",
            "Aggregate [driver_id#31], [driver_id#31, sum(fare#92) AS revenue#1191]\n",
            "+- Filter (status#34 = Completed)\n",
            "   +- Join LeftOuter, (city#32 = city#21)\n",
            "      :- Join Inner, (driver_id#31 = driver_id#0)\n",
            "      :  :- SubqueryAlias t\n",
            "      :  :  +- Project [trip_id#30, driver_id#31, city#32, status#34, trip_date#91, fare#92]\n",
            "      :  :     +- Project [trip_id#30, driver_id#31, city#32, date_raw#33, status#34, fare_raw#35, trip_date#91, cast(fare_raw#35 as double) AS fare#92]\n",
            "      :  :        +- Project [trip_id#30, driver_id#31, city#32, date_raw#33, status#34, fare_raw#35, coalesce(to_date(try_to_timestamp(date_raw#33, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true), to_date(try_to_timestamp(date_raw#33, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true), to_date(try_to_timestamp(date_raw#33, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true)) AS trip_date#91]\n",
            "      :  :           +- LogicalRDD [trip_id#30, driver_id#31, city#32, date_raw#33, status#34, fare_raw#35], false\n",
            "      :  +- SubqueryAlias d\n",
            "      :     +- Project [driver_id#0, dnam#72, city#3, age#73, vehicles#74]\n",
            "      :        +- Project [driver_id#0, dnam#72, age_raw#2, city#3, vehicle_raw#4, age#73, split(regexp_replace(coalesce(vehicle_raw#4, ), [|], ,, 1), ,, -1) AS vehicles#74]\n",
            "      :           +- Project [driver_id#0, dnam#72, age_raw#2, city#3, vehicle_raw#4, CASE WHEN RLIKE(age_raw#2, ^[0-9]+$) THEN cast(age_raw#2 as int) END AS age#73]\n",
            "      :              +- Project [driver_id#0, CASE WHEN (trim(dnam#1, None) = ) THEN cast(null as string) ELSE dnam#1 END AS dnam#72, age_raw#2, city#3, vehicle_raw#4]\n",
            "      :                 +- LogicalRDD [driver_id#0, dnam#1, age_raw#2, city#3, vehicle_raw#4], false\n",
            "      +- ResolvedHint (strategy=broadcast)\n",
            "         +- SubqueryAlias c\n",
            "            +- LogicalRDD [city#21, region#22], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Aggregate [driver_id#31], [driver_id#31, sum(fare#92) AS revenue#1191]\n",
            "+- Project [driver_id#31, fare#92]\n",
            "   +- Join LeftOuter, (city#32 = city#21), rightHint=(strategy=broadcast)\n",
            "      :- Project [driver_id#31, city#32, fare#92]\n",
            "      :  +- Join Inner, (driver_id#31 = driver_id#0)\n",
            "      :     :- Project [driver_id#31, city#32, cast(fare_raw#35 as double) AS fare#92]\n",
            "      :     :  +- Filter ((isnotnull(status#34) AND (status#34 = Completed)) AND isnotnull(driver_id#31))\n",
            "      :     :     +- LogicalRDD [trip_id#30, driver_id#31, city#32, date_raw#33, status#34, fare_raw#35], false\n",
            "      :     +- Project [driver_id#0]\n",
            "      :        +- Filter isnotnull(driver_id#0)\n",
            "      :           +- LogicalRDD [driver_id#0, dnam#1, age_raw#2, city#3, vehicle_raw#4], false\n",
            "      +- Project [city#21]\n",
            "         +- Filter isnotnull(city#21)\n",
            "            +- LogicalRDD [city#21, region#22], false\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- HashAggregate(keys=[driver_id#31], functions=[sum(fare#92)], output=[driver_id#31, revenue#1191])\n",
            "   +- HashAggregate(keys=[driver_id#31], functions=[partial_sum(fare#92)], output=[driver_id#31, sum#1219])\n",
            "      +- Project [driver_id#31, fare#92]\n",
            "         +- BroadcastHashJoin [city#32], [city#21], LeftOuter, BuildRight, false\n",
            "            :- Project [driver_id#31, city#32, fare#92]\n",
            "            :  +- SortMergeJoin [driver_id#31], [driver_id#0], Inner\n",
            "            :     :- Sort [driver_id#31 ASC NULLS FIRST], false, 0\n",
            "            :     :  +- Exchange hashpartitioning(driver_id#31, 200), ENSURE_REQUIREMENTS, [plan_id=16234]\n",
            "            :     :     +- Project [driver_id#31, city#32, cast(fare_raw#35 as double) AS fare#92]\n",
            "            :     :        +- Filter ((isnotnull(status#34) AND (status#34 = Completed)) AND isnotnull(driver_id#31))\n",
            "            :     :           +- Scan ExistingRDD[trip_id#30,driver_id#31,city#32,date_raw#33,status#34,fare_raw#35]\n",
            "            :     +- Sort [driver_id#0 ASC NULLS FIRST], false, 0\n",
            "            :        +- Exchange hashpartitioning(driver_id#0, 200), ENSURE_REQUIREMENTS, [plan_id=16235]\n",
            "            :           +- Project [driver_id#0]\n",
            "            :              +- Filter isnotnull(driver_id#0)\n",
            "            :                 +- Scan ExistingRDD[driver_id#0,dnam#1,age_raw#2,city#3,vehicle_raw#4]\n",
            "            +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=16241]\n",
            "               +- Project [city#21]\n",
            "                  +- Filter isnotnull(city#21)\n",
            "                     +- Scan ExistingRDD[city#21,region#22]\n",
            "\n",
            "== Parsed Logical Plan ==\n",
            "'Sort ['revenue DESC NULLS LAST], true\n",
            "+- Aggregate [city#32, driver_id#31], [city#32, driver_id#31, sum(fare#92) AS revenue#1227]\n",
            "   +- Filter (status#34 = Completed)\n",
            "      +- Join LeftOuter, (city#32 = city#21)\n",
            "         :- Join Inner, (driver_id#31 = driver_id#0)\n",
            "         :  :- SubqueryAlias t\n",
            "         :  :  +- Project [trip_id#30, driver_id#31, city#32, status#34, trip_date#91, fare#92]\n",
            "         :  :     +- Project [trip_id#30, driver_id#31, city#32, date_raw#33, status#34, fare_raw#35, trip_date#91, cast(fare_raw#35 as double) AS fare#92]\n",
            "         :  :        +- Project [trip_id#30, driver_id#31, city#32, date_raw#33, status#34, fare_raw#35, coalesce(to_date(try_to_timestamp(date_raw#33, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true), to_date(try_to_timestamp(date_raw#33, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true), to_date(try_to_timestamp(date_raw#33, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true)) AS trip_date#91]\n",
            "         :  :           +- LogicalRDD [trip_id#30, driver_id#31, city#32, date_raw#33, status#34, fare_raw#35], false\n",
            "         :  +- SubqueryAlias d\n",
            "         :     +- Project [driver_id#0, dnam#72, city#3, age#73, vehicles#74]\n",
            "         :        +- Project [driver_id#0, dnam#72, age_raw#2, city#3, vehicle_raw#4, age#73, split(regexp_replace(coalesce(vehicle_raw#4, ), [|], ,, 1), ,, -1) AS vehicles#74]\n",
            "         :           +- Project [driver_id#0, dnam#72, age_raw#2, city#3, vehicle_raw#4, CASE WHEN RLIKE(age_raw#2, ^[0-9]+$) THEN cast(age_raw#2 as int) END AS age#73]\n",
            "         :              +- Project [driver_id#0, CASE WHEN (trim(dnam#1, None) = ) THEN cast(null as string) ELSE dnam#1 END AS dnam#72, age_raw#2, city#3, vehicle_raw#4]\n",
            "         :                 +- LogicalRDD [driver_id#0, dnam#1, age_raw#2, city#3, vehicle_raw#4], false\n",
            "         +- ResolvedHint (strategy=broadcast)\n",
            "            +- SubqueryAlias c\n",
            "               +- LogicalRDD [city#21, region#22], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "city: string, driver_id: string, revenue: double\n",
            "Sort [revenue#1227 DESC NULLS LAST], true\n",
            "+- Aggregate [city#32, driver_id#31], [city#32, driver_id#31, sum(fare#92) AS revenue#1227]\n",
            "   +- Filter (status#34 = Completed)\n",
            "      +- Join LeftOuter, (city#32 = city#21)\n",
            "         :- Join Inner, (driver_id#31 = driver_id#0)\n",
            "         :  :- SubqueryAlias t\n",
            "         :  :  +- Project [trip_id#30, driver_id#31, city#32, status#34, trip_date#91, fare#92]\n",
            "         :  :     +- Project [trip_id#30, driver_id#31, city#32, date_raw#33, status#34, fare_raw#35, trip_date#91, cast(fare_raw#35 as double) AS fare#92]\n",
            "         :  :        +- Project [trip_id#30, driver_id#31, city#32, date_raw#33, status#34, fare_raw#35, coalesce(to_date(try_to_timestamp(date_raw#33, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true), to_date(try_to_timestamp(date_raw#33, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true), to_date(try_to_timestamp(date_raw#33, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true)) AS trip_date#91]\n",
            "         :  :           +- LogicalRDD [trip_id#30, driver_id#31, city#32, date_raw#33, status#34, fare_raw#35], false\n",
            "         :  +- SubqueryAlias d\n",
            "         :     +- Project [driver_id#0, dnam#72, city#3, age#73, vehicles#74]\n",
            "         :        +- Project [driver_id#0, dnam#72, age_raw#2, city#3, vehicle_raw#4, age#73, split(regexp_replace(coalesce(vehicle_raw#4, ), [|], ,, 1), ,, -1) AS vehicles#74]\n",
            "         :           +- Project [driver_id#0, dnam#72, age_raw#2, city#3, vehicle_raw#4, CASE WHEN RLIKE(age_raw#2, ^[0-9]+$) THEN cast(age_raw#2 as int) END AS age#73]\n",
            "         :              +- Project [driver_id#0, CASE WHEN (trim(dnam#1, None) = ) THEN cast(null as string) ELSE dnam#1 END AS dnam#72, age_raw#2, city#3, vehicle_raw#4]\n",
            "         :                 +- LogicalRDD [driver_id#0, dnam#1, age_raw#2, city#3, vehicle_raw#4], false\n",
            "         +- ResolvedHint (strategy=broadcast)\n",
            "            +- SubqueryAlias c\n",
            "               +- LogicalRDD [city#21, region#22], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Sort [revenue#1227 DESC NULLS LAST], true\n",
            "+- Aggregate [city#32, driver_id#31], [city#32, driver_id#31, sum(fare#92) AS revenue#1227]\n",
            "   +- Project [driver_id#31, city#32, fare#92]\n",
            "      +- Join LeftOuter, (city#32 = city#21), rightHint=(strategy=broadcast)\n",
            "         :- Project [driver_id#31, city#32, fare#92]\n",
            "         :  +- Join Inner, (driver_id#31 = driver_id#0)\n",
            "         :     :- Project [driver_id#31, city#32, cast(fare_raw#35 as double) AS fare#92]\n",
            "         :     :  +- Filter ((isnotnull(status#34) AND (status#34 = Completed)) AND isnotnull(driver_id#31))\n",
            "         :     :     +- LogicalRDD [trip_id#30, driver_id#31, city#32, date_raw#33, status#34, fare_raw#35], false\n",
            "         :     +- Project [driver_id#0]\n",
            "         :        +- Filter isnotnull(driver_id#0)\n",
            "         :           +- LogicalRDD [driver_id#0, dnam#1, age_raw#2, city#3, vehicle_raw#4], false\n",
            "         +- Project [city#21]\n",
            "            +- Filter isnotnull(city#21)\n",
            "               +- LogicalRDD [city#21, region#22], false\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Sort [revenue#1227 DESC NULLS LAST], true, 0\n",
            "   +- Exchange rangepartitioning(revenue#1227 DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=16402]\n",
            "      +- HashAggregate(keys=[city#32, driver_id#31], functions=[sum(fare#92)], output=[city#32, driver_id#31, revenue#1227])\n",
            "         +- HashAggregate(keys=[city#32, driver_id#31], functions=[partial_sum(fare#92)], output=[city#32, driver_id#31, sum#1256])\n",
            "            +- Project [driver_id#31, city#32, fare#92]\n",
            "               +- BroadcastHashJoin [city#32], [city#21], LeftOuter, BuildRight, false\n",
            "                  :- Project [driver_id#31, city#32, fare#92]\n",
            "                  :  +- SortMergeJoin [driver_id#31], [driver_id#0], Inner\n",
            "                  :     :- Sort [driver_id#31 ASC NULLS FIRST], false, 0\n",
            "                  :     :  +- Exchange hashpartitioning(driver_id#31, 200), ENSURE_REQUIREMENTS, [plan_id=16389]\n",
            "                  :     :     +- Project [driver_id#31, city#32, cast(fare_raw#35 as double) AS fare#92]\n",
            "                  :     :        +- Filter ((isnotnull(status#34) AND (status#34 = Completed)) AND isnotnull(driver_id#31))\n",
            "                  :     :           +- Scan ExistingRDD[trip_id#30,driver_id#31,city#32,date_raw#33,status#34,fare_raw#35]\n",
            "                  :     +- Sort [driver_id#0 ASC NULLS FIRST], false, 0\n",
            "                  :        +- Exchange hashpartitioning(driver_id#0, 200), ENSURE_REQUIREMENTS, [plan_id=16390]\n",
            "                  :           +- Project [driver_id#0]\n",
            "                  :              +- Filter isnotnull(driver_id#0)\n",
            "                  :                 +- Scan ExistingRDD[driver_id#0,dnam#1,age_raw#2,city#3,vehicle_raw#4]\n",
            "                  +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=16396]\n",
            "                     +- Project [city#21]\n",
            "                        +- Filter isnotnull(city#21)\n",
            "                           +- Scan ExistingRDD[city#21,region#22]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[trip_id: string, driver_id: string, city: string, status: string, trip_date: date, fare: double, driver_id: string, dnam: string, city: string, age: int, vehicles: array<string>, city: string, region: string]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    }
  ]
}